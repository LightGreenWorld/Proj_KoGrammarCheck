{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grammatical_final_fixed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAgF_2xzyEnT",
        "outputId": "364c2cfa-7c7e-4cc7-b27f-c335d1e210d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yxJzt9AyRuW",
        "outputId": "94ea051d-6142-4964-9df7-dcb98c09a44e"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "if torch.cuda.is_available(): # GPU 이용 가능하다면,\n",
        "\n",
        "  device = torch.device(\"cuda\")   # 파이토치에게 GPU(\"cuda\") 사용하라고 말해\n",
        "\n",
        "  print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
        "  print(\"We will use the GPU:\", torch.cuda.get_device_name(0))  # GPU 장치 이름 출력\n",
        "\n",
        "else:\n",
        "  print(\"No GPU available, using the CPU instead\")\n",
        "  device = torch.device(\"cpu\")    # GPU가 없다면/GPU를 이용할 수 없다면 파이토치에게 CPU(\"cpu\") 사용하라고 말해줘"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukdoulEu2hoI",
        "outputId": "559cd7fd-9d03-473e-af6c-6d1feb1db0ea"
      },
      "source": [
        "import pandas as pd # tsv파일 열기 위한 라이브러리\n",
        "\n",
        "# Train(훈련) / Dev(검증) / Test(테스트) dataset\n",
        "dataset_train = pd.read_csv(\"/content/drive/MyDrive/NLP/NIKL_CoLA_train.tsv\", delimiter = '\\t', header=None, names = ['sentence_source_train', 'label_train', 'label_notes', 'sentence_train'])\n",
        "dataset_dev = pd.read_csv(\"/content/drive/MyDrive/NLP/NIKL_CoLA_dev.tsv\", delimiter = '\\t', header = None, names = ['sentence_source_dev', 'label_dev', 'lable_notes_dev', 'sentence_dev'])\n",
        "dataset_test = pd.read_csv(\"/content/drive/MyDrive/NLP/NIKL_CoLA_test.tsv\", delimiter = '\\t', header = None, names = ['index', 'sentence_test'])\n",
        "\n",
        "# 문장 개수 확인\n",
        "print(\"Number of training sentence: {:,}\\n\".format(dataset_train.shape[0]))\n",
        "print(\"Number of dev sentence: {:,}\\n\".format(dataset_dev.shape[0]))\n",
        "print(\"Number of test sentence: {:,}\\n\".format(dataset_test.shape[0]))\n",
        "\n",
        "# 랜덤으로 10개 문장 확인\n",
        "# dataset_train.sample(10)\n",
        "# dataset_dev.sample(10)\n",
        "# dataset_test.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentence: 15,877\n",
            "\n",
            "Number of dev sentence: 2,033\n",
            "\n",
            "Number of test sentence: 1,061\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMCwl9epHfn"
      },
      "source": [
        "### dataset_train & dataset_dev 테이블 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llCK3KmE2nR9",
        "outputId": "be5557b5-2fa9-41c3-de2d-2920a932d3c5"
      },
      "source": [
        "# 데이터 전처리\n",
        "import numpy as np\n",
        "\n",
        "# Train 데이터 list화\n",
        "sentences_train = dataset_train.sentence_train.values\n",
        "labels_train = dataset_train.label_train.values\n",
        "sentences_train = sentences_train[1:]\n",
        "labels_train = labels_train[1:]\n",
        "labels_train = labels_train.astype(np.int64) # 라벨 정수화\n",
        "print(\"Train_sentences: \", sentences_train)\n",
        "print(\"Train_labels: \", labels_train)\n",
        "\n",
        "# Dev 데이터 list화\n",
        "sentences_dev = dataset_dev.sentence_dev.values\n",
        "labels_dev = dataset_dev.label_dev.values\n",
        "sentences_dev = sentences_dev[1:]\n",
        "labels_dev = labels_dev[1:]\n",
        "labels_dev = labels_dev.astype(np.int64) # 라벨 정수화\n",
        "print(\"Dev_sentences: \", sentences_dev)\n",
        "print(\"Dev_labels: \", labels_dev)\n",
        "\n",
        "# Test 데이터 list화\n",
        "sentences_test = dataset_test.sentence_test.values\n",
        "index_test = dataset_test.index.values\n",
        "sentences_test = sentences_test[1:]\n",
        "index_test = index_test[1:]\n",
        "index_test = index_test.astype(np.int64) # 라벨 정수화\n",
        "print(\"Test_sentences: \", sentences_test)\n",
        "print(\"Test_index: \", index_test)\n",
        "\n",
        "# Train / Dev / Test 데이터 셋 list화\n",
        "dataset_train = dataset_train.values[1:]\n",
        "dataset_dev = dataset_dev.values[1:]\n",
        "dataset_test = dataset_test.values[1:]\n",
        "\n",
        "print(dataset_train)\n",
        "print(dataset_dev)\n",
        "print(dataset_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_sentences:  ['높은 달이 떴다.' '달이 뜸이 높았다.' '실없는 사람이 까불까불한다.' ...\n",
            " '선생님이 순희에게 책을 읽게 하시나 순희는 책을 읽지 않는다.' '선생님이 순희에게 책을 읽히시나 순희는 책을 읽지 않는다'\n",
            " '그의 부주의로 말미암아 사건이 터졌다.']\n",
            "Train_labels:  [1 0 1 ... 1 0 1]\n",
            "Dev_sentences:  ['실없는 사람이 까불한다.' '순희에게는 아무리 좋은 옷도 어울리지 않는다.' '사람은 언제나 젊는 수는 없다.' ...\n",
            " '밤새 그 술을 다 먹었는 것이다.' '학교에서 철수는 놀았고, 순이는 공부했다.' '그의 부주의에 말미암아 사건이 터졌다.']\n",
            "Dev_labels:  [0 1 0 ... 0 1 0]\n",
            "Test_sentences:  ['나는 철수에게 공을 던져다 주었다.' '먹은 것을 다 소화시켜야 한다.' '그가 노래를 부르고는 내가 피아노를 쳤다.' ...\n",
            " '그는 나를 바보 여긴다.' '수호는 모든 일에 전혀 무감각하다.' '나는 할아버지가 제일 무서우시다.']\n",
            "Test_index:  [   1    2    3 ... 1058 1059 1060]\n",
            "[['T00001' '1' nan '높은 달이 떴다.']\n",
            " ['T00001' '0' '*' '달이 뜸이 높았다.']\n",
            " ['T00002' '1' nan '실없는 사람이 까불까불한다.']\n",
            " ...\n",
            " ['T09999' '1' nan '선생님이 순희에게 책을 읽게 하시나 순희는 책을 읽지 않는다.']\n",
            " ['T09999' '0' '*' '선생님이 순희에게 책을 읽히시나 순희는 책을 읽지 않는다']\n",
            " ['T10000' '1' nan '그의 부주의로 말미암아 사건이 터졌다.']]\n",
            "[['T00002' '0' '*' '실없는 사람이 까불한다.']\n",
            " ['T00029' '1' nan '순희에게는 아무리 좋은 옷도 어울리지 않는다.']\n",
            " ['T00033' '0' '*' '사람은 언제나 젊는 수는 없다.']\n",
            " ...\n",
            " ['T09994' '0' '*' '밤새 그 술을 다 먹었는 것이다.']\n",
            " ['T09997' '1' nan '학교에서 철수는 놀았고, 순이는 공부했다.']\n",
            " ['T10000' '0' '*' '그의 부주의에 말미암아 사건이 터졌다.']]\n",
            "[['0' '나는 철수에게 공을 던져다 주었다.']\n",
            " ['1' '먹은 것을 다 소화시켜야 한다.']\n",
            " ['2' '그가 노래를 부르고는 내가 피아노를 쳤다.']\n",
            " ...\n",
            " ['1057' '그는 나를 바보 여긴다.']\n",
            " ['1058' '수호는 모든 일에 전혀 무감각하다.']\n",
            " ['1059' '나는 할아버지가 제일 무서우시다.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XU4Er400Fc"
      },
      "source": [
        "### SKT-Kobert 인스톨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m8C1S64orDf",
        "outputId": "fa60ccfb-a36f-40c4-8c0f-77f315af5e45"
      },
      "source": [
        "!pip install kobert-transformers\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "#KoBert\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kobert-transformers in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (4.12.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kobert-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (3.3.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.0.46)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.0.19)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5,>=3->kobert-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=3->kobert-transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.15.0)\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-6a24llxm/kobert-tokenizer_4f89239d73014639b9940ca4e238d397\n",
            "  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-6a24llxm/kobert-tokenizer_4f89239d73014639b9940ca4e238d397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u4a3A5q1DMP"
      },
      "source": [
        "### 데이터 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYb3wKMF2p2y",
        "outputId": "4964d555-9f2d-4434-d731-fd13e84d1aca"
      },
      "source": [
        "print(\"Train_Original: \", sentences_train[0])\n",
        "print(\"Train_Tokenized: \", tokenizer.tokenize(sentences_train[0]))\n",
        "print(\"Train_Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))\n",
        "\n",
        "print(\"Dev_Original: \", sentences_dev[0])\n",
        "print(\"Dev_Tokenized: \", tokenizer.tokenize(sentences_dev[0]))\n",
        "print(\"Dev_Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_dev[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Original:  높은 달이 떴다.\n",
            "Train_Tokenized:  ['▁높은', '▁달', '이', '▁', '떴', '다', '.']\n",
            "Train_Token IDs:  [1520, 1597, 7096, 517, 5974, 5782, 54]\n",
            "Dev_Original:  실없는 사람이 까불한다.\n",
            "Dev_Tokenized:  ['▁실', '없는', '▁사람이', '▁', '까', '불', '한다', '.']\n",
            "Dev_Token IDs:  [3036, 6882, 2589, 517, 5591, 6424, 7831, 54]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2smwi0Roh1h"
      },
      "source": [
        "dataset_train의 encoded_dict\n",
        "\n",
        "dataset_dev의 encoded_dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "dd-Hd7GEt4Dp",
        "outputId": "90ce80e4-fd7b-41ff-c9ec-7a91e6f54baa"
      },
      "source": [
        "# Train_data_Tokenize\n",
        "# 모든 문장을 토크나이즈 한 후 토큰들을 그것들의 단어 ID에 대응·매치시키는 작업\n",
        "\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# 모든 문장에 대하여\n",
        "for sent in sentences_train:\n",
        "    # `encode_plus`는:\n",
        "    #   (1) 문장을 토크나이저.\n",
        "    #   (2) [CLS]를 모든 문장의 가장 앞에 삽입.\n",
        "    #   (3) [SEP]을 모든 문장의 가장 뒤에 삽입.\n",
        "    #       CLS, SEP는 토큰 임베딩 분야의 특수 토큰으로,\n",
        "    #       CLS는 special CLaSsification token, SEP은 sepcial SEParator token을 의미\n",
        "    #   (4) 토큰들을 그들의 단어 아이디와 매치시킴.\n",
        "    #   (5) 문장의 길이는 'max_length' 수치에 맞게 늘려주거나 줄여줌.\n",
        "    #       Pad: 특정 형상의 배열로 변형할 때 빈자리를 0으로 채워준다는 의미\n",
        "    #   (6) [PAD] 토큰을 위한 attention mask 생성\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                         # 인코딩할 문장 자리 / 문장을 인코딩\n",
        "                        add_special_tokens = True,    # 특수 토큰 [CLS]와 [SEP] 추가\n",
        "                        max_length = 64,              # max_length에 맞게 모든 문장 패딩 & 축소\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True, # Attention Mask 구축 / 자료 구조는 tensor 형태\n",
        "                                                      # Attention Mask는 단어 배치와 동일하게 \"1\" 생성 \n",
        "                        return_tensors = 'pt',        # 인코딩된 문장을 pytorch 텐서 형태로 변경\n",
        "                                                      # tensorflow를 사용하고 있다면 return_tensors = 'tf'라고 씀\n",
        "                   )\n",
        "\n",
        "    # 인코딩된 문장들 List[input_ids_train]에 넣기 but input_ids_train은 이미\n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # Attention mask 인자들 List[attention_masks_train]에 넣기 (simply differentiates padding from non-padding).\n",
        "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids_train = torch.cat(input_ids_train, dim=0) # dim은 축·차원의 수 axis0부터 시작, dim=0는 축 1개 or 1차원\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "# print(\"Train_labels_array: \", labels_train)\n",
        "labels_train = torch.tensor(labels_train)\n",
        "\n",
        "\n",
        "# Train 데이터의 문장과 ID 출력. (인코딩이 잘 됐는지 확인하는 작업)\n",
        "print('Train_Original: ', sentences_train[0]) # 1차원\n",
        "print('Train_Token IDs: {}, \\nTrain_input_ids_shape: {}, \\nTrain_input_ids_dim: {}'.format(input_ids_train, input_ids_train.shape, input_ids_train.ndim))\n",
        "print('Train_labels: {}, \\nTrain_labels_shape: {}, \\nTrain_labels_dim: {}'.format(labels_train, labels_train.shape, labels_train.ndim))\n",
        "\n",
        "# Dev_data_Tokenize\n",
        "# 모든 문장을 토크나이즈 한 후 토큰들을 그것들의 단어 ID에 대응·매치시키는 작업\n",
        "input_ids_dev = []\n",
        "attention_masks_dev = []\n",
        "\n",
        "# 위와 동일하게 모든 문장에 encode_plus 적용\n",
        "for sent in sentences_dev:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "    \n",
        "    # encode_dict로 인코딩된 문장을 input_ids_dev 리스트에 추가   \n",
        "    input_ids_dev.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # econde_dict의 어텐션마스크를 attention mask_dev 리스트에 추가 (simply differentiates padding from non-padding).\n",
        "    attention_masks_dev.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "# 리스트를 텐서 형태로 변경\n",
        "input_ids_dev = torch.cat(input_ids_dev, dim=0)\n",
        "attention_masks_dev = torch.cat(attention_masks_dev, dim=0)\n",
        "labels_dev = torch.tensor(labels_dev)\n",
        "\n",
        "# 0번째 문장, 토큰, 라벨 아이디 출력\n",
        "print('Dev_Original: ', sentences_dev[0]) # 1차원\n",
        "print('Dev_Token IDs: {}, \\nDev_input_ids_shape: {}, \\nDev_input_ids_dim: {}'.format(input_ids_dev[0], input_ids_dev.shape, input_ids_dev.ndim))\n",
        "print('Dev_labels: {}, \\nDev_labels_shape: {}, \\nDev_labels_dim: {}'.format(labels_dev, labels_dev.shape, labels_dev.ndim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bdb41c2b11a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 모든 문장에 대하여\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# `encode_plus`는:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#   (1) 문장을 토크나이저.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sentences_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqOjz3cc3XBn",
        "outputId": "4c54d639-10a7-43dc-e36e-cb67ca410fb2"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# TensorDataset()은 텐서를 감싸는 (wrapping) Dataset으로, 길이와 인덱싱 방식을 정의\n",
        "# Dataset을 상속한 클래스로, 학습데이터·독립변수X(input_ids_train, attention_mask_train)와 레이블·종속변수Y(labels_train)를 묶어 놓는 컨테이너\n",
        "# TensorDataset()을 DataLoader에 전달하면, 반복문(for문)에서 데이터의 일부분만 간단히 추출할 수 있다.\n",
        "# TensorDataset()은 텐서만 전달 가능하며, Variable은 전달 불가.\n",
        "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dev_dataset = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "\n",
        "# print(train_dataset[input_ids_train]) \n",
        "\n",
        "# 각 세트의 샘플 문장 개수 확인 및 train_size/dev_size 변수에 저장\n",
        "print(len(train_dataset))\n",
        "print(len(dev_dataset))\n",
        "train_size = int(len(train_dataset))\n",
        "dev_size = int(len(dev_dataset))\n",
        "\n",
        "# 트레이닝 데이터 & 검증 데이터 크기 다시 한 번 확인\n",
        "print(\"Number of train sentence: {:,}\".format(train_size))\n",
        "print(\"Number of dev sentence: {:,}\".format(dev_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15876\n",
            "2032\n",
            "Number of train sentence: 15,876\n",
            "Number of dev sentence: 2,032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuzp4sc7VV7",
        "outputId": "a9240a00-22d9-4a4e-fd08-e6454432e541"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# DataLoader는 데이터를 학습시키기 위해 batch size를 알아야 하기 때문에, batch size를 설정해줄 것.\n",
        "# Fine-tuning BERT를 만들기 위해, batch size를 16 또는 32을 추천\n",
        "batch_size = 32\n",
        "\n",
        "# Train Dataloader 생성\n",
        "train_dataloader = DataLoader(\n",
        "              train_dataset, # Train samples.\n",
        "              sampler = RandomSampler(train_dataset),\n",
        "              batch_size = batch_size)\n",
        "\n",
        "# Dev Dataloader 생성\n",
        "dev_dataloader = DataLoader(\n",
        "              dev_dataset, # Dev samples.\n",
        "              sampler = RandomSampler(dev_dataset),\n",
        "              batch_size = batch_size)\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(dev_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "497\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tn1Vd0N7nHZ",
        "outputId": "8177a651-19ca-49b8-c5b5-d3087f0ca970"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# BertForSequenceClassification 설치\n",
        "# 가장 위 레이어에 단일 linear classification 레이어를 가진, 사전 학습된 BERT 모델\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'skt/kobert-base-v1',\n",
        "    num_labels = 2, # 레이블의 개수는 2진분류가 디폴트.\n",
        "                    # 하지만 멀티 클래스 태스크를 증가시킬 수 있다(?)\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Pytorch에게 이 모델을 GPU에서 사용하라고 요청\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exUI-o-b_XRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba16b758-e1c3-408b-ae80-ae648c7f8324"
      },
      "source": [
        "# 튜플들의 리스트 형태로 모델의 모든 파라미터들 추출\n",
        "\n",
        "params = list(model.named_parameters())\n",
        "print('The BERT model has {:} different named paraeters.\\n'.format(len(params)))\n",
        "\n",
        "print('===== Embedding Layer =====\\n')\n",
        "\n",
        "for p in params [0:5]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params [5:21]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params [-4:]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named paraeters.\n",
            "\n",
            "===== Embedding Layer =====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                   (8002, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Ct1jMS8vJw"
      },
      "source": [
        "# 참고: AdamW은 huggingface 라이브러리에 있는 클래스. (PyTorch와 대조적으로)\n",
        "# 아마도 W는 \"Weight Decay fix\"를 의미하는 것으로 추정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5,   # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyItV69M9qPl"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# 학습 epochs 설정. 글쓴이는 2~4 추천\n",
        "# 일단 4로 해보고, 오버 피팅되면 조절\n",
        "epochs = 4\n",
        "\n",
        "# 학습 횟수·단계 설정: [batch의 개수] x [epochs의 개수]. (batch size ≠ batch의 개수)\n",
        "# ※학습 샘플 수와 같지 않음\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Learning Rate 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipaOG-MP-jM3"
      },
      "source": [
        "# 예측 대비 레이블의 정확성 계산을 위한 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "  # pred_flat = torch.argmax(preds, axis=0).flatten()\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6u-AXG__dcc"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  '''\n",
        "  Takes a time in seconds and returns a string hh:mm:ss\n",
        "  '''\n",
        "  # 1초 단위로 반올림\n",
        "  elapsed_rounded = int(round((elapsed))) \n",
        "\n",
        "  # 시간형태: hh:mm:ss\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-H8_H4ST4J_"
      },
      "source": [
        "### Dev_data_Tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQZ28klAM2K",
        "outputId": "9a158abc-544e-434c-88ac-340e99e63dfa"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible. 하지만 42는 큰 의미 없는 수\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val) # 생성된 난수 중 씨드값 42의 수 출력(고정)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 학습값 손실, 검증값 손실, 검증데이터 정확성, 시간 등 여러 측정 상태 저장 및 출력\n",
        "training_stats = []\n",
        "\n",
        "# 전체 학습 시간 측정\n",
        "total_t0 = time.time()\n",
        "\n",
        "# 매 epoch에 대해서...\n",
        "for epoch_i in range(0, epochs): # ∵epochs = 4\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # 학습 데이터셋에 대한 1회차 실행\n",
        "\n",
        "    print('')\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # epoch 도는데 걸리는 시간 측정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 1 epoch에 대한 총 학습값 손실 0으로 리셋\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # 모델(model = BertForSequenceClassification.from_pretrained)을 트레이닝 모드에 넣음.\n",
        "    # Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # print(\"step: {}, batch: {}\".format(step, batch))\n",
        "\n",
        "        # 40 배치씩 결과 출력\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Train_dataloader의 트레이닝 batch 해체 분석. \n",
        "        # batch를 해체시킬 때, 각 tensor를 'to' 메소드를 사용하는 GPU(device = torch.device(\"cuda\"))에 복사\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # b_input_ids: 2차원, b_labels: 1차원\n",
        "\n",
        "        # 항상 이전에 계산된 gradients들은, backward pass를 수행하기 전에 초기화하여 0으로 만들어 줘야함\n",
        "        # PyTorch는 이것을 자동으로 해주지 않음.\n",
        "        # 왜냐하면 RNNs을 학습시키는 동안에 gradients를 계산하는 것이 편리하기 때문에 \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # 전방 전달(forward pass) 수행 (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "\n",
        "        '''\n",
        "        전방 전달(forward pass)은 입력부터 출력까지 값을 계산한다.\n",
        "        그리고 나서 후방 전달(backward pass)은 역전파(back propagation)을 수행하는데, \n",
        "        이는 끝에서 시작해서 반복적으로 연쇄 법칙을 적용해 회로 입력에 대한 모든 길에서\n",
        "        그라디언트 값을 계산한다. 그라디언트 값은 회로를 통해 거꾸로 흐르는 것으로 볼 수 있다.\n",
        "\n",
        "        순전파(forwards propagation)은 뉴럴 네트워크의 그래프를 계산하기 위해서\n",
        "        중간 변수들을 순서대로 계산하고 저장한다. 즉, 입력층부터 시작해서 출력층까지 처리한다.\n",
        "        역전파(back propagation)은 중간 변수와 파라미터에 대한 그래디언트(gradient)를\n",
        "        반대 방향으로 계산하고 저장한다.\n",
        "        '''\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss = loss.float()\n",
        "        # print(\"loss:\", loss) # loss값 확인\n",
        "\n",
        "        # 모든 batch에 대한 학습 손실값을 축적\n",
        "        # 그래서 우리는 마지막에 평균 손실값을 구할 수 있다.\n",
        "        # 'loss'는 단일 값을 포함한 Tensor. \n",
        "        # '.item()'함수는 tensor로부터 Python 값을 리턴.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # gradients를 계산하기 위해 loss에 대해 후방 전달(backward pass) 수행\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Development\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Development...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "            logits = outputs[0]\n",
        "            logits = logits.float()\n",
        "\n",
        "        # Accumulate the development loss.\n",
        "        total_eval_loss += logits.item()\n",
        "\n",
        "        dev_logits = outputs[1]\n",
        "        # dev_logits: 2차원, b_labels: 1차원\n",
        "\n",
        "        # (log_)softmax 함수는 tensor 형태로 들어가야함\n",
        "        # dev_logits = F.log_softmax(dev_logits, dim=1)\n",
        "        # print(\"DIM_dev_logits: {}, dev_logits: {}\".format(dev_logits.ndim, dev_logits))\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        # argmax 함수는 numpy 형태로 들어가야함\n",
        "        dev_logits = dev_logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(dev_logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this development run.\n",
        "    avg_dev_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_dev_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_dev_loss = total_eval_loss / len(dev_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    development_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Development Loss: {0:.2f}\".format(avg_dev_loss))\n",
        "    print(\"  Development took: {:}\".format(development_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Dev. Loss': avg_dev_loss,\n",
        "            'Dev. Accur.': avg_dev_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Development Time': development_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    497.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    497.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    497.    Elapsed: 0:01:19.\n",
            "  Batch   160  of    497.    Elapsed: 0:01:46.\n",
            "  Batch   200  of    497.    Elapsed: 0:02:13.\n",
            "  Batch   240  of    497.    Elapsed: 0:02:40.\n",
            "  Batch   280  of    497.    Elapsed: 0:03:06.\n",
            "  Batch   320  of    497.    Elapsed: 0:03:33.\n",
            "  Batch   360  of    497.    Elapsed: 0:04:00.\n",
            "  Batch   400  of    497.    Elapsed: 0:04:27.\n",
            "  Batch   440  of    497.    Elapsed: 0:04:53.\n",
            "  Batch   480  of    497.    Elapsed: 0:05:20.\n",
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epoch took: 0:05:31\n",
            "\n",
            "Running Development...\n",
            "  Accuracy: 0.62\n",
            "  Development Loss: 0.64\n",
            "  Development took: 0:00:14\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    497.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    497.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    497.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    497.    Elapsed: 0:01:47.\n",
            "  Batch   200  of    497.    Elapsed: 0:02:14.\n",
            "  Batch   240  of    497.    Elapsed: 0:02:40.\n",
            "  Batch   280  of    497.    Elapsed: 0:03:07.\n",
            "  Batch   320  of    497.    Elapsed: 0:03:34.\n",
            "  Batch   360  of    497.    Elapsed: 0:04:00.\n",
            "  Batch   400  of    497.    Elapsed: 0:04:27.\n",
            "  Batch   440  of    497.    Elapsed: 0:04:54.\n",
            "  Batch   480  of    497.    Elapsed: 0:05:21.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epoch took: 0:05:31\n",
            "\n",
            "Running Development...\n",
            "  Accuracy: 0.65\n",
            "  Development Loss: 0.64\n",
            "  Development took: 0:00:14\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    497.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    497.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    497.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    497.    Elapsed: 0:01:47.\n",
            "  Batch   200  of    497.    Elapsed: 0:02:14.\n",
            "  Batch   240  of    497.    Elapsed: 0:02:40.\n",
            "  Batch   280  of    497.    Elapsed: 0:03:07.\n",
            "  Batch   320  of    497.    Elapsed: 0:03:34.\n",
            "  Batch   360  of    497.    Elapsed: 0:04:00.\n",
            "  Batch   400  of    497.    Elapsed: 0:04:27.\n",
            "  Batch   440  of    497.    Elapsed: 0:04:54.\n",
            "  Batch   480  of    497.    Elapsed: 0:05:21.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epoch took: 0:05:32\n",
            "\n",
            "Running Development...\n",
            "  Accuracy: 0.65\n",
            "  Development Loss: 0.68\n",
            "  Development took: 0:00:14\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    497.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    497.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    497.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    497.    Elapsed: 0:01:47.\n",
            "  Batch   200  of    497.    Elapsed: 0:02:14.\n",
            "  Batch   240  of    497.    Elapsed: 0:02:40.\n",
            "  Batch   280  of    497.    Elapsed: 0:03:07.\n",
            "  Batch   320  of    497.    Elapsed: 0:03:34.\n",
            "  Batch   360  of    497.    Elapsed: 0:04:01.\n",
            "  Batch   400  of    497.    Elapsed: 0:04:27.\n",
            "  Batch   440  of    497.    Elapsed: 0:04:54.\n",
            "  Batch   480  of    497.    Elapsed: 0:05:21.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:05:32\n",
            "\n",
            "Running Development...\n",
            "  Accuracy: 0.66\n",
            "  Development Loss: 0.75\n",
            "  Development took: 0:00:14\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:23:00 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybJX8-lt-88x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e85af02b-a852-4466-8fca-62ab5e8f53d7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Dev. Loss</th>\n",
              "      <th>Dev. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Development Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.68</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:05:31</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:05:31</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:05:32</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:05:32</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Dev. Loss  Dev. Accur. Training Time Development Time\n",
              "epoch                                                                      \n",
              "1               0.68       0.64         0.62       0:05:31          0:00:14\n",
              "2               0.60       0.64         0.65       0:05:31          0:00:14\n",
              "3               0.51       0.68         0.65       0:05:32          0:00:14\n",
              "4               0.43       0.75         0.66       0:05:32          0:00:14"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdhAzaKIA2Rd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9c79270c-cf05-4989-d0ee-623016d57ed8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# seaborn 사용하여 plot 생성\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# plot 사이즈 & 폰트 사이즈 지정\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Dev. Loss'], 'g-o', label=\"Development\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Development Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKP-Nb6yD9GV"
      },
      "source": [
        "### Test 데이터 검증\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_jOYx9qDrwc"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load the dataset into a pandas dataframe.\n",
        "\n",
        "# # Test 데이터 셋 array화\n",
        "# dataset_dev = pd.read_csv(\"/content/drive/MyDrive/NLP/NIKL_CoLA_dev.tsv\", delimiter = '\\t', header = None, names = ['sentence_source_dev', 'label_dev', 'lable_notes_dev', 'sentence_dev'])\n",
        "# print(dataset_dev)\n",
        "\n",
        "# # 문장 개수 확인\n",
        "# print('Number of test sentences: {:,}\\n'.format(dataset_dev.shape[0]))\n",
        "\n",
        "# # Create sentence and lists\n",
        "# sentences_dev = dataset_dev.sentence_dev.values\n",
        "# sentences_dev = sentences_dev[1:]\n",
        "# labels_dev = dataset_dev.label_dev.values\n",
        "# labels_dev = labels_dev[1:]\n",
        "# labels_dev = labels_dev.astype(np.int64) # 라벨 정수화\n",
        "# print(sentences_dev)\n",
        "\n",
        "\n",
        "# # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "# input_ids_dev = []\n",
        "# attention_masks_dev = []\n",
        "\n",
        "# # For every sentence...\n",
        "# for sent in sentences_dev:\n",
        "#     # `encode_plus` will:\n",
        "#     #   (1) Tokenize the sentence.\n",
        "#     #   (2) Prepend the `[CLS]` token to the start.\n",
        "#     #   (3) Append the `[SEP]` token to the end.\n",
        "#     #   (4) Map tokens to their IDs.\n",
        "#     #   (5) Pad or truncate the sentence to `max_length`\n",
        "#     #   (6) Create attention masks for [PAD] tokens.\n",
        "#     encoded_dict = tokenizer.encode_plus(\n",
        "#                         sent,                      # Sentence to encode.\n",
        "#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "#                         max_length = 64,           # Pad & truncate all sentences.\n",
        "#                         padding = 'max_length',\n",
        "#                         truncation = True,\n",
        "#                         return_attention_mask = True,   # Construct attn. masks.\n",
        "#                         return_tensors = 'pt',     # Return pytorch tensors.\n",
        "#                    )\n",
        "    \n",
        "#     # Add the encoded sentence to the list.    \n",
        "#     input_ids_dev.append(encoded_dict['input_ids'])\n",
        "    \n",
        "#     # And its attention mask (simply differentiates padding from non-padding).\n",
        "#     attention_masks_dev.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# # Convert the lists into tensors.\n",
        "# input_ids_dev = torch.cat(input_ids_dev, dim=0)\n",
        "# attention_masks_dev = torch.cat(attention_masks_dev, dim=0)\n",
        "# labels_dev = torch.Tensor(labels_dev)\n",
        "\n",
        "# print('Dev_Original: ', sentences_dev[0]) # 1차원\n",
        "# print('Dev_Token IDs: {}, \\nDev_input_ids_shape: {}, \\nDev_input_ids_dim: {}'.format(input_ids_dev[0], input_ids_dev.shape, input_ids_dev.ndim))\n",
        "# print('Dev_labels: {}, \\nDev_labels_shape: {}, \\nDev_labels_dim: {}'.format(labels_dev, labels_dev.shape, labels_dev.ndim))\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeRLralHkqOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808c0b09-4bf8-4fbf-8678-10471b36790d"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} dev sentences...'.format(len(input_ids_dev)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  dev_logits = outputs[0]\n",
        "  # print(\"dev_logits: \", dev_logits)\n",
        "  # dev_preds = torch.argmax(torch.nn.functional.log_softmax(dev_logits,dim=1), dim=1)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  dev_logits = dev_logits.to('cpu').numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy().astype(np.int64)\n",
        "  dev_logits = dev_logits.tolist()\n",
        "  label_ids = label_ids.tolist()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(dev_logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "print(\"Predictions: \", predictions)\n",
        "print(\"True_labels: \", true_labels)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,032 dev sentences...\n",
            "Predictions:  [[[-1.4599076509475708, 0.990625262260437], [-1.2279213666915894, 0.8192576766014099], [1.4068405628204346, -1.387860894203186], [-1.6817760467529297, 1.1786209344863892], [-1.1707144975662231, 0.7168563008308411], [1.2575523853302002, -1.1231592893600464], [-0.22775517404079437, -0.16848061978816986], [-1.0576753616333008, 0.6426922082901001], [-1.627734661102295, 1.1230442523956299], [0.5537183284759521, -0.9803716540336609], [0.7563073635101318, -0.9292792081832886], [-1.8366167545318604, 1.34181809425354], [-0.9090119004249573, 0.37342309951782227], [-0.8226344585418701, 0.23106776177883148], [-0.6003010869026184, 0.10473090410232544], [1.3681544065475464, -1.0044609308242798], [-0.6188574433326721, 0.06222949177026749], [0.6464830040931702, -1.0633933544158936], [-0.26846787333488464, -0.25151708722114563], [0.2632990777492523, -0.6695963740348816], [-0.2617894113063812, 0.3484037518501282], [1.3801348209381104, -0.9383382201194763], [-0.4123695194721222, -0.023661941289901733], [-0.08583611249923706, -0.21231065690517426], [-1.2257041931152344, 0.891745388507843], [0.09968219697475433, -0.634853720664978], [-0.11062846332788467, -0.14115837216377258], [-0.8933792114257812, 0.45579248666763306], [0.895706832408905, -0.7899095416069031], [-1.0857452154159546, 0.7194845676422119], [-1.8682701587677002, 1.4268925189971924], [1.3116796016693115, -1.1574630737304688]], [[1.656468152999878, -1.2368550300598145], [-1.5860422849655151, 1.0837043523788452], [-1.22078275680542, 0.8129171133041382], [-1.8371001482009888, 1.3115684986114502], [-1.4615275859832764, 1.1167786121368408], [-0.21949082612991333, -0.25806769728660583], [-0.5821173787117004, 0.19234247505664825], [1.4060752391815186, -1.2120450735092163], [0.7895649075508118, -0.6953481435775757], [-0.08289749175310135, -0.2191539853811264], [1.2415810823440552, -0.8500739336013794], [0.028953704982995987, -0.42451584339141846], [-1.2848739624023438, 0.8922829627990723], [1.539150357246399, -1.1660186052322388], [-0.1678715944290161, -0.15246731042861938], [0.2855418920516968, -0.6771204471588135], [-0.6255006194114685, 0.06960362195968628], [1.6829267740249634, -1.291556477546692], [1.5546067953109741, -1.1744354963302612], [-1.6838418245315552, 1.210759162902832], [0.15725737810134888, -0.5779252648353577], [1.4161404371261597, -0.9555233120918274], [-1.9632683992385864, 1.4014209508895874], [1.5689419507980347, -1.222070574760437], [-1.6547261476516724, 1.21880042552948], [-1.925294280052185, 1.370011329650879], [-1.4631884098052979, 1.0074595212936401], [-0.6404736042022705, 0.1428341567516327], [-1.4046016931533813, 0.9696248769760132], [-1.0544404983520508, 0.6047105193138123], [-1.730429768562317, 1.2343474626541138], [-1.4534159898757935, 0.9035239219665527]], [[-0.11598051339387894, -0.284313827753067], [-1.63689124584198, 1.1259297132492065], [-0.5605834722518921, 0.19782638549804688], [-0.9937710762023926, 0.5728395581245422], [-1.2716670036315918, 0.8929173946380615], [0.8720731139183044, -0.7963604927062988], [0.906004011631012, -0.7189345359802246], [1.335784912109375, -0.9430893063545227], [-1.2330352067947388, 0.7400347590446472], [-1.779622197151184, 1.1705024242401123], [0.34591513872146606, -0.5381842255592346], [-0.9583593606948853, 0.6301589012145996], [-1.1232333183288574, 0.4211964011192322], [-1.116587519645691, 0.6546362042427063], [-0.1421181857585907, -0.2525281310081482], [-0.6697449088096619, 0.33622488379478455], [-1.0328129529953003, 0.6202348470687866], [-1.8655201196670532, 1.244175672531128], [-0.4765903055667877, 0.017596760764718056], [0.3214018940925598, -0.8738102912902832], [-0.020980821922421455, -0.4878084361553192], [-0.15420499444007874, -0.21997423470020294], [-1.8946316242218018, 1.3207486867904663], [1.005250096321106, -0.7992197275161743], [-1.4346858263015747, 1.3379892110824585], [-1.1396465301513672, 1.1443458795547485], [0.7710211277008057, -1.128544569015503], [-1.6184715032577515, 0.9522754549980164], [-1.0648781061172485, 0.6748974919319153], [1.224992275238037, -0.7949034571647644], [-0.035599831491708755, -0.5451880693435669], [1.639313817024231, -1.2909660339355469]], [[1.7252782583236694, -1.2384865283966064], [-1.6304177045822144, 1.0884591341018677], [1.2265713214874268, -0.8462151885032654], [-1.003912329673767, 0.5451523065567017], [-1.240268349647522, 0.7647627592086792], [-1.7287918329238892, 1.1068371534347534], [-0.03636184334754944, -0.4314538240432739], [0.5803611874580383, -0.6438712477684021], [-1.8458002805709839, 1.2949416637420654], [-0.8289377093315125, 0.3040417730808258], [-0.7736430764198303, 0.2675740420818329], [1.27781343460083, -1.1851005554199219], [0.6632097959518433, -0.8434743881225586], [-1.1515679359436035, 0.9119528532028198], [-0.7164575457572937, 0.9512010812759399], [-1.2986184358596802, 0.9050071835517883], [-1.8942415714263916, 1.390854001045227], [-1.97218656539917, 1.3479758501052856], [0.1927717924118042, -0.7285574078559875], [-1.8330273628234863, 1.2688807249069214], [-0.29615476727485657, -0.13382679224014282], [-1.7800607681274414, 1.2866276502609253], [-1.629630446434021, 1.1312891244888306], [1.7321797609329224, -1.227203369140625], [-1.8886650800704956, 1.356452226638794], [1.6265724897384644, -1.2752301692962646], [0.8831475973129272, -1.1103143692016602], [-0.3113853931427002, -0.033813320100307465], [0.3565300703048706, -0.7452330589294434], [-1.3387515544891357, 1.0477800369262695], [-0.9034948348999023, 0.8007478713989258], [-1.2351601123809814, 1.0190318822860718]], [[-1.3989568948745728, 1.0752463340759277], [-1.9310470819473267, 1.4323270320892334], [-1.9233864545822144, 1.4423128366470337], [-0.34889963269233704, -0.18760381639003754], [1.6033897399902344, -1.1199983358383179], [-1.9908607006072998, 1.5282567739486694], [0.18060386180877686, -0.5894871354103088], [-1.4097638130187988, 1.1296215057373047], [-0.9856528639793396, 0.6393386721611023], [-1.7823420763015747, 1.101509928703308], [-1.1994633674621582, 1.1119129657745361], [-0.8305360674858093, 0.324675053358078], [-0.20539948344230652, -0.10321246087551117], [-1.0405685901641846, 0.48871198296546936], [-0.9078478217124939, 0.2994692325592041], [-1.9363181591033936, 1.344164490699768], [-1.5187709331512451, 0.9684048295021057], [-1.8932216167449951, 1.3776051998138428], [-0.7838807702064514, 0.23889046907424927], [-0.6142505407333374, 0.12764526903629303], [-0.7276849746704102, 0.20598481595516205], [-1.1208992004394531, 0.5345084071159363], [-1.6550931930541992, 1.0261856317520142], [1.8476805686950684, -1.2489631175994873], [-1.8535887002944946, 1.512768268585205], [-1.8274286985397339, 1.3556032180786133], [-0.6747809648513794, 0.1417824923992157], [-0.44853395223617554, -0.010206704027950764], [0.5260272026062012, -0.8533975481987], [-1.8477425575256348, 1.3445061445236206], [-1.8415623903274536, 1.3212863206863403], [-1.5867279767990112, 1.3252768516540527]], [[-0.23956464231014252, -0.2489881068468094], [1.5388263463974, -1.210259199142456], [-0.9405385851860046, 0.4658857583999634], [-0.6834915280342102, 0.28951865434646606], [-1.7817788124084473, 1.3001786470413208], [-0.6564692258834839, 0.40049755573272705], [0.9839279651641846, -0.8126965165138245], [1.3703854084014893, -0.6728183031082153], [-1.3628422021865845, 0.9639849066734314], [1.0451304912567139, -0.4035014510154724], [-1.980306625366211, 1.5076686143875122], [0.20312899351119995, -0.6335573792457581], [0.2813027799129486, -0.7045608758926392], [-0.6162850856781006, 0.1724623739719391], [-1.67374849319458, 1.19969642162323], [-1.038558006286621, 0.598016619682312], [0.4653204679489136, -0.9049075841903687], [-1.4859035015106201, 1.1352678537368774], [0.4855782091617584, -0.9585641026496887], [-0.33989089727401733, -0.044747743755578995], [-0.4983249306678772, 0.04985615611076355], [-0.04963207617402077, -0.11195758730173111], [-1.7993643283843994, 1.1838523149490356], [-1.8986358642578125, 1.243606686592102], [-1.0366389751434326, 0.6402714848518372], [-1.9343405961990356, 1.3984793424606323], [0.7043807506561279, -1.0222244262695312], [0.062054917216300964, -0.5062147974967957], [0.6761799454689026, -0.8263350129127502], [-1.7944326400756836, 1.2926799058914185], [-1.4961793422698975, 0.9099969863891602], [-0.8424860835075378, 0.31384509801864624]], [[0.6804373860359192, -0.9808365106582642], [-1.660788893699646, 1.046561360359192], [-1.8655266761779785, 1.3863946199417114], [-1.973797082901001, 1.3689335584640503], [-1.3587645292282104, 1.2231268882751465], [-0.8716042041778564, 0.4059922695159912], [-1.1380581855773926, 0.5383768677711487], [-0.5799658894538879, 0.295133113861084], [-1.8489971160888672, 1.240088701248169], [-1.909732699394226, 1.3795281648635864], [-2.0272536277770996, 1.4475469589233398], [-1.4707285165786743, 1.1798259019851685], [-1.493196725845337, 1.0878840684890747], [-0.6373715400695801, 0.4773971140384674], [-0.7359802722930908, 0.2838749587535858], [-1.9910943508148193, 1.4800060987472534], [-1.3787498474121094, 1.1057665348052979], [-1.9169788360595703, 1.4443374872207642], [-0.9707018733024597, 0.4564667046070099], [-1.4461498260498047, 0.9303712248802185], [-0.8392952680587769, 0.5395983457565308], [0.5930295586585999, -0.6374666690826416], [0.14163242280483246, -0.32489636540412903], [1.2626090049743652, -0.7836593985557556], [-1.9483106136322021, 1.4570289850234985], [-1.3239527940750122, 1.0158535242080688], [-1.9125486612319946, 1.3462382555007935], [0.400022953748703, -0.699613094329834], [-1.3048768043518066, 1.061902642250061], [-1.6883634328842163, 1.034745216369629], [0.40515318512916565, -0.7055283188819885], [0.1741601973772049, -0.6649696826934814]], [[-1.7927459478378296, 1.1509413719177246], [-1.733728051185608, 1.2833852767944336], [-1.960244059562683, 1.4431661367416382], [1.4315067529678345, -1.2268879413604736], [-0.3785233497619629, 0.05242503806948662], [-0.3545899987220764, 0.07558442652225494], [0.11816631257534027, -0.5491900444030762], [-0.8869462013244629, 0.398233562707901], [-0.4861030578613281, 0.014664781279861927], [-1.3079192638397217, 0.7653340101242065], [-1.1141598224639893, 0.904096782207489], [-1.2485313415527344, 0.8580448031425476], [1.674006700515747, -1.1573073863983154], [-0.51474928855896, -0.08878029137849808], [0.3075401186943054, -0.8229357600212097], [-1.4793450832366943, 1.1652346849441528], [-1.8735275268554688, 1.426153540611267], [0.7039675116539001, -0.9152020812034607], [-0.8403593301773071, 0.5908253788948059], [-1.8308533430099487, 1.3227977752685547], [-1.4010429382324219, 0.8520801663398743], [1.8049702644348145, -1.3725777864456177], [-1.3933390378952026, 1.1172627210617065], [-0.43085363507270813, -0.028819343075156212], [-1.8976194858551025, 1.4555047750473022], [-0.7466478943824768, 0.9009637832641602], [0.28052186965942383, -0.705767810344696], [-0.5893915891647339, 0.06898868829011917], [-1.6996632814407349, 1.1730525493621826], [-0.5870040059089661, 0.15504319965839386], [0.7392873167991638, -0.4460033178329468], [-1.180867075920105, 0.7824015617370605]], [[-1.4946461915969849, 1.1362881660461426], [0.7344916462898254, -1.0571542978286743], [-1.6071006059646606, 1.1133208274841309], [-0.22655537724494934, -0.15507526695728302], [-0.3335782587528229, -0.0026645748876035213], [-1.7889686822891235, 1.2394620180130005], [-0.6269229650497437, 0.22521859407424927], [-0.5080134272575378, -0.08575144410133362], [-0.24439053237438202, -0.34899017214775085], [-1.75466787815094, 1.1996943950653076], [-1.9437510967254639, 1.4479212760925293], [-1.9434459209442139, 1.420777440071106], [-0.9285922050476074, 0.47584423422813416], [-0.25313207507133484, -0.1605575829744339], [-0.4708935022354126, 0.21220402419567108], [0.0532485656440258, -0.35879838466644287], [0.8958809971809387, -1.0965485572814941], [-1.2553439140319824, 0.7919059991836548], [1.793991208076477, -1.340449571609497], [-0.504427969455719, -0.06646241992712021], [-1.0669280290603638, 0.5720816850662231], [-1.6537331342697144, 1.122552752494812], [-1.1294152736663818, 0.7628147602081299], [-1.042961597442627, 0.7677624225616455], [-1.8637865781784058, 1.3904379606246948], [-1.9175570011138916, 1.363892674446106], [1.0764726400375366, -1.0399434566497803], [-1.7572611570358276, 1.1695702075958252], [-1.4024274349212646, 1.0345767736434937], [-1.0329954624176025, 0.6664392948150635], [0.6906179189682007, -1.1012763977050781], [1.7555688619613647, -1.3443583250045776]], [[-1.9779561758041382, 1.4632021188735962], [-0.4598531424999237, 0.018037188798189163], [-1.3878587484359741, 0.9732889533042908], [0.46791601181030273, -0.9911800026893616], [-0.2036588042974472, -0.12846651673316956], [-0.46127834916114807, -0.04859413951635361], [-0.5012547373771667, -0.01765342429280281], [-1.9520294666290283, 1.4596600532531738], [-0.4361334443092346, -0.004475175403058529], [0.18711845576763153, -0.6418274641036987], [-0.1867201179265976, -0.21338003873825073], [0.9345349073410034, -0.4438552260398865], [-1.487864375114441, 1.2474348545074463], [-0.3129754364490509, -0.06012283265590668], [-0.49593448638916016, 0.17764812707901], [-0.19927771389484406, -0.11138971894979477], [0.03499453887343407, -0.3463115096092224], [1.5383374691009521, -1.0583477020263672], [-1.7475194931030273, 1.223005771636963], [-0.9597439765930176, 0.5581609010696411], [-1.2517025470733643, 0.8196204304695129], [-1.2101850509643555, 0.8356146812438965], [-1.4426884651184082, 0.9640557169914246], [-1.5866862535476685, 1.1947362422943115], [-1.4996289014816284, 1.1755602359771729], [1.7963283061981201, -1.30617356300354], [-0.2972685396671295, -0.17652437090873718], [-0.09987661242485046, -0.4506057798862457], [-0.3315311670303345, -0.1292426735162735], [0.38370099663734436, -0.6986207365989685], [-0.30951106548309326, -0.09962780773639679], [0.6591390371322632, -0.42587435245513916]], [[-1.193225383758545, 0.8653154373168945], [-0.8966606259346008, 0.5996279716491699], [-1.3396399021148682, 0.7741299867630005], [-0.4409036934375763, 0.020657802000641823], [-0.41809773445129395, 0.0010040018241852522], [1.5741298198699951, -1.2038547992706299], [1.3933466672897339, -0.9401848912239075], [-1.067912220954895, 0.4964563548564911], [1.1399301290512085, -0.9800515174865723], [-1.7742342948913574, 1.293707013130188], [-0.31719961762428284, -0.17862720787525177], [-1.142768144607544, 0.615810215473175], [-0.2232140600681305, -0.27874556183815], [-1.2102491855621338, 0.6322253942489624], [1.4260956048965454, -0.8010854721069336], [-1.7447900772094727, 1.1725411415100098], [-1.7617217302322388, 1.4487605094909668], [-0.6349809765815735, 0.12341152131557465], [-1.141190767288208, 0.688867449760437], [-1.3903841972351074, 1.1227890253067017], [-1.1108416318893433, 0.6981111764907837], [1.3682100772857666, -1.005698561668396], [-1.9181180000305176, 1.4500832557678223], [-1.9514288902282715, 1.2086960077285767], [-0.019058268517255783, -0.43103569746017456], [-1.5181742906570435, 1.0442360639572144], [-1.3985880613327026, 1.0340205430984497], [0.41004955768585205, -0.9699642062187195], [-0.5102856755256653, -0.12768299877643585], [0.39394569396972656, -0.6419841647148132], [-1.9297031164169312, 1.3998339176177979], [-1.6387273073196411, 1.1470645666122437]], [[-1.948373794555664, 1.4021151065826416], [1.101610779762268, -0.7891903519630432], [-1.7899527549743652, 1.259596586227417], [-0.6814124584197998, 0.24375925958156586], [-1.2989587783813477, 0.8135596513748169], [0.6037331819534302, -0.6765486001968384], [-0.058995626866817474, -0.11296334862709045], [-0.8018785715103149, 0.28574255108833313], [-1.2399356365203857, 1.3408468961715698], [-1.1342873573303223, 0.6823018193244934], [0.22636082768440247, -0.36063098907470703], [0.05275239422917366, -0.4435974657535553], [-1.3758169412612915, 1.1040469408035278], [-1.2768502235412598, 0.81697678565979], [1.418656587600708, -1.1704670190811157], [-1.3138296604156494, 0.9654179811477661], [-1.5101385116577148, 1.106651782989502], [-1.1747660636901855, 1.0164557695388794], [1.7575067281723022, -1.2125808000564575], [0.5662683844566345, -0.3879789113998413], [1.6067543029785156, -1.147422194480896], [-0.7288680076599121, 0.18842658400535583], [-1.2521041631698608, 0.8441608548164368], [1.5446151494979858, -1.2403826713562012], [-1.3878873586654663, 0.8449583649635315], [-1.688391089439392, 1.1915243864059448], [-1.3735283613204956, 1.1099237203598022], [-1.2556322813034058, 0.9166328310966492], [-1.745416283607483, 1.160078763961792], [-0.4933711290359497, 0.34585341811180115], [-1.9447276592254639, 1.3538477420806885], [0.36777421832084656, -0.6634459495544434]], [[-0.11212873458862305, -0.4543845057487488], [1.5259546041488647, -1.025637149810791], [-1.8484691381454468, 1.3158767223358154], [1.785294771194458, -1.3830026388168335], [-1.1846308708190918, 1.0385602712631226], [1.4790987968444824, -1.0753507614135742], [-1.5779824256896973, 1.2836861610412598], [0.017059387639164925, -0.2989167869091034], [-1.1245181560516357, 0.8186613917350769], [-1.968424916267395, 1.391486644744873], [-0.8741349577903748, 0.4394751191139221], [0.06873758137226105, -0.6404820680618286], [-1.8806376457214355, 1.445618748664856], [-1.8809545040130615, 1.1953535079956055], [-1.753440499305725, 1.239840030670166], [-0.5432460904121399, 0.04582662507891655], [-1.1317157745361328, 0.7427361607551575], [1.3424650430679321, -1.077860951423645], [-1.6204367876052856, 1.1622791290283203], [1.2529064416885376, -1.4227898120880127], [-0.9033746123313904, 0.47032666206359863], [0.638541042804718, -1.0741795301437378], [1.3662563562393188, -0.8870083689689636], [-0.9727047085762024, 1.0754505395889282], [-0.4337090849876404, -0.18774932622909546], [-0.672692060470581, 0.06466393172740936], [-1.217444896697998, 0.8573171496391296], [-1.094891905784607, 0.5291350483894348], [-0.18970614671707153, -0.3084968626499176], [-0.2383347451686859, -0.29137998819351196], [-0.17950670421123505, -0.396560400724411], [1.0118011236190796, -1.0905100107192993]], [[-0.3788851201534271, -0.11688744276762009], [-1.5864187479019165, 1.3838156461715698], [-0.13877156376838684, -0.2342659831047058], [-1.1882456541061401, 0.8224718570709229], [-1.2422758340835571, 0.7320634722709656], [-1.31156325340271, 1.3209270238876343], [-0.2963240146636963, -0.27711939811706543], [-0.8982723951339722, 0.36590003967285156], [1.3292394876480103, -0.87079918384552], [-1.939712405204773, 1.3849066495895386], [-0.32867151498794556, -0.14176392555236816], [-1.2965127229690552, 0.903408944606781], [-1.460436463356018, 1.0099258422851562], [-2.013314723968506, 1.4399147033691406], [-1.7465777397155762, 1.3252509832382202], [-0.5291792750358582, 0.07568686455488205], [-0.8608678579330444, 0.5088385939598083], [1.5191495418548584, -1.161051630973816], [-1.425405502319336, 1.1093096733093262], [0.41863682866096497, -0.47814345359802246], [-1.3643039464950562, 0.8780599236488342], [-0.24467194080352783, -0.2823857367038727], [1.5869390964508057, -1.2966609001159668], [-0.4340863823890686, 0.5183736681938171], [0.07514659315347672, -0.58115154504776], [-0.865251898765564, 0.3446870744228363], [-1.9411967992782593, 1.2957944869995117], [-1.648343563079834, 1.0884718894958496], [-1.3379327058792114, 0.8611664772033691], [0.2309238165616989, -0.7103267312049866], [1.8940362930297852, -1.3515148162841797], [-0.6117143034934998, 0.2833191156387329]], [[1.7129243612289429, -1.252475619316101], [1.3854029178619385, -1.3195682764053345], [-0.11847800761461258, -0.2808554470539093], [-1.147792100906372, 0.7796908617019653], [-0.3265303075313568, 0.02431240864098072], [-1.656700849533081, 0.968017041683197], [-1.712746262550354, 1.4401825666427612], [-0.4255959987640381, 0.003960823640227318], [0.42758411169052124, -0.8369957208633423], [-1.9755713939666748, 1.2581080198287964], [1.1506538391113281, -0.674354612827301], [-2.0122170448303223, 1.4488625526428223], [-1.0178593397140503, 1.0070255994796753], [-0.3895023465156555, -0.2040204554796219], [-1.3098969459533691, 0.7135719060897827], [-0.6488442420959473, 0.13358087837696075], [-0.8132222890853882, 0.3250015377998352], [0.08150430023670197, -0.5621060132980347], [-0.18916699290275574, -0.08348561823368073], [-0.4415639340877533, 0.009142525494098663], [0.1510443538427353, 0.4622994661331177], [-1.8825644254684448, 1.4200546741485596], [-1.3242615461349487, 0.9995984435081482], [0.022223681211471558, -0.540755569934845], [0.8257067203521729, -1.271451711654663], [-1.9780467748641968, 1.3084434270858765], [1.5287675857543945, -1.06735360622406], [-1.4961642026901245, 1.0494718551635742], [-0.9681141376495361, 0.2744537889957428], [-1.794641375541687, 1.3137887716293335], [-1.5240191221237183, 1.0691560506820679], [-1.1411361694335938, 0.6603913903236389]], [[1.196913719177246, -0.9211465120315552], [0.4460107982158661, -0.8587489724159241], [0.4330146610736847, -0.8703660368919373], [-0.8131225109100342, 0.30889713764190674], [-1.3308438062667847, 0.807610034942627], [-0.5228317379951477, 0.04559457674622536], [-1.3940428495407104, 0.8889827728271484], [-1.7029614448547363, 1.389666199684143], [-1.7072962522506714, 1.4733505249023438], [0.8725218176841736, -1.2531181573867798], [-0.9336044192314148, 0.5239472389221191], [-1.429840326309204, 0.9206916093826294], [-1.7173725366592407, 1.1781622171401978], [1.8283659219741821, -1.3612265586853027], [-1.2477139234542847, 0.7953420281410217], [-1.5989099740982056, 1.0788540840148926], [1.5584614276885986, -0.9975309371948242], [1.755741000175476, -1.2365559339523315], [-0.42895710468292236, -0.05617574229836464], [-1.0471423864364624, 0.9964066743850708], [0.26294758915901184, -0.8944897055625916], [-0.11665218323469162, 0.4697107970714569], [-1.952162504196167, 1.338625431060791], [-1.7334259748458862, 1.207033634185791], [-0.9850950241088867, 0.6260685920715332], [0.9374182224273682, -1.1235651969909668], [0.529600203037262, -0.47585898637771606], [-1.6040124893188477, 1.0920367240905762], [1.7891464233398438, -1.3577440977096558], [-0.7721812725067139, 0.36536285281181335], [1.200692892074585, -1.1654012203216553], [-1.686400055885315, 1.142359972000122]], [[-1.645620584487915, 1.1914573907852173], [0.5348929166793823, -0.8942397236824036], [-1.6833114624023438, 1.183867335319519], [1.3245097398757935, -1.0032094717025757], [-1.4405760765075684, 1.2676986455917358], [0.10607820004224777, -0.6150447726249695], [-1.5843056440353394, 0.8585383892059326], [-1.2539373636245728, 0.6436221599578857], [1.4351661205291748, -1.226091980934143], [-1.2481738328933716, 1.057096242904663], [-1.9400486946105957, 1.3314461708068848], [-1.6318861246109009, 1.061376690864563], [-1.6204391717910767, 1.151215672492981], [0.5421215295791626, -0.2887294888496399], [-1.1375763416290283, 0.8549920916557312], [-1.4254558086395264, 1.1188628673553467], [-0.5020340085029602, 0.048528656363487244], [-0.2872283160686493, -0.09932580590248108], [-0.02190067246556282, -0.5386255383491516], [-1.784062147140503, 1.277793526649475], [-1.3745218515396118, 0.8796558380126953], [-1.6680357456207275, 1.14309823513031], [-1.7970240116119385, 1.1258445978164673], [0.614395260810852, -0.5780557990074158], [-0.3032194972038269, 0.28973034024238586], [-1.678020715713501, 1.1435673236846924], [-1.1630864143371582, 0.7239195704460144], [-1.231920838356018, 0.7790724039077759], [0.9553448557853699, -1.0226421356201172], [-1.164626121520996, 0.5662767887115479], [-0.4973016381263733, 0.06273344904184341], [1.861610770225525, -1.3578417301177979]], [[-1.151063323020935, 0.8174694180488586], [-1.304732322692871, 0.825002133846283], [0.6039314866065979, -0.8761508464813232], [0.009005915373563766, -0.43840736150741577], [0.1833856701850891, -0.6552378535270691], [1.5353657007217407, -1.1998876333236694], [-0.22220227122306824, 0.007408449426293373], [-0.7863949537277222, 0.47651976346969604], [-1.644248604774475, 1.0715776681900024], [-1.4244470596313477, 0.8630443215370178], [-1.7674251794815063, 1.269386649131775], [-2.0432584285736084, 1.4284563064575195], [-1.491719126701355, 0.9778168201446533], [-0.2921616733074188, -0.16048608720302582], [-1.9117558002471924, 1.407326102256775], [1.0164145231246948, -0.8639443516731262], [0.25515952706336975, -0.727514386177063], [-1.3468425273895264, 0.8620362877845764], [-0.84486323595047, 0.3607373535633087], [-0.373169869184494, -0.20606271922588348], [0.019473468884825706, -0.34842047095298767], [1.637831449508667, -1.226171851158142], [-1.85093092918396, 1.4032597541809082], [1.513363242149353, -1.3537776470184326], [-0.9858254194259644, 0.5875577330589294], [-1.8719557523727417, 1.3922069072723389], [1.1450330018997192, -0.7000301480293274], [-1.7229915857315063, 1.2128952741622925], [-0.49387127161026, 0.1277712881565094], [-0.6438559293746948, 0.09655030071735382], [-0.41543325781822205, -0.06492792069911957], [1.7623637914657593, -1.2725032567977905]], [[-0.7089276909828186, 0.13754533231258392], [-1.3147385120391846, 0.7285813689231873], [-0.6905062794685364, 0.1889815777540207], [-0.7096720933914185, 0.44071057438850403], [-0.015194999054074287, -0.2569856643676758], [-1.7804290056228638, 1.4420020580291748], [-1.722590684890747, 1.2776511907577515], [-1.6689174175262451, 1.1789133548736572], [-1.950650930404663, 1.3053566217422485], [-1.8243725299835205, 1.4027023315429688], [-0.7057913541793823, 0.20840542018413544], [-1.2560473680496216, 1.0415326356887817], [-1.6307799816131592, 1.3323659896850586], [1.6285264492034912, -1.2997099161148071], [1.554924488067627, -1.2144341468811035], [-0.875615656375885, 0.3684329688549042], [-0.8905343413352966, 0.49975869059562683], [0.9343281388282776, -0.952712893486023], [-1.3040709495544434, 0.8954249024391174], [-1.8384488821029663, 1.2021933794021606], [-0.44938209652900696, 0.11806974560022354], [1.738718867301941, -1.2476487159729004], [-1.7481985092163086, 1.2274911403656006], [-0.5093663334846497, -0.06513073295354843], [-0.8361415863037109, 0.33468520641326904], [-1.8885141611099243, 1.301497459411621], [-0.45829328894615173, 0.045872800052165985], [-1.8243346214294434, 1.203145146369934], [-0.8357542753219604, 0.3373876214027405], [-1.6280319690704346, 1.2460147142410278], [-0.8055862188339233, 0.3541826903820038], [-1.8019366264343262, 1.1694447994232178]], [[1.136182427406311, -0.8025080561637878], [-1.271863579750061, 0.8813068866729736], [-1.9808034896850586, 1.3915858268737793], [1.7145373821258545, -1.3536090850830078], [1.6982771158218384, -1.35551917552948], [-0.06295661628246307, -0.4334251582622528], [-1.7312920093536377, 1.3136646747589111], [-1.7712455987930298, 1.226836085319519], [-0.4252927601337433, -0.0939098671078682], [-0.9888331294059753, 0.5595635175704956], [-0.606374204158783, 0.17712657153606415], [-0.44727450609207153, -0.0984731912612915], [-0.7485241889953613, 0.34532850980758667], [-1.1601288318634033, 0.5230908393859863], [0.04648461192846298, 0.110159732401371], [-1.7214488983154297, 1.191733479499817], [-1.7460613250732422, 1.2426875829696655], [1.597037434577942, -1.1085925102233887], [-1.1753556728363037, 1.216149926185608], [-1.7630579471588135, 1.3391860723495483], [-0.9695819616317749, 1.2254760265350342], [-1.2330527305603027, 0.7639803290367126], [-1.065327525138855, 0.5132341384887695], [0.06264958530664444, -0.1643061637878418], [-1.9188507795333862, 1.3947679996490479], [-0.2315005213022232, 0.30693262815475464], [-1.867121934890747, 1.2128229141235352], [-0.6936829090118408, 0.518814742565155], [-1.551905870437622, 1.0322589874267578], [1.8673042058944702, -1.3917452096939087], [-1.977928638458252, 1.403515338897705], [0.4266316890716553, -0.7683418989181519]], [[0.47590550780296326, -0.9255226254463196], [1.507265329360962, -1.2459768056869507], [-1.3733493089675903, 0.8319914937019348], [-0.21042518317699432, -0.15676118433475494], [-0.3397331237792969, 0.0043149180710315704], [-1.0361409187316895, 0.6230249404907227], [-0.9158389568328857, 0.4866693317890167], [-1.1321992874145508, 0.5152314901351929], [-1.9348734617233276, 1.412506341934204], [-0.8608044385910034, 0.4735710918903351], [-1.7603307962417603, 1.3748352527618408], [-0.9368237853050232, 0.5087395906448364], [-1.0616618394851685, 0.8334559798240662], [-1.618666410446167, 1.302056908607483], [-0.8203250169754028, 0.4834460914134979], [-1.9632903337478638, 1.4171459674835205], [-1.0806258916854858, 0.6225234270095825], [-0.4403347074985504, 0.005137435160577297], [-1.3959417343139648, 0.8230224847793579], [-1.8305537700653076, 1.3529163599014282], [-0.6784958839416504, 0.2591458857059479], [-1.4074238538742065, 0.9124205708503723], [-1.0265077352523804, 0.4769841730594635], [-1.644349455833435, 1.3277913331985474], [-0.9642297029495239, 0.47934991121292114], [-1.8600389957427979, 1.2289551496505737], [0.07212404161691666, -0.3330727219581604], [1.330317497253418, -1.062785029411316], [-0.5562024712562561, 0.07647399604320526], [-1.498993992805481, 1.1483441591262817], [0.845289945602417, -1.1464921236038208], [0.42321911454200745, -0.8339277505874634]], [[-1.2620902061462402, 0.7993363738059998], [-0.24813269078731537, -0.16199851036071777], [1.5775123834609985, -1.2444733381271362], [1.1412001848220825, -1.0075546503067017], [-1.4859999418258667, 1.3736852407455444], [-1.730387806892395, 1.182985544204712], [-1.3086564540863037, 0.9685790538787842], [0.018190434202551842, -0.43883150815963745], [-0.7995961308479309, 0.19469910860061646], [1.758002519607544, -1.23208749294281], [-0.09867061674594879, -0.28067275881767273], [-0.603853702545166, 0.21395732462406158], [0.4598740041255951, -0.806256890296936], [-1.4520623683929443, 1.0358986854553223], [-0.4979099929332733, 0.018662258982658386], [0.762549638748169, -1.133221983909607], [-1.4322898387908936, 1.0447226762771606], [0.7697820663452148, -1.1122562885284424], [-1.164612889289856, 0.6167730093002319], [1.7445471286773682, -1.3100125789642334], [-1.262644648551941, 0.8962967395782471], [-1.5332454442977905, 1.2146185636520386], [1.225206971168518, -1.036162257194519], [-0.9569902420043945, 0.6571177840232849], [0.5315907597541809, -0.9314387440681458], [-0.2253049910068512, -0.14454369246959686], [-0.3041408956050873, 0.026120873168110847], [-1.2529346942901611, 1.0781558752059937], [0.7066811919212341, -1.170775055885315], [1.1393533945083618, -1.4650558233261108], [-0.6957492828369141, 0.3492876887321472], [-1.2085801362991333, 0.82343989610672]], [[-0.6864551305770874, 0.2292274385690689], [-0.9795194864273071, 0.4914904534816742], [1.4019927978515625, -1.1084563732147217], [-1.0053805112838745, 0.6872453689575195], [0.06510929018259048, 0.5390750169754028], [-1.2724052667617798, 0.8276042938232422], [-1.6481200456619263, 1.2635841369628906], [-1.8738877773284912, 1.3357465267181396], [-1.1001211404800415, 0.6739099025726318], [0.21372026205062866, 0.21632598340511322], [-1.5928738117218018, 1.0568100214004517], [-1.4371525049209595, 0.9534783363342285], [0.19915790855884552, -0.11362462490797043], [-1.9179589748382568, 1.4750111103057861], [-1.812694787979126, 1.327379584312439], [-0.5532151460647583, 0.017170628532767296], [0.5657840371131897, -0.9506258368492126], [0.13310514390468597, -0.6113606691360474], [-1.665771484375, 1.2741196155548096], [-1.3377937078475952, 0.9871206879615784], [1.5392335653305054, -1.1528346538543701], [-1.5646758079528809, 0.9545478224754333], [-0.8409441709518433, 0.4383133351802826], [-0.6050204038619995, 0.19285772740840912], [-0.8953954577445984, 0.9977269768714905], [-1.9950597286224365, 1.337424397468567], [1.3490171432495117, -1.304431676864624], [-0.911565363407135, 0.7074527144432068], [-1.9909641742706299, 1.306402325630188], [1.5439765453338623, -0.9461421370506287], [-1.4026423692703247, 1.1741946935653687], [-1.5416117906570435, 1.1395628452301025]], [[-1.0358432531356812, 0.6153596639633179], [-0.9194538593292236, 0.5167655348777771], [1.4575411081314087, -1.1823852062225342], [-0.7051720023155212, 0.2584621012210846], [0.06480631977319717, -0.5596398711204529], [-0.18089702725410461, -0.38372883200645447], [-0.3746989667415619, -0.22472737729549408], [-0.8793765306472778, 0.46132034063339233], [-0.45533260703086853, 0.1630040556192398], [0.17559446394443512, 0.03490036725997925], [-1.9815857410430908, 1.3673213720321655], [-0.24134346842765808, -0.2541006803512573], [-0.3677735924720764, 0.011302526108920574], [-1.5643781423568726, 1.0476531982421875], [1.5970760583877563, -1.1814990043640137], [-1.4204329252243042, 1.064419150352478], [-0.17253147065639496, -0.3767571747303009], [1.383358359336853, -1.1877325773239136], [0.6411833763122559, -0.9288229942321777], [-0.6520256400108337, 0.09655331075191498], [0.023336291313171387, -0.5825471878051758], [1.463314175605774, -0.9448143243789673], [1.109965205192566, -1.4437408447265625], [0.7660825252532959, -1.0901484489440918], [1.3320772647857666, -1.3811862468719482], [-1.805974006652832, 1.2788041830062866], [1.1073625087738037, -1.0723638534545898], [-0.8988068699836731, 0.4478185176849365], [1.4695404767990112, -1.4195722341537476], [-1.87787663936615, 1.2226701974868774], [-1.7770543098449707, 1.1487274169921875], [0.1480492353439331, -0.6009761095046997]], [[0.6490126252174377, -0.49369239807128906], [-1.1091053485870361, 0.8372743129730225], [1.4436012506484985, -1.2512664794921875], [-0.401075541973114, 0.02128683030605316], [-0.9142965078353882, 0.5350173115730286], [0.6236674785614014, -0.8978092074394226], [-1.6332517862319946, 1.1576429605484009], [0.6966273784637451, -0.9764277935028076], [-1.996681809425354, 1.399812936782837], [-0.046999234706163406, -0.43966156244277954], [-1.4853763580322266, 1.2022485733032227], [0.7204758524894714, -0.18529348075389862], [-1.3852927684783936, 1.2607766389846802], [-0.18112337589263916, -0.25716111063957214], [-1.4945157766342163, 1.1856290102005005], [-1.943150281906128, 1.367173433303833], [1.0751382112503052, -0.969145655632019], [-1.518014907836914, 1.185579538345337], [1.4288748502731323, -1.1620981693267822], [-1.3457305431365967, 1.0121362209320068], [0.25650671124458313, -0.5704787969589233], [-1.279386281967163, 0.9350687265396118], [-0.01509827934205532, -0.4739457964897156], [1.947147250175476, -1.3596729040145874], [-1.4368807077407837, 1.4019261598587036], [0.08719669282436371, -0.3447215259075165], [-0.8957759737968445, 0.3184618651866913], [0.4300355315208435, -0.29765230417251587], [0.7351825833320618, -1.0292671918869019], [0.5947760343551636, -0.9938884377479553], [-0.16590046882629395, -0.16848905384540558], [-1.740480899810791, 1.3005543947219849]], [[-1.8655829429626465, 1.4843387603759766], [-1.6438465118408203, 1.0375639200210571], [0.09551979601383209, -0.5580396056175232], [-1.046085000038147, 0.42235854268074036], [-1.1475228071212769, 0.6856857538223267], [-1.515436053276062, 1.1031955480575562], [1.2572247982025146, -1.136967420578003], [-0.8019430041313171, 0.47175493836402893], [-0.7195957899093628, 0.15762127935886383], [-0.29082968831062317, -0.13993088901042938], [-0.957520604133606, 0.46267104148864746], [-1.4592825174331665, 1.040220856666565], [-1.4465103149414062, 1.008360743522644], [-1.4245134592056274, 0.8696819543838501], [0.5840552449226379, -0.13871052861213684], [-1.8514372110366821, 1.4454097747802734], [0.05699170008301735, -0.3883587121963501], [0.768340528011322, -0.23054563999176025], [-1.5046322345733643, 1.0072269439697266], [-0.37576591968536377, -0.07102028280496597], [-0.16831962764263153, -0.3367275893688202], [-0.382254034280777, 0.026685426011681557], [1.7382856607437134, -1.3143707513809204], [-0.24295639991760254, -0.13761456310749054], [1.465110421180725, -1.1484495401382446], [-1.0060040950775146, 0.5410511493682861], [-0.26692405343055725, 0.48797035217285156], [0.8620113730430603, -1.2901439666748047], [0.7397087812423706, -1.2107031345367432], [0.4260067641735077, -0.8176107406616211], [0.2443271279335022, -0.6684672236442566], [0.7862715125083923, -1.2033065557479858]], [[0.5233359932899475, -0.9268844723701477], [0.711132287979126, -0.9934129118919373], [0.11187252402305603, -0.3975796699523926], [-1.6965217590332031, 1.141060471534729], [-0.5331520438194275, 0.07507092505693436], [-0.7018799185752869, 0.9453977346420288], [0.07650233060121536, -0.5519354343414307], [-0.6560723781585693, 0.14254793524742126], [1.0556461811065674, -1.2000102996826172], [0.8664656281471252, -0.918973982334137], [0.6942211389541626, -0.916090190410614], [1.0664927959442139, -0.9087074995040894], [-1.0397363901138306, 0.5303342938423157], [-0.32969164848327637, 0.08302058279514313], [-0.38509130477905273, -0.012195916846394539], [-0.6147060990333557, 0.16460226476192474], [-0.7922986149787903, 0.46199995279312134], [1.5403250455856323, -1.3472322225570679], [-1.2843892574310303, 0.8780557513237], [-0.7759812474250793, 0.288623571395874], [0.5915782451629639, -0.8900213837623596], [-1.8761029243469238, 1.32108473777771], [1.3376084566116333, -1.45608389377594], [-1.4959392547607422, 1.1719722747802734], [1.8891913890838623, -1.3282757997512817], [-0.620307207107544, 0.2686294615268707], [-0.48959365487098694, 0.10485812276601791], [1.3466330766677856, -1.023967981338501], [-0.21077564358711243, -0.06947094947099686], [-1.4514367580413818, 1.15578031539917], [1.0087131261825562, -0.8515865802764893], [-0.7963929176330566, 0.24031883478164673]], [[-1.2711434364318848, 0.8823802471160889], [1.4907993078231812, -1.3239741325378418], [-0.18342836201190948, -0.040041983127593994], [-1.5925662517547607, 1.3992410898208618], [1.0523889064788818, -0.8684709072113037], [-0.736996591091156, 0.2897367477416992], [-0.903277575969696, 0.5130877494812012], [-1.737931728363037, 1.309869408607483], [-0.0826123058795929, -0.3695334196090698], [-0.19458596408367157, -0.24403318762779236], [-1.6971017122268677, 1.1528159379959106], [-0.9307562112808228, 0.46139976382255554], [1.8608627319335938, -1.1963810920715332], [1.8135199546813965, -1.2944680452346802], [-1.75169837474823, 1.3127691745758057], [-0.018839050084352493, -0.42394399642944336], [0.4502399265766144, -0.907443642616272], [-1.3425394296646118, 0.7988345623016357], [0.8641184568405151, -1.307904601097107], [-1.7309045791625977, 1.2617390155792236], [-1.211644172668457, 0.8782842755317688], [-1.5743871927261353, 1.4674774408340454], [-0.536046028137207, 0.04787776246666908], [-1.0144468545913696, 0.6084005236625671], [0.8152730464935303, -1.1505883932113647], [1.115412712097168, -1.398550271987915], [-1.8234269618988037, 1.346235990524292], [-0.3708958625793457, -0.2110978662967682], [-1.5536450147628784, 0.9460828900337219], [-0.3653123080730438, 0.033872295171022415], [-0.42235881090164185, -0.12310861051082611], [-1.6948968172073364, 1.1395256519317627]], [[0.015853863209486008, -0.5994249582290649], [-0.671924352645874, 0.14266164600849152], [-0.6001434326171875, 0.14973974227905273], [0.07833661884069443, -0.5148435831069946], [1.1141844987869263, -1.2532434463500977], [-1.6330393552780151, 1.3517351150512695], [0.4730057120323181, -0.8395074605941772], [-1.35356605052948, 0.9438562393188477], [-1.3965497016906738, 0.9307612180709839], [-1.8858799934387207, 1.3523046970367432], [1.6332645416259766, -1.15723717212677], [-1.8105442523956299, 1.2928433418273926], [1.0089497566223145, -1.2742966413497925], [-0.7344960570335388, 0.2354520857334137], [-1.114931344985962, 0.5480055212974548], [-1.2316398620605469, 0.7976891994476318], [1.4926832914352417, -0.9025762677192688], [-1.2020941972732544, 0.6664223670959473], [-0.5528985857963562, 0.0807608962059021], [-0.8930610418319702, 0.43245142698287964], [-0.04080614447593689, -0.3209324777126312], [-1.4262950420379639, 0.9191967844963074], [-0.3235054612159729, -0.167308047413826], [1.6296833753585815, -1.1920479536056519], [0.591991662979126, -0.6511197686195374], [1.4381697177886963, -1.1985708475112915], [-0.37015801668167114, -0.2410411536693573], [0.16629073023796082, -0.6152613759040833], [-1.6500585079193115, 1.056667685508728], [-0.7830892205238342, 0.23948489129543304], [0.5475015640258789, -1.0496859550476074], [-0.10026555508375168, -0.5037902593612671]], [[-1.9430201053619385, 1.4351125955581665], [-0.5093193650245667, 0.1032395139336586], [0.12726905941963196, -0.21492809057235718], [-0.10400401800870895, -0.39946967363357544], [-0.40363627672195435, -0.029920311644673347], [1.583237886428833, -1.3120567798614502], [1.3276863098144531, -1.2895424365997314], [-1.5659993886947632, 1.0614418983459473], [-0.3584606647491455, -0.04667059704661369], [-0.7051748633384705, 0.14575298130512238], [-0.04574739933013916, -0.22601766884326935], [-1.9829739332199097, 1.3765183687210083], [0.7492982745170593, -0.9563482403755188], [-0.07963842153549194, -0.09132938832044601], [-0.9533852338790894, 0.5515927672386169], [-0.1664641797542572, -0.325030654668808], [-1.128973364830017, 0.6318326592445374], [-1.8584909439086914, 1.4431815147399902], [-1.7596904039382935, 1.378526210784912], [-1.5075796842575073, 1.325244426727295], [-1.9165897369384766, 1.405703067779541], [0.7793160080909729, -1.0920991897583008], [-1.2711644172668457, 0.9859967231750488], [-1.6826860904693604, 1.2869678735733032], [-1.8453383445739746, 1.368828296661377], [-1.396628737449646, 0.8789469003677368], [1.2320456504821777, -1.352894902229309], [0.24851872026920319, -0.5777043700218201], [-1.6911102533340454, 1.1907175779342651], [-1.8056522607803345, 1.2665213346481323], [0.5756967663764954, -0.5225802659988403], [-1.709899663925171, 1.206531286239624]], [[-1.2498327493667603, 0.7849614024162292], [-1.3085286617279053, 0.5963992476463318], [-0.6506198644638062, 0.06341272592544556], [-1.2222634553909302, 0.6148343086242676], [-0.7520158886909485, 0.26039132475852966], [-1.4501973390579224, 0.9543666243553162], [-0.16282176971435547, -0.37431687116622925], [-0.5700226426124573, -0.024049941450357437], [-0.08605976402759552, -0.23960690200328827], [-1.8710651397705078, 1.3957533836364746], [-0.7234074473381042, 0.36767274141311646], [-1.9326019287109375, 1.3782596588134766], [-0.6930878758430481, 0.9909102916717529], [-0.1825883686542511, -0.2698281705379486], [-1.4725991487503052, 0.9674650430679321], [-0.7488852739334106, 0.27666422724723816], [-0.270882785320282, -0.21036331355571747], [-1.479263186454773, 0.9093449711799622], [0.10195840895175934, -0.6729775667190552], [0.004027853719890118, -0.5255697965621948], [-1.9423273801803589, 1.3967071771621704], [1.5303175449371338, -1.1633808612823486], [-0.44726812839508057, 0.005319681949913502], [-1.5694342851638794, 1.1167597770690918], [0.5454074740409851, -0.8797770142555237], [0.019423507153987885, -0.5709049701690674], [1.6844148635864258, -1.1648552417755127], [-1.9516738653182983, 1.468228816986084], [1.4594393968582153, -1.0419061183929443], [-0.5491016507148743, 0.20016413927078247], [-1.4385151863098145, 0.9994550347328186], [-0.37114012241363525, -0.13025884330272675]], [[0.3162366449832916, -0.6416505575180054], [-0.7030442357063293, 0.21216735243797302], [-0.8805784583091736, 0.4333741366863251], [-2.0073108673095703, 1.4062291383743286], [-1.0325891971588135, 0.486490398645401], [0.13369691371917725, -0.6787831783294678], [-0.4625530540943146, -0.032384563237428665], [1.0582503080368042, -1.3831318616867065], [1.1173697710037231, -1.38733971118927], [-0.4487609565258026, 0.027858374640345573], [-0.7060068249702454, 0.32524561882019043], [-0.9186280965805054, 0.5036900639533997], [-1.9142988920211792, 1.421583890914917], [-1.349426031112671, 1.0897395610809326], [-1.5850446224212646, 1.1044954061508179], [-0.3019733428955078, -0.10600326210260391], [-1.4727572202682495, 1.1164824962615967], [0.685967743396759, -0.8195022940635681], [-0.3864566683769226, 0.07685109972953796], [0.21821056306362152, -0.748085618019104], [-1.6530249118804932, 1.2782976627349854], [-0.1817285716533661, -0.3806067109107971], [-0.8040165305137634, 0.2380208522081375], [1.0889513492584229, -0.4618435800075531], [0.7408545613288879, -1.1461751461029053], [-0.6069415807723999, 0.06328365206718445], [-0.915095865726471, 0.35590776801109314], [-0.04792424663901329, -0.4362820088863373], [-0.8265408873558044, 0.5206994414329529], [-0.9828815460205078, 0.5957185626029968], [-0.10003706812858582, -0.38331523537635803], [-1.0166118144989014, 0.5782055854797363]], [[-0.1176888570189476, -0.2785457670688629], [-0.18620605766773224, -0.22219210863113403], [0.5946470499038696, -1.0825406312942505], [-1.2386415004730225, 0.7434545755386353], [-1.393550992012024, 1.1611067056655884], [-1.235599160194397, 0.9860054850578308], [-1.2844407558441162, 0.9156316518783569], [-1.471411943435669, 1.0269807577133179], [-1.3595916032791138, 1.1001454591751099], [-0.1850178837776184, -0.20713835954666138], [0.7976856827735901, -0.6030879616737366], [-0.8934038877487183, 0.4898111820220947], [1.3591560125350952, -0.959327220916748], [-1.7637014389038086, 1.4106117486953735], [-1.8410284519195557, 1.3225340843200684], [-0.7397975325584412, 0.1729537546634674], [-1.7132816314697266, 1.2113016843795776], [0.837865948677063, -1.2747013568878174], [-0.8968105316162109, 0.40037888288497925], [-0.9943562746047974, 0.6444746851921082], [-0.7629481554031372, 0.332031786441803], [-0.12655626237392426, -0.21137787401676178], [0.6564443111419678, -1.0833253860473633], [-1.8009138107299805, 1.2074408531188965], [-1.5597590208053589, 1.0394060611724854], [1.8348709344863892, -1.3577512502670288], [-1.8057701587677002, 1.3590426445007324], [-0.05386914685368538, -0.5540046095848083], [-1.7646734714508057, 1.252975344657898], [-1.83267080783844, 1.246182918548584], [1.6179662942886353, -1.2617648839950562], [-1.5494375228881836, 0.994881272315979]], [[-1.3605360984802246, 1.0123612880706787], [1.052816390991211, -0.9326490759849548], [-1.5951969623565674, 1.1756619215011597], [1.5902396440505981, -1.1689584255218506], [-1.8103493452072144, 1.170151710510254], [-0.48241329193115234, -0.028755197301506996], [0.361993670463562, -0.7055987119674683], [-1.3816334009170532, 1.1977611780166626], [-1.773520588874817, 1.3701633214950562], [-0.5749733448028564, 0.03867410123348236], [-1.3503252267837524, 1.2428582906723022], [0.4440210461616516, -0.8875852227210999], [1.575561761856079, -1.2785743474960327], [0.681443989276886, -0.9402391314506531], [-0.04023900255560875, -0.42835915088653564], [-1.8515344858169556, 1.2426520586013794], [-0.7394292950630188, 0.49412256479263306], [1.0045562982559204, -1.080910325050354], [-0.7896704077720642, 0.4575166702270508], [-0.46928608417510986, -0.043548550456762314], [0.6172527074813843, -1.001479148864746], [-0.48019999265670776, 0.19099298119544983], [-0.7994748950004578, 0.2964663505554199], [-1.1397314071655273, 0.5523289442062378], [-0.8943590521812439, 0.44187989830970764], [-0.7438711524009705, 0.1949560046195984], [-0.6125130653381348, 0.04733385890722275], [0.7676029205322266, -1.1899398565292358], [-1.5579609870910645, 0.8897702097892761], [-0.598220944404602, 0.31707942485809326], [0.9987826943397522, -1.3953500986099243], [-1.5545151233673096, 1.1372007131576538]], [[-0.016533896327018738, -0.4578275978565216], [1.2764142751693726, -1.2953020334243774], [-0.3263182044029236, -0.11739376932382584], [-1.5320576429367065, 1.0571502447128296], [-0.1800459623336792, -0.4120689332485199], [-1.293891429901123, 0.8293255567550659], [-1.305869221687317, 0.8675087690353394], [0.3816547393798828, -0.8193448185920715], [-1.6588894128799438, 1.1342418193817139], [-0.12764433026313782, -0.08377061039209366], [-1.4954222440719604, 1.008889079093933], [-0.15653157234191895, -0.27969154715538025], [-0.26583051681518555, -0.1525202989578247], [-0.37473753094673157, -0.05269934609532356], [-0.44410181045532227, 0.08886168152093887], [-0.9104065299034119, 0.4705565869808197], [-1.4384599924087524, 0.976137101650238], [0.8932471871376038, -0.30039042234420776], [-1.9922990798950195, 1.450670599937439], [0.05469303950667381, -0.5949878692626953], [-1.5973994731903076, 0.9993739724159241], [-1.2980294227600098, 0.9518433809280396], [0.5096431374549866, -0.5443828105926514], [-1.3470160961151123, 0.8238096237182617], [0.23692713677883148, -0.5625668168067932], [0.8004103899002075, -1.1465145349502563], [0.8273354768753052, -1.2761253118515015], [-0.3279169499874115, -0.09839300066232681], [-0.049376752227544785, -0.23928436636924744], [-0.9649893045425415, 0.5996613502502441], [1.840785026550293, -1.331465721130371], [-0.01730387471616268, -0.32632511854171753]], [[-1.4678072929382324, 1.0440031290054321], [-1.18367600440979, 0.824627161026001], [-0.8032622337341309, 0.20837010443210602], [-0.5214414596557617, 0.06335245072841644], [-1.363413691520691, 0.8775200247764587], [0.029096269980072975, -0.3922116458415985], [-1.985060691833496, 1.3921260833740234], [1.3350166082382202, -1.0863354206085205], [1.3377623558044434, -1.1513906717300415], [-0.8080013394355774, 0.4874218702316284], [-1.9052767753601074, 1.3270928859710693], [-1.8516498804092407, 1.2963526248931885], [-1.3411749601364136, 0.8536725044250488], [-1.8180302381515503, 1.2343213558197021], [-0.13481998443603516, -0.2693672478199005], [0.13147331774234772, -0.4896312654018402], [0.8381800055503845, -0.5021676421165466], [0.3564685583114624, -0.6293390989303589], [0.32463765144348145, -0.7640656232833862], [-0.26077988743782043, 0.24401220679283142], [1.6954649686813354, -1.3548235893249512], [1.5873372554779053, -1.1876848936080933], [-1.8377271890640259, 1.3078943490982056], [0.5909172892570496, -0.1562512069940567], [-1.9375813007354736, 1.5203441381454468], [-1.8950340747833252, 1.3862801790237427], [-1.1093509197235107, 0.6374114751815796], [-1.940842866897583, 1.4482271671295166], [1.67472505569458, -1.1959309577941895], [-2.0230681896209717, 1.4334793090820312], [-1.9013302326202393, 1.3541260957717896], [0.1704058051109314, -0.6353694200515747]], [[-1.5364817380905151, 1.1332716941833496], [-1.7259770631790161, 1.3116205930709839], [-0.1926194578409195, -0.16471797227859497], [0.7834342122077942, -0.9641245007514954], [-0.807708203792572, 0.6862264275550842], [-1.4984121322631836, 1.2185338735580444], [-1.6635792255401611, 1.4358125925064087], [-1.821926236152649, 1.3527700901031494], [0.02101469226181507, -0.24833253026008606], [-1.981035590171814, 1.3415722846984863], [0.9357340335845947, -0.6978825330734253], [1.5938644409179688, -1.3023251295089722], [-1.6414382457733154, 1.1207860708236694], [-1.9974756240844727, 1.3963336944580078], [0.9636664390563965, -1.1585617065429688], [-1.5897035598754883, 1.269790768623352], [-0.21467101573944092, -0.13899606466293335], [-1.7660167217254639, 1.2334868907928467], [-1.3656690120697021, 0.8029375672340393], [-1.7469724416732788, 1.342074990272522], [1.7786791324615479, -1.227339267730713], [-1.956473469734192, 1.364465594291687], [-1.8296188116073608, 1.286795735359192], [-0.7577894926071167, 0.25049731135368347], [-1.8386121988296509, 1.2783596515655518], [-0.4497195780277252, 0.17465375363826752], [1.220950961112976, -1.1982543468475342], [0.2838222086429596, -0.6386611461639404], [-1.9994310140609741, 1.5046659708023071], [-1.6859358549118042, 1.4281020164489746], [0.672360897064209, -0.08194620907306671], [-0.7728643417358398, 0.44858822226524353]], [[-1.1040754318237305, 0.9561306238174438], [0.7486752867698669, -0.7254772782325745], [-0.6907700300216675, 0.06702758371829987], [1.2988440990447998, -1.1842303276062012], [1.4023734331130981, -1.1625200510025024], [-0.45499083399772644, 0.41595345735549927], [-0.7684308886528015, 0.4719659090042114], [-0.781867504119873, 0.4405292272567749], [-0.2936592102050781, 0.14858074486255646], [1.554249882698059, -1.140992283821106], [1.634010672569275, -1.1455869674682617], [-0.7866867184638977, 0.4831082224845886], [-0.14338712394237518, -0.3496534526348114], [-0.9781509637832642, 0.5341550707817078], [-1.5344083309173584, 1.1482048034667969], [0.24562664330005646, -0.6249829530715942], [-1.4339399337768555, 1.0920203924179077], [-1.9017317295074463, 1.448673129081726], [-1.9170763492584229, 1.4724981784820557], [-2.0180084705352783, 1.4615617990493774], [0.04876549169421196, -0.10304103046655655], [-1.4756180047988892, 1.0494178533554077], [-0.8214408755302429, 0.5768990516662598], [1.611302137374878, -1.3743970394134521], [0.9774590730667114, -1.1055916547775269], [1.8064295053482056, -1.1585602760314941], [-2.003476858139038, 1.4781240224838257], [-0.6030579805374146, 0.19755196571350098], [-0.6244313716888428, 0.15198063850402832], [1.8373749256134033, -1.3600009679794312], [1.7214096784591675, -1.2958699464797974], [-1.3864237070083618, 1.101078748703003]], [[-1.2776697874069214, 0.8209401369094849], [-1.7079650163650513, 1.16880464553833], [0.5983848571777344, -0.9433530569076538], [-0.20534729957580566, -0.2219330370426178], [0.7043846845626831, -0.4918709099292755], [-1.9821697473526, 1.4609352350234985], [-1.8541439771652222, 1.2840545177459717], [-1.9803662300109863, 1.3372478485107422], [-1.8668022155761719, 1.344954013824463], [-1.8776419162750244, 1.3775346279144287], [1.7751277685165405, -1.331234097480774], [-1.6854636669158936, 1.1171846389770508], [-1.7490826845169067, 1.2671475410461426], [-1.0962077379226685, 0.8154987096786499], [-1.5846424102783203, 1.2043683528900146], [-1.0209943056106567, 0.5543925762176514], [-1.2812086343765259, 1.4400391578674316], [-0.2191840410232544, -0.19369713962078094], [-1.8467801809310913, 1.2822563648223877], [-1.704714298248291, 1.6027125120162964], [1.424818515777588, -1.0468946695327759], [1.2392884492874146, -1.1503567695617676], [-1.8355604410171509, 1.3279147148132324], [-1.7634142637252808, 1.3390692472457886], [-1.628603219985962, 1.0453171730041504], [-0.636273205280304, 0.18768179416656494], [-0.9315569400787354, 0.39210832118988037], [-1.4243800640106201, 1.2575894594192505], [-1.9209545850753784, 1.3105205297470093], [-0.9065375924110413, 0.442623496055603], [-0.4077882468700409, -0.03930990770459175], [0.06753353774547577, -0.3633989095687866]], [[0.7985515594482422, -0.9251701831817627], [-0.4153592884540558, -0.20605923235416412], [0.11148426681756973, -0.31608158349990845], [0.14016614854335785, -0.4070199429988861], [-1.1624095439910889, 0.7572858929634094], [-1.5694003105163574, 1.0549548864364624], [1.853757381439209, -1.2287652492523193], [-1.7906793355941772, 1.3617031574249268], [-0.7598060369491577, 0.2609051764011383], [-0.30283287167549133, 0.060411930084228516], [0.5717639923095703, -0.7172654867172241], [-1.0701287984848022, 0.8184861540794373], [-0.1960843950510025, -0.18728122115135193], [-1.120376706123352, 0.8555110096931458], [1.8613301515579224, -1.3429821729660034], [-1.2493388652801514, 0.9931609630584717], [-0.5323824286460876, 0.2054223269224167], [0.9285462498664856, -0.87286376953125], [-1.0524228811264038, 0.5946904420852661], [1.086424469947815, -1.4420149326324463], [-0.20776471495628357, -0.34897881746292114], [-1.8383560180664062, 1.299146294593811], [1.5643389225006104, -1.1206601858139038], [-1.8494775295257568, 1.381596326828003], [-0.11153313517570496, -0.3099185526371002], [0.7333282232284546, -0.14242808520793915], [0.1907244324684143, -0.5004604458808899], [-0.9699129462242126, 0.4912126362323761], [-0.30471402406692505, -0.24083943665027618], [0.463175892829895, -0.8117506504058838], [1.7411552667617798, -1.171949028968811], [-0.36624541878700256, -0.012060010805726051]], [[-0.7278639674186707, 0.22915418446063995], [0.6131860017776489, -1.052749514579773], [-1.620410442352295, 1.0327218770980835], [-1.7162160873413086, 1.123587965965271], [-1.9478480815887451, 1.3577749729156494], [-1.5156972408294678, 1.1706311702728271], [-1.2737981081008911, 1.3160737752914429], [0.4451274573802948, -0.759955883026123], [-1.1835821866989136, 0.6537312865257263], [0.6809649467468262, -0.9205832481384277], [-1.6098134517669678, 1.2097309827804565], [0.8736095428466797, -1.1926913261413574], [0.6712101101875305, -1.1226212978363037], [0.7835860848426819, -1.2178088426589966], [-1.0940279960632324, 0.5775700807571411], [0.9528400897979736, -0.678840160369873], [1.4421287775039673, -0.8511882424354553], [1.2065120935440063, -1.2558867931365967], [-1.1729717254638672, 0.7326517701148987], [-0.8382316827774048, 0.5922904014587402], [-0.36068856716156006, -0.09443190693855286], [-0.8616712689399719, 0.5102930665016174], [-1.856462836265564, 1.3208328485488892], [-1.0126928091049194, 0.5847463011741638], [-1.0677241086959839, 0.49958398938179016], [-1.4904636144638062, 1.1858850717544556], [-1.9090909957885742, 1.295440435409546], [-1.9391460418701172, 1.4347143173217773], [-1.707714319229126, 1.2344918251037598], [-1.0465364456176758, 1.1269546747207642], [1.0147186517715454, -1.149962067604065], [-1.738503336906433, 1.1699550151824951]], [[-0.256569504737854, -0.2634235620498657], [-0.1691470593214035, -0.22624734044075012], [0.17044319212436676, -0.6652195453643799], [-1.5774966478347778, 1.172397255897522], [-1.7050284147262573, 1.2871283292770386], [-0.8681629300117493, 0.3165518045425415], [0.6670134663581848, -0.9206932187080383], [-1.7710232734680176, 1.1978296041488647], [0.12439819425344467, -0.631251335144043], [-0.26228582859039307, -0.2730698585510254], [-0.1720389723777771, -0.3380252718925476], [-1.964892864227295, 1.477232813835144], [-1.6228992938995361, 1.3093178272247314], [-0.0691332072019577, -0.072665736079216], [-1.443352222442627, 0.9680688977241516], [-1.4881672859191895, 1.084887146949768], [-1.4966216087341309, 1.0179723501205444], [1.0988235473632812, -0.8960288166999817], [0.05786796659231186, -0.20622076094150543], [-1.8888260126113892, 1.3289430141448975], [0.07243803888559341, -0.5876809358596802], [-1.6138802766799927, 1.3589253425598145], [1.7521308660507202, -1.2993505001068115], [-1.9503852128982544, 1.5083162784576416], [1.219327449798584, -0.9259661436080933], [0.513504683971405, -0.19610947370529175], [-1.9729282855987549, 1.4233713150024414], [1.1581745147705078, -1.1553127765655518], [-1.1269551515579224, 0.6375250816345215], [-0.9449662566184998, 0.6237671971321106], [0.07840222120285034, -0.5311070680618286], [-1.6866995096206665, 1.4994745254516602]], [[-1.3766887187957764, 0.9344101548194885], [-1.1350831985473633, 0.7122582197189331], [-1.8043030500411987, 1.287229061126709], [1.2619653940200806, -0.9662511348724365], [-0.7495213150978088, 0.26163244247436523], [-0.2589251399040222, -0.24632497131824493], [-1.4912443161010742, 0.9606274366378784], [-0.40804338455200195, -0.024207131937146187], [-1.675943374633789, 1.2119801044464111], [-1.9105415344238281, 1.2149423360824585], [-1.0400171279907227, 0.5204810500144958], [1.3060179948806763, -0.9631808996200562], [-0.24590176343917847, -0.011284509673714638], [1.4020596742630005, -0.9887160062789917], [1.8016893863677979, -1.3184000253677368], [-1.9769307374954224, 1.3303499221801758], [-0.2693668603897095, -0.16652394831180573], [-2.036919593811035, 1.444176197052002], [-0.9124734997749329, 0.6520666480064392], [0.2744581997394562, -0.598447322845459], [1.3870567083358765, -0.9607851505279541], [-0.07795358449220657, -0.36647287011146545], [-1.9811762571334839, 1.463416337966919], [-1.6957614421844482, 1.53489089012146], [1.5841630697250366, -1.0870418548583984], [-1.6338794231414795, 1.2508800029754639], [-1.9104670286178589, 1.3449050188064575], [0.9158048033714294, -1.2506208419799805], [0.24399039149284363, -0.6760475635528564], [0.41480255126953125, -0.5653497576713562], [1.400572419166565, -1.3776873350143433], [-0.25027841329574585, -0.30460605025291443]], [[-0.7930170893669128, 0.3864775598049164], [0.7901714444160461, -1.0833563804626465], [0.6925516128540039, -1.13029944896698], [-1.5549765825271606, 1.26347017288208], [-0.6160097718238831, 0.09100271761417389], [-1.6662758588790894, 1.3433606624603271], [-1.402344822883606, 0.9667525291442871], [-0.2755964398384094, -0.11945652961730957], [-1.7928497791290283, 1.4734594821929932], [-1.3051784038543701, 0.8284669518470764], [-0.7718148827552795, 0.285469651222229], [0.48010188341140747, -0.6489712595939636], [-0.36110326647758484, 0.10256630182266235], [0.600311815738678, -0.13597625494003296], [0.3603484630584717, -0.7249683141708374], [1.0083093643188477, -0.9866189360618591], [1.8381479978561401, -1.324023723602295], [-2.017771005630493, 1.4638038873672485], [0.8480347394943237, -1.3020001649856567], [1.2953683137893677, -1.0703020095825195], [1.6666381359100342, -1.2826995849609375], [-0.8756747841835022, 0.49121952056884766], [-0.8908487558364868, 0.38272106647491455], [-0.031987257301807404, 0.1129290983080864], [-0.3399951756000519, 0.0780140683054924], [1.7239274978637695, -1.1599539518356323], [1.7850117683410645, -1.2337491512298584], [-0.7426270842552185, 0.25541332364082336], [1.7524279356002808, -1.287832260131836], [-1.9509062767028809, 1.4568129777908325], [-0.38035351037979126, 0.34132567048072815], [-0.6020106673240662, 0.3852299451828003]], [[-0.4642392694950104, 0.38294753432273865], [1.5083149671554565, -1.0942846536636353], [-0.9853119850158691, 0.5906124114990234], [1.4981849193572998, -1.1367857456207275], [-0.250112920999527, -0.24249477684497833], [-1.3770802021026611, 0.9360125064849854], [0.036391645669937134, -0.5309795141220093], [1.4191473722457886, -1.0318979024887085], [-1.2460618019104004, 1.0853445529937744], [1.1090375185012817, -1.0948760509490967], [-0.8782655596733093, 0.7518505454063416], [0.15891003608703613, -0.5888357758522034], [1.7041280269622803, -1.2386332750320435], [1.422994613647461, -0.9911187887191772], [-1.7544920444488525, 1.3510637283325195], [-0.522729218006134, -0.026704983785748482], [-0.6318259239196777, 0.16663160920143127], [-0.3809969425201416, 0.018439428880810738], [-0.5750730037689209, 0.28851959109306335], [0.5661835670471191, -0.982553243637085], [1.565857172012329, -1.369672179222107], [0.7606114745140076, -1.2751274108886719], [-0.683982789516449, 0.22239379584789276], [1.7350188493728638, -1.2606050968170166], [-0.9091097712516785, 0.9216356873512268], [0.6506987810134888, -1.0695642232894897], [-0.5941234827041626, 0.26591160893440247], [0.17775583267211914, -0.46570587158203125], [-1.600237250328064, 1.1932697296142578], [-1.5125689506530762, 1.0735028982162476], [1.1461714506149292, -0.6915596723556519], [-1.1998534202575684, 0.7035393714904785]], [[0.4390806555747986, -0.8142224550247192], [-0.06379587948322296, -0.3369537591934204], [-1.7299309968948364, 1.232894778251648], [0.06998518109321594, -0.4767540395259857], [-0.4636375904083252, 0.005670554004609585], [0.6488996744155884, -1.1795285940170288], [1.4616669416427612, -1.1596742868423462], [-1.3511911630630493, 0.9518601298332214], [1.1317390203475952, -0.7531086802482605], [0.6201724410057068, -1.0543859004974365], [-0.997460663318634, 0.5177804827690125], [-1.1946512460708618, 0.652099072933197], [-2.0013039112091064, 1.3276896476745605], [1.6574534177780151, -1.2009044885635376], [0.5436939597129822, -0.08119001984596252], [1.792658805847168, -1.2730913162231445], [0.6671870946884155, -0.5478657484054565], [0.2780691385269165, -0.5190306305885315], [0.05925966054201126, -0.34514766931533813], [-1.7520831823349, 1.3278734683990479], [-0.9174550175666809, 0.5653151273727417], [0.06550344079732895, -0.4813040494918823], [-0.2943474352359772, -0.17354412376880646], [-1.0299382209777832, 0.4909017086029053], [-1.1082797050476074, 0.661365807056427], [1.376598596572876, -1.3461107015609741], [-1.2940720319747925, 0.6811754107475281], [-1.7740784883499146, 1.0325443744659424], [0.7733810544013977, -1.0131124258041382], [-1.3583552837371826, 0.9378653764724731], [-0.959458589553833, 0.5908336043357849], [0.12283995747566223, -0.5920032858848572]], [[-1.7313568592071533, 1.0948823690414429], [1.4531574249267578, -1.0591861009597778], [0.22090940177440643, -0.380466103553772], [-0.2429993897676468, -0.03376596048474312], [-0.08326111733913422, -0.509099006652832], [-1.856471061706543, 1.2908004522323608], [-1.3197532892227173, 0.8085525035858154], [-0.6615078449249268, 0.3146611154079437], [-0.9819246530532837, 0.6226572394371033], [0.6809543967247009, -0.1954890638589859], [-0.7553644776344299, 0.44560882449150085], [-1.2670326232910156, 0.7230327129364014], [0.14177308976650238, -0.7457704544067383], [-1.5726653337478638, 1.1627761125564575], [0.05560782551765442, -0.6969443559646606], [0.5374829173088074, -0.790560245513916], [1.8252339363098145, -1.3416117429733276], [0.8532710671424866, -1.266182541847229], [-1.7748842239379883, 1.3386156558990479], [0.2743458151817322, -0.5131869912147522], [1.038083791732788, -1.0085994005203247], [-1.7022576332092285, 1.2842402458190918], [1.220301628112793, -1.1884639263153076], [-1.005807638168335, 0.4754715859889984], [0.03815317153930664, -0.6097948551177979], [-0.01845717243850231, -0.4252770245075226], [-1.2495601177215576, 0.884149968624115], [0.9986878037452698, -1.0355262756347656], [-1.5003873109817505, 1.187760829925537], [0.6491793394088745, -0.9696505069732666], [-1.8853895664215088, 1.183509111404419], [-0.8732165098190308, 0.33893829584121704]], [[-0.16286875307559967, -0.3341485857963562], [1.704679250717163, -1.2717164754867554], [-0.8270560503005981, 0.6596757173538208], [-1.4937885999679565, 1.1332372426986694], [0.32394570112228394, -0.47718164324760437], [1.7003066539764404, -1.2156803607940674], [-1.9954736232757568, 1.4398270845413208], [-1.0466628074645996, 0.678899347782135], [-1.3792047500610352, 0.8715523481369019], [-0.410067081451416, -0.0925886482000351], [-0.6110756993293762, 0.08912914246320724], [-0.17655330896377563, -0.14611615240573883], [-2.0297868251800537, 1.4363149404525757], [-0.9718473553657532, 0.4618005156517029], [1.1182469129562378, -1.074713945388794], [0.7734494209289551, -1.0141152143478394], [-1.9266787767410278, 1.1708693504333496], [-1.114709734916687, 0.7335337400436401], [-1.0250509977340698, 0.8758638501167297], [-1.172316312789917, 0.7420785427093506], [-1.5331335067749023, 1.0627111196517944], [-1.118006944656372, 0.6481173038482666], [0.7958593964576721, -0.8052820563316345], [-0.9670987129211426, 0.28116393089294434], [-0.6389356851577759, 0.1412580907344818], [-0.7662277221679688, 0.2814413905143738], [-1.8745383024215698, 1.1829322576522827], [-0.3206528127193451, -0.20563489198684692], [-1.8484992980957031, 1.2801414728164673], [1.2780753374099731, -0.8756632208824158], [-1.9227317571640015, 1.3230509757995605], [-1.5622652769088745, 1.0723605155944824]], [[0.1897166669368744, -0.5428956747055054], [-0.4760712683200836, 0.6143518090248108], [-0.027953768149018288, -0.3394373953342438], [1.8014239072799683, -1.2812697887420654], [-1.3494235277175903, 0.9088143110275269], [-1.6486254930496216, 1.115499496459961], [0.8463975191116333, -1.1051483154296875], [-1.8890208005905151, 1.351029872894287], [-1.6373865604400635, 1.1005845069885254], [0.0427740104496479, -0.5019010901451111], [0.357287734746933, -0.7901172637939453], [0.31652167439460754, -0.6943970322608948], [-0.7061694860458374, 0.11709464341402054], [-1.6951241493225098, 1.2341574430465698], [-0.7053008675575256, 0.598021388053894], [-1.009623408317566, 0.6736429333686829], [-1.7188280820846558, 1.0909624099731445], [-1.8539503812789917, 1.1996105909347534], [-1.3656331300735474, 1.0504664182662964], [-1.285330057144165, 0.6973806619644165], [-1.4897466897964478, 0.8412290811538696], [0.3607153594493866, -0.5840252637863159], [1.5185258388519287, -1.2465640306472778], [1.1124576330184937, -0.8670851588249207], [-1.9079902172088623, 1.567674160003662], [-1.609920620918274, 1.1327929496765137], [-1.8560750484466553, 1.1288561820983887], [-1.4790210723876953, 1.1748863458633423], [-1.1241716146469116, 0.6120008826255798], [-0.5687018632888794, 0.03454545512795448], [-1.5064218044281006, 0.9839924573898315], [0.04675046354532242, -0.5743798017501831]], [[-0.05259207636117935, -0.46503227949142456], [-0.8713365197181702, 0.3665638267993927], [0.2146938443183899, -0.5727505087852478], [0.43651166558265686, -0.8458659052848816], [-1.7136149406433105, 1.1960386037826538], [-0.7977792024612427, 0.5274268388748169], [-1.6408714056015015, 1.2261171340942383], [0.992979109287262, -0.9617635011672974], [-1.7743641138076782, 1.124180793762207], [-1.9015178680419922, 1.1514774560928345], [-1.5601027011871338, 0.9877258539199829], [-1.391127586364746, 0.9384934902191162], [-0.011544779874384403, -0.44870778918266296], [-1.6445969343185425, 1.1931109428405762], [-1.4827460050582886, 1.1563349962234497], [-1.8473072052001953, 1.458541750907898], [-0.04389533773064613, -0.1378113329410553], [-1.7452166080474854, 1.3038171529769897], [-0.9480072259902954, 0.3990737497806549], [-1.172226905822754, 0.6094744801521301], [1.0289719104766846, -1.3142651319503784], [-1.7801594734191895, 1.069955587387085], [-0.7661648988723755, 0.22392047941684723], [-1.6402274370193481, 1.290598750114441], [1.7547191381454468, -1.3487963676452637], [0.2777085304260254, -0.41336968541145325], [-1.5871481895446777, 0.9271591901779175], [-0.20874547958374023, -0.17067566514015198], [1.81028413772583, -1.291276454925537], [1.3641571998596191, -1.2421687841415405], [-0.838509738445282, 0.24486644566059113], [-0.03177464008331299, -0.5970013737678528]], [[-0.17841851711273193, -0.1829543113708496], [-1.071240782737732, 0.6573801636695862], [-1.5563547611236572, 1.2720462083816528], [1.548907995223999, -1.3669253587722778], [0.4843372106552124, -0.8489094972610474], [-1.416455864906311, 0.8546127080917358], [-0.5320751070976257, 0.18288154900074005], [-0.8161324262619019, 0.43694937229156494], [0.4689594507217407, -0.22992976009845734], [-1.3251714706420898, 1.1364731788635254], [-0.4651308059692383, -0.017401840537786484], [0.7115373611450195, -1.0874090194702148], [-1.864367961883545, 1.2848799228668213], [0.3685515820980072, -0.9028958082199097], [-1.1846812963485718, 0.6015441417694092], [-0.29897063970565796, -0.19057637453079224], [-1.7658005952835083, 1.142968773841858], [-1.824966549873352, 1.2265386581420898], [-1.5314358472824097, 1.2296693325042725], [-1.7495462894439697, 1.322645664215088], [0.1843467652797699, -0.7148019671440125], [-1.717419981956482, 1.3240432739257812], [-1.4233547449111938, 1.0437383651733398], [-1.9539779424667358, 1.4675849676132202], [-0.7117175459861755, 0.2414446473121643], [0.9885345697402954, -1.0568480491638184], [1.6522290706634521, -1.2646137475967407], [-1.8936465978622437, 1.4227991104125977], [-0.3269200623035431, -0.05703533813357353], [0.05033491551876068, -0.46361756324768066], [-1.2327430248260498, 0.8191362023353577], [1.5087182521820068, -1.0125346183776855]], [[-1.8712636232376099, 1.3991888761520386], [0.18374043703079224, -0.6267727613449097], [-0.2144390493631363, -0.2128307819366455], [-1.0271029472351074, 0.7154858112335205], [0.7343202233314514, -0.825471818447113], [-0.254463791847229, -0.004766765981912613], [0.5005512237548828, -0.1368069350719452], [-0.8453449606895447, 0.4224541485309601], [-0.26145103573799133, 0.5157500505447388], [-1.983805775642395, 1.4025397300720215], [1.1361242532730103, -0.9166474938392639], [0.055857960134744644, -0.5173810720443726], [1.1338398456573486, -0.7717032432556152], [1.4275659322738647, -1.4099501371383667], [-1.3033887147903442, 0.8455986976623535], [-1.3735435009002686, 0.8725388646125793], [-0.6148272752761841, 0.32892730832099915], [-1.9462085962295532, 1.2640659809112549], [-0.9174142479896545, 0.9253017902374268], [-1.7887814044952393, 1.2240291833877563], [0.6855859756469727, -0.6497167944908142], [0.1727093756198883, -0.5336341261863708], [-1.5276738405227661, 1.0141375064849854], [1.8457919359207153, -1.2580715417861938], [-1.8576527833938599, 1.382295846939087], [-1.9174140691757202, 1.445902705192566], [1.903786063194275, -1.3311305046081543], [-0.04102880507707596, -0.23286564648151398], [-0.9341226816177368, 0.6617100238800049], [0.612400233745575, -0.8830884695053101], [-0.34163472056388855, 0.018547290936112404], [-1.8693946599960327, 1.4667435884475708]], [[0.2621106505393982, -0.36361148953437805], [-0.004104165360331535, 0.09269603341817856], [-0.025764785706996918, -0.36344584822654724], [-1.1759954690933228, 0.6612339019775391], [-1.754075288772583, 1.2613630294799805], [-1.7091602087020874, 1.1452594995498657], [1.7068431377410889, -1.2868989706039429], [0.9331849813461304, -0.733902633190155], [-1.9498127698898315, 1.4234466552734375], [-1.9594881534576416, 1.4959235191345215], [-0.3196863830089569, -0.09552717953920364], [-1.972127079963684, 1.527820348739624], [-1.012507677078247, 0.6132166981697083], [-0.8347954154014587, 0.43819743394851685], [-1.177924633026123, 0.7665528059005737], [1.4780325889587402, -1.1627238988876343], [1.1566663980484009, -0.8405056595802307], [-1.711319923400879, 1.2546709775924683], [-1.779390573501587, 1.3800255060195923], [-0.5794534683227539, 0.19535964727401733], [-1.732460618019104, 1.3382316827774048], [-1.988101601600647, 1.4844781160354614], [-1.7491992712020874, 1.3363449573516846], [-0.018996451050043106, 0.18188628554344177], [0.12037601321935654, -0.5954092741012573], [-1.4850136041641235, 1.0893365144729614], [1.8532447814941406, -1.3394535779953003], [-0.4312876760959625, 0.07911090552806854], [-1.7082267999649048, 1.3141165971755981], [1.2050755023956299, -1.2288944721221924], [0.16835623979568481, -0.2343853861093521], [-1.9398585557937622, 1.4245684146881104]], [[0.2822864353656769, -0.47056207060813904], [-1.1028573513031006, 0.7689543962478638], [-0.030495265498757362, 0.13445532321929932], [0.17896012961864471, -0.5811870098114014], [-0.8023943305015564, 0.3657035231590271], [0.6288377642631531, -0.9349592924118042], [1.9399563074111938, -1.3759063482284546], [-1.954803228378296, 1.305314064025879], [0.5398220419883728, -1.0440733432769775], [-0.6347838640213013, 0.0697050541639328], [0.14092180132865906, -0.36725151538848877], [-1.1271313428878784, 0.9144430756568909], [-1.494727611541748, 1.1109298467636108], [-1.852117657661438, 1.3839377164840698], [-0.7289722561836243, 0.10388249903917313], [-0.2134953886270523, -0.22504740953445435], [-0.11648304760456085, -0.3187881410121918], [-1.0354971885681152, 0.5682731866836548], [-1.9985508918762207, 1.3238320350646973], [1.1032183170318604, -1.3977506160736084], [-0.5422506928443909, 0.5378634333610535], [-0.7156177759170532, 0.713563084602356], [-0.9681705832481384, 0.48630034923553467], [-1.9560341835021973, 1.3304173946380615], [0.22642870247364044, -0.017574159428477287], [-1.871974229812622, 1.3282825946807861], [1.0433021783828735, -1.1113420724868774], [1.9065841436386108, -1.3264274597167969], [-1.9517900943756104, 1.2819554805755615], [-0.29593637585639954, -0.1216283068060875], [1.7877095937728882, -1.3350614309310913], [-1.5032477378845215, 1.0490857362747192]], [[1.49751877784729, -1.293144941329956], [1.4714136123657227, -1.0490102767944336], [0.6071265935897827, -0.27628371119499207], [1.56038498878479, -1.1260370016098022], [0.7768409848213196, -1.2225795984268188], [0.20353160798549652, -0.5591594576835632], [-1.8638848066329956, 1.4465339183807373], [-1.862012267112732, 1.4879685640335083], [-0.36321350932121277, -0.10392803698778152], [-0.864609956741333, 0.4917454123497009], [1.7865321636199951, -1.329105257987976], [-1.9816021919250488, 1.3343900442123413], [-0.5558042526245117, 0.11327808350324631], [0.41993632912635803, -0.865627110004425], [1.057482361793518, -1.3036468029022217], [-1.9808728694915771, 1.498206377029419], [-1.6997859477996826, 1.3550982475280762], [-1.7770024538040161, 1.1657134294509888], [-1.7001336812973022, 1.1819629669189453], [-1.8119380474090576, 1.2716801166534424], [0.30273082852363586, -0.521402895450592], [-0.7050520777702332, 0.32164666056632996], [-1.941942572593689, 1.3794124126434326], [-1.732011079788208, 1.193854570388794], [-1.51309335231781, 1.0908191204071045], [-1.678588628768921, 1.1383869647979736], [1.91825532913208, -1.3678425550460815], [1.790069818496704, -1.2800185680389404], [-1.6894311904907227, 1.2634148597717285], [1.4830164909362793, -1.2741785049438477], [-1.6501469612121582, 1.158333659172058], [-0.09988689422607422, -0.24330316483974457]], [[-1.4853047132492065, 1.0017814636230469], [1.4128683805465698, -0.9089396595954895], [0.8665140867233276, -0.8761333227157593], [0.850497305393219, -1.1058491468429565], [-1.4141298532485962, 0.9343923330307007], [-0.40916621685028076, 0.26988348364830017], [1.0293951034545898, -1.2672979831695557], [0.713479220867157, -0.7786858081817627], [-1.9252110719680786, 1.447993278503418], [-1.2451459169387817, 0.9302941560745239], [-1.0825738906860352, 0.6967871189117432], [1.2821842432022095, -1.3975611925125122], [-1.2370721101760864, 0.7676807045936584], [1.3227286338806152, -1.3813724517822266], [0.4763961732387543, -0.9111382961273193], [0.4118267297744751, -0.6913766264915466], [-0.9984699487686157, 0.7108139395713806], [0.0404106080532074, -0.5718662142753601], [-0.6519797444343567, 0.17673487961292267], [0.3387286365032196, 0.012927214615046978], [-0.6333301067352295, 0.24683834612369537], [-1.2985117435455322, 0.958590567111969], [-1.8257746696472168, 1.3499656915664673], [-1.2635011672973633, 0.7873512506484985], [1.3788232803344727, -1.1816107034683228], [-1.0657622814178467, 0.5803262591362], [-0.8936634659767151, 0.6067833304405212], [0.013389527797698975, -0.5250568389892578], [-0.9554182887077332, 0.4122718274593353], [0.13254237174987793, -0.7239145040512085], [0.20420777797698975, -0.6170815825462341], [-0.0710679367184639, -0.4152906537055969]], [[-1.522933006286621, 1.2509746551513672], [-1.8516244888305664, 1.4703038930892944], [1.7406150102615356, -1.1820167303085327], [-2.0064291954040527, 1.4204949140548706], [-0.5525102615356445, 0.06660043448209763], [1.0910893678665161, -0.9507431983947754], [0.9569270610809326, -0.9794232249259949], [-1.4160252809524536, 1.030759334564209], [0.7375485897064209, -1.0014342069625854], [-0.06643809378147125, 0.0431944914162159], [-1.39076828956604, 0.8754680752754211], [-1.8764839172363281, 1.4255971908569336], [0.8483549952507019, -0.7903965711593628], [-0.5170562267303467, 0.09484636038541794], [-1.430997371673584, 1.0049660205841064], [-0.9770235419273376, 0.618797242641449], [-0.2594480514526367, -0.2325371503829956], [-0.6521098017692566, 0.2555446922779083], [-1.9006686210632324, 1.3839291334152222], [-0.3577582538127899, -0.12178432196378708], [-0.20145033299922943, -0.20244833827018738], [-0.08817796409130096, -0.40861886739730835], [0.16541096568107605, -0.3639264702796936], [-0.5719646215438843, 0.39285239577293396], [0.6906908750534058, -0.9406328201293945], [0.19363071024417877, -0.706424355506897], [-1.19861900806427, 0.7366203665733337], [-0.8512028455734253, 0.466394305229187], [0.8951755166053772, -0.9756252765655518], [1.472103476524353, -1.1752445697784424], [-1.9595074653625488, 1.4215867519378662], [0.8645967841148376, -1.1428097486495972]], [[-0.6776502728462219, 0.28698527812957764], [-0.14975661039352417, 0.22699233889579773], [-1.4065405130386353, 0.9361047148704529], [-1.2952187061309814, 0.7258719801902771], [-1.494567632675171, 0.9638486504554749], [-1.7756348848342896, 1.2106157541275024], [1.0131053924560547, -1.172903060913086], [0.7506654858589172, -1.1995983123779297], [-0.6917461156845093, 0.16375917196273804], [0.3922399580478668, -0.6697038412094116], [-0.35567155480384827, -0.1165405809879303], [1.1951370239257812, -0.8439731597900391], [-1.187307596206665, 0.7059608697891235], [-0.7208852171897888, 0.3445506691932678], [-1.0554909706115723, 0.5523896217346191], [-0.3679865896701813, -0.09975150972604752], [-0.9810385704040527, 0.6286264061927795], [-1.5304112434387207, 1.064500093460083], [0.8604158163070679, -1.169454574584961], [1.2686634063720703, -1.1804448366165161], [1.0703188180923462, -0.9677820801734924], [-1.7040107250213623, 1.1993519067764282], [-1.504748821258545, 1.235952615737915], [-0.48293983936309814, 0.1339241862297058], [-1.5148142576217651, 1.0637025833129883], [-1.6720082759857178, 1.220839023590088], [0.5392797589302063, -0.9668013453483582], [0.7917650938034058, -0.7056611180305481], [1.756001591682434, -1.258452296257019], [1.6137975454330444, -1.238987922668457], [-0.25038400292396545, 0.08795643597841263], [0.7106817960739136, -1.2322286367416382]], [[-0.985375165939331, 0.6429592370986938], [1.4809460639953613, -1.3638676404953003], [-1.0396465063095093, 0.5943731069564819], [-1.0630594491958618, 0.7182422876358032], [-1.205427646636963, 0.684691309928894], [1.4944125413894653, -0.9940381646156311], [-1.8701205253601074, 1.347280740737915], [0.9273636937141418, -1.1799087524414062], [-1.8888989686965942, 1.4261785745620728], [-1.839314341545105, 1.3662489652633667], [1.7329603433609009, -1.3956037759780884], [1.7385199069976807, -1.2939633131027222], [1.3697986602783203, -0.8054693937301636], [0.9347332119941711, -0.8859449028968811], [-0.13956084847450256, -0.15878507494926453], [-1.3083992004394531, 1.0668489933013916], [1.653890609741211, -1.188476324081421], [0.374112069606781, -0.7993972897529602], [1.3579628467559814, -1.3992348909378052], [0.29341843724250793, -0.911550760269165], [-0.025416813790798187, -0.47614479064941406], [-0.8422257304191589, 0.7345146536827087], [-0.5731002688407898, 0.20096780359745026], [-1.5287456512451172, 1.206510066986084], [-1.7531812191009521, 1.342463731765747], [-1.4491372108459473, 1.0624133348464966], [-0.7476765513420105, 0.448014497756958], [-1.7707905769348145, 1.1420387029647827], [-0.8523138761520386, 0.5863540768623352], [-0.48151567578315735, 0.1602671891450882], [-0.3987066447734833, -0.09821871668100357], [-1.1054818630218506, 0.6337270736694336]], [[0.1202380433678627, -0.39873090386390686], [-1.394397258758545, 0.9328109622001648], [-0.030099783092737198, -0.4476834535598755], [-1.3914895057678223, 0.9381343722343445], [-1.618499755859375, 1.225555419921875], [-1.2277569770812988, 0.8073989748954773], [0.006732153240591288, 0.3230944573879242], [-2.0173182487487793, 1.4241585731506348], [1.240343451499939, -1.1883981227874756], [0.9361522197723389, -1.2833536863327026], [1.7078368663787842, -1.2948274612426758], [0.3676978647708893, -0.43923741579055786], [-0.23635777831077576, 0.12413907796144485], [-0.6707767844200134, 0.3594840168952942], [-1.7669841051101685, 1.3406243324279785], [-1.8232656717300415, 1.2806230783462524], [1.3174538612365723, -1.037301778793335], [-1.9721606969833374, 1.4318389892578125], [-0.034208644181489944, -0.22585594654083252], [-1.339600682258606, 0.9433599710464478], [-1.5619165897369385, 1.094744324684143], [-1.9139821529388428, 1.394484043121338], [0.14652691781520844, -0.7534851431846619], [-0.6268069744110107, 0.4845423996448517], [-0.4105498194694519, -0.1696736067533493], [-1.304558515548706, 0.8351976275444031], [-0.7402167320251465, 0.24015401303768158], [-0.5298377275466919, -0.1273588091135025], [-0.18013989925384521, -0.26014286279678345], [-0.6876742243766785, 0.9273666143417358], [-1.93375563621521, 1.4017090797424316], [-1.9491708278656006, 1.4924453496932983]], [[-1.264087438583374, 1.0576518774032593], [-1.830161452293396, 1.3661478757858276], [0.24144403636455536, -0.625034511089325], [-1.6134636402130127, 1.003108024597168], [-0.08806717395782471, -0.2921029329299927], [-1.6651912927627563, 1.3129069805145264], [1.6255011558532715, -1.159806251525879], [0.21546848118305206, -0.09299900382757187], [-0.7790269255638123, 0.16234275698661804], [-0.7786767482757568, 0.27169373631477356], [-0.5556191205978394, 0.1634082943201065], [-0.015156801789999008, -0.4424133896827698], [1.0998786687850952, -1.2805150747299194], [1.714443325996399, -1.3750571012496948], [-1.9978294372558594, 1.4319913387298584], [-1.5964820384979248, 0.9947459697723389], [-1.984641671180725, 1.3290263414382935], [-0.7535266876220703, 0.4023343026638031], [0.09118464589118958, -0.3636513352394104], [-1.9198641777038574, 1.271989345550537], [1.6429698467254639, -1.078545093536377], [-1.0290632247924805, 0.8355690836906433], [-1.5893498659133911, 1.1353764533996582], [-0.9948354959487915, 0.8540223240852356], [-1.296112060546875, 0.8067991137504578], [1.3513785600662231, -0.972180187702179], [0.18270306289196014, -0.4487994313240051], [0.6178674697875977, -1.016510248184204], [-1.4850199222564697, 1.1225638389587402], [-1.2803759574890137, 0.7449930310249329], [-0.9107723832130432, 0.3385877013206482], [-0.7875546813011169, 0.36224812269210815]], [[1.3939476013183594, -1.2953509092330933], [-1.4143567085266113, 0.939624011516571], [1.0584676265716553, -1.2886804342269897], [-1.2746156454086304, 0.7605875134468079], [-1.6622401475906372, 1.178850531578064], [-1.1280620098114014, 0.9407526850700378], [-1.2091734409332275, 0.7805174589157104], [-1.6941035985946655, 1.2543303966522217], [-0.37344393134117126, 0.020640673115849495], [0.5000045299530029, 0.040269602090120316], [-1.948455810546875, 1.5371509790420532], [-1.3380217552185059, 0.8914269208908081], [-1.6181519031524658, 1.0788038969039917], [-1.8047785758972168, 1.2772811651229858], [-0.6218520998954773, 0.16759605705738068], [-0.5882155299186707, 0.47777360677719116], [-1.563275694847107, 1.099713683128357], [-1.4808826446533203, 1.0599952936172485], [-0.5231963396072388, 0.4074958860874176], [-1.5399292707443237, 1.1397548913955688], [-1.6546629667282104, 1.3653992414474487], [-0.8700743317604065, 0.3514702022075653], [-1.1521486043930054, 0.8058800101280212], [-1.5968056917190552, 1.179046392440796], [-1.891095757484436, 1.2309114933013916], [0.8007772564888, -1.1080836057662964], [-1.8982726335525513, 1.4125744104385376], [-1.6562488079071045, 1.1485391855239868], [1.5974082946777344, -1.408483862876892], [-0.6972969770431519, 0.39353281259536743], [0.02996632643043995, -0.465761661529541], [-0.9849336743354797, 0.6694002151489258]], [[0.3525831997394562, -0.7134194374084473], [1.4306185245513916, -1.070969820022583], [1.3940763473510742, -1.2512645721435547], [-0.9541851878166199, 0.5597265362739563], [-0.7394235730171204, 0.38880255818367004], [1.0686991214752197, -0.8597494959831238], [-0.417537659406662, 0.11147056519985199], [0.6394367814064026, -0.6529821753501892], [-0.6283408403396606, 0.17554059624671936], [-1.5226553678512573, 0.9810754060745239], [0.6214752793312073, -1.0637866258621216], [0.5411103367805481, -0.9771086573600769], [-1.0730781555175781, 0.6770288944244385], [-1.3956325054168701, 1.0488934516906738], [0.34747326374053955, -0.3177958130836487], [1.8084924221038818, -1.31282639503479], [-1.24660325050354, 0.9069299101829529], [-1.6789058446884155, 1.189440131187439], [-1.787163496017456, 1.1961851119995117], [-0.8487533330917358, 0.43059319257736206], [0.16676980257034302, -0.5600742101669312], [-1.7594566345214844, 0.9515061974525452], [-0.19145312905311584, -0.017468005418777466], [-0.9725739359855652, 0.7503663301467896], [0.5918816924095154, -1.0655405521392822], [-0.5003306865692139, -0.02096840925514698], [1.479743242263794, -1.1732105016708374], [-2.0054025650024414, 1.420784592628479], [1.5539636611938477, -1.209991216659546], [0.6211817264556885, -0.9253778457641602], [-0.6943976283073425, 0.16032573580741882], [-0.7998771667480469, 0.2746583819389343]], [[1.2839075326919556, -0.7462335228919983], [-1.7913507223129272, 1.2953848838806152], [-1.8610373735427856, 1.3077070713043213], [-0.028950845822691917, -0.36825722455978394], [-0.7175137996673584, 0.23116213083267212], [-1.5154527425765991, 1.234350562095642], [-1.921338438987732, 1.3882062435150146], [1.651580572128296, -1.2626687288284302], [-0.161772683262825, 0.0046342043206095695], [-0.8199195861816406, 0.8658596277236938], [-1.7475693225860596, 1.3218919038772583], [-1.8923213481903076, 1.2217832803726196], [-1.9586923122406006, 1.3868119716644287], [-1.0189077854156494, 0.5187710523605347], [-1.0897295475006104, 1.1924407482147217], [-1.864625334739685, 1.2323256731033325]]]\n",
            "True_labels:  [[0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0], [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0], [1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0], [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0], [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1], [1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0], [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0], [0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1], [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0], [0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1], [1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1], [1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1], [0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0], [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0], [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0], [1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1], [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1], [0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1], [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0], [0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1], [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1], [1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1], [1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0], [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1], [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0], [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1], [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0], [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1], [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1], [0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1], [1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0], [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0], [1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0], [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1], [0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1], [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]]\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HbgazjIlhGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0737a3-6c54-496b-adbe-320b85c024bb"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (labels_dev.sum(), len(labels_dev), (labels_dev.sum() / len(labels_dev) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 1071 of 2032 (52.71%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANhZEk7irYQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e97039-53c8-452d-fa50-370fce1cddcb"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "print(\"Len_true_labels: \", len(true_labels))\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  print(pred_labels_i)\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Len:  64\n",
            "[1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0]\n",
            "[0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1]\n",
            "[1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1]\n",
            "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0]\n",
            "[1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1]\n",
            "[1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0]\n",
            "[1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0]\n",
            "[1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1]\n",
            "[1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0]\n",
            "[0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1]\n",
            "[0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1]\n",
            "[0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1]\n",
            "[1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0]\n",
            "[1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0]\n",
            "[0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1]\n",
            "[1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0]\n",
            "[0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1]\n",
            "[1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0]\n",
            "[0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1]\n",
            "[1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0]\n",
            "[1 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1]\n",
            "[1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1]\n",
            "[0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1]\n",
            "[0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1]\n",
            "[1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1]\n",
            "[0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0]\n",
            "[1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0]\n",
            "[1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1]\n",
            "[1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 1]\n",
            "[1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0]\n",
            "[0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1]\n",
            "[1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "[1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            "[1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1]\n",
            "[0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0]\n",
            "[1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1]\n",
            "[0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]\n",
            "[0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0]\n",
            "[0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0]\n",
            "[1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1]\n",
            "[0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0]\n",
            "[1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0]\n",
            "[1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0]\n",
            "[1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0]\n",
            "[1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1]\n",
            "[1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1]\n",
            "[0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1]\n",
            "[0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1]\n",
            "[0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qTU9WjBt6fD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9442e937-e36a-4e38-b42b-ba1eb6f97c0b"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTX81rJ2t7M5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f441195b-f6ed-423e-e601-7782d1631434"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR9UiX5furIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144acba8-6228-4501-fb50-75f2958b75c9"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/spiece.model',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4W9SsIpqIKE",
        "outputId": "f80369df-27bb-4ca1-a1cf-64ed29e88ad0"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# output_dir = '/content/drive/My Drive/saved_model/KoBERT_model_1'\n",
        "output_dir = './model_save/'\n",
        "\n",
        "print(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "./model_save/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xfZW4WbqTIT",
        "outputId": "d9963965-7f31-4667-ea76-1c26137150c5"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iMllmU9tcJw",
        "outputId": "56ed33b1-9f49-4def-e4c2-9ee4d915d14c"
      },
      "source": [
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "print(\"sentences_test:\", sentences_test)\n",
        "# 모든 문장에 대하여\n",
        "for sent in sentences_test:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) 문장을 토크나이저 합니다. Tokenize the sentence.\n",
        "    #   (2) [CLS]를 모든 문장의 가장 앞에 삽입합니다.\n",
        "    #   (3) [SEP]을 모든 문장의 가장 뒤에 삽입합니다.\n",
        "    #       CLS, SEP는 토큰 임베딩 분야의 특수 토큰으로,\n",
        "    #       CLS는 special CLaSsification token, SEP은 sepcial SEParator token을 의미\n",
        "    #   (4) 토큰들을 그들의 단어 아이디와 매치시킵니다.\n",
        "    #   (5) 문장의 길이는 'max_length' 수치에 맞게 늘려주거나 줄여줍니다.\n",
        "    #       Pad: 특정 형상의 배열로 변형할 때 빈자리를 0으로 채워준다는 의미\n",
        "    #   (6) [PAD] 토큰을 위한 attention mask 생성\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                         # 인코딩할 문장 자리 / 문장을 인코딩\n",
        "                        add_special_tokens = True,    # 특수 토큰 [CLS]와 [SEP] 추가\n",
        "                        max_length = 64,              # max_length에 맞게 모든 문장 패딩 & 축소\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True, # Attention Mask 구축 / 자료 구조는 tensor 형태\n",
        "                                                      # Attention Mask는 단어 배치와 동일하게 \"1\" 생성 \n",
        "                        return_tensors = 'pt',        # 인코딩된 문장을 pytorch 텐서 형태로 변경\n",
        "                                                      # tensorflow를 사용하고 있다면 return_tensors = 'tf'라고 씀\n",
        "                   )\n",
        "\n",
        "    # 인코딩된 문장들 List[input_ids_test]에 넣기 but input_ids_test은 이미\n",
        "    input_ids_test.append(encoded_dict['input_ids'])\n",
        "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "index_test = torch.tensor(index_test)\n",
        "\n",
        "print(\"Input_id_test: \", input_ids_test)\n",
        "print(\"Attention_mask_test: \", attention_masks_test)\n",
        "print(\"Index_test: \", index_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences_test: ['나는 철수에게 공을 던져다 주었다.' '먹은 것을 다 소화시켜야 한다.' '그가 노래를 부르고는 내가 피아노를 쳤다.' ...\n",
            " '그는 나를 바보 여긴다.' '수호는 모든 일에 전혀 무감각하다.' '나는 할아버지가 제일 무서우시다.']\n",
            "Input_id_test:  tensor([[   2, 1375, 4473,  ...,    1,    1,    1],\n",
            "        [   2, 2010, 7086,  ...,    1,    1,    1],\n",
            "        [   2, 1186, 1479,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2, 1191, 1370,  ...,    1,    1,    1],\n",
            "        [   2, 2872, 7926,  ...,    1,    1,    1],\n",
            "        [   2, 1375, 4977,  ...,    1,    1,    1]])\n",
            "Attention_mask_test:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "Index_test:  tensor([   1,    2,    3,  ..., 1058, 1059, 1060])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8YtZxpMsmrf"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_loaded = model_loaded.to(device)\n",
        "input_ids_test = input_ids_test.to(device)\n",
        "attention_masks_test = attention_masks_test.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBltg1k_tBfz",
        "outputId": "c428025a-0c80-4297-f186-37007dcd9510"
      },
      "source": [
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  outputs = model_loaded(input_ids_test, token_type_ids=None, attention_mask=attention_masks_test)\n",
        "test_logits = outputs[0]\n",
        "test_logits = test_logits.detach().cpu().numpy()\n",
        "test_logits = np.argmax(test_logits, axis=1).flatten()\n",
        "labels_test = []\n",
        "for i in range(len(test_logits)):\n",
        "    index = test_logits[i]\n",
        "    if index == 1:\n",
        "      labels_test.append(1)\n",
        "      # print(\"1(True)\")\n",
        "    else:\n",
        "      labels_test.append(0)\n",
        "      # print(\"0(False)\")\n",
        "result = labels_test\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSxBM4vKKJ7"
      },
      "source": [
        "import json\n",
        "\n",
        "dict_result = [{\"idx\" : idx, \"label\" : data} for idx, data in enumerate(result)]\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/COLA_Test_HJ.json\", \"w\") as json_file:\n",
        "    json_result = {\"cola\" : dict_result}\n",
        "    json.dump(json_result, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7TGEHLBMoNL",
        "outputId": "d75521c5-eca6-4a37-a11a-646488995a8b"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/COLA_Test_HJ.json') as json_file:\n",
        "    COLA = json.load(json_file)\n",
        "    print(COLA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cola': [{'idx': 0, 'label': 1}, {'idx': 1, 'label': 1}, {'idx': 2, 'label': 0}, {'idx': 3, 'label': 1}, {'idx': 4, 'label': 0}, {'idx': 5, 'label': 1}, {'idx': 6, 'label': 1}, {'idx': 7, 'label': 1}, {'idx': 8, 'label': 0}, {'idx': 9, 'label': 0}, {'idx': 10, 'label': 1}, {'idx': 11, 'label': 0}, {'idx': 12, 'label': 1}, {'idx': 13, 'label': 1}, {'idx': 14, 'label': 1}, {'idx': 15, 'label': 1}, {'idx': 16, 'label': 0}, {'idx': 17, 'label': 0}, {'idx': 18, 'label': 1}, {'idx': 19, 'label': 0}, {'idx': 20, 'label': 1}, {'idx': 21, 'label': 1}, {'idx': 22, 'label': 1}, {'idx': 23, 'label': 1}, {'idx': 24, 'label': 0}, {'idx': 25, 'label': 1}, {'idx': 26, 'label': 0}, {'idx': 27, 'label': 0}, {'idx': 28, 'label': 0}, {'idx': 29, 'label': 1}, {'idx': 30, 'label': 1}, {'idx': 31, 'label': 0}, {'idx': 32, 'label': 1}, {'idx': 33, 'label': 0}, {'idx': 34, 'label': 0}, {'idx': 35, 'label': 1}, {'idx': 36, 'label': 0}, {'idx': 37, 'label': 1}, {'idx': 38, 'label': 0}, {'idx': 39, 'label': 1}, {'idx': 40, 'label': 0}, {'idx': 41, 'label': 1}, {'idx': 42, 'label': 1}, {'idx': 43, 'label': 1}, {'idx': 44, 'label': 1}, {'idx': 45, 'label': 1}, {'idx': 46, 'label': 0}, {'idx': 47, 'label': 0}, {'idx': 48, 'label': 0}, {'idx': 49, 'label': 1}, {'idx': 50, 'label': 1}, {'idx': 51, 'label': 0}, {'idx': 52, 'label': 1}, {'idx': 53, 'label': 1}, {'idx': 54, 'label': 0}, {'idx': 55, 'label': 1}, {'idx': 56, 'label': 1}, {'idx': 57, 'label': 1}, {'idx': 58, 'label': 0}, {'idx': 59, 'label': 1}, {'idx': 60, 'label': 1}, {'idx': 61, 'label': 1}, {'idx': 62, 'label': 1}, {'idx': 63, 'label': 1}, {'idx': 64, 'label': 1}, {'idx': 65, 'label': 1}, {'idx': 66, 'label': 0}, {'idx': 67, 'label': 1}, {'idx': 68, 'label': 1}, {'idx': 69, 'label': 1}, {'idx': 70, 'label': 0}, {'idx': 71, 'label': 0}, {'idx': 72, 'label': 1}, {'idx': 73, 'label': 0}, {'idx': 74, 'label': 1}, {'idx': 75, 'label': 1}, {'idx': 76, 'label': 0}, {'idx': 77, 'label': 1}, {'idx': 78, 'label': 0}, {'idx': 79, 'label': 1}, {'idx': 80, 'label': 1}, {'idx': 81, 'label': 1}, {'idx': 82, 'label': 0}, {'idx': 83, 'label': 1}, {'idx': 84, 'label': 1}, {'idx': 85, 'label': 1}, {'idx': 86, 'label': 0}, {'idx': 87, 'label': 0}, {'idx': 88, 'label': 1}, {'idx': 89, 'label': 1}, {'idx': 90, 'label': 0}, {'idx': 91, 'label': 1}, {'idx': 92, 'label': 0}, {'idx': 93, 'label': 0}, {'idx': 94, 'label': 1}, {'idx': 95, 'label': 1}, {'idx': 96, 'label': 1}, {'idx': 97, 'label': 0}, {'idx': 98, 'label': 1}, {'idx': 99, 'label': 0}, {'idx': 100, 'label': 1}, {'idx': 101, 'label': 1}, {'idx': 102, 'label': 0}, {'idx': 103, 'label': 1}, {'idx': 104, 'label': 1}, {'idx': 105, 'label': 0}, {'idx': 106, 'label': 1}, {'idx': 107, 'label': 1}, {'idx': 108, 'label': 1}, {'idx': 109, 'label': 1}, {'idx': 110, 'label': 1}, {'idx': 111, 'label': 0}, {'idx': 112, 'label': 1}, {'idx': 113, 'label': 0}, {'idx': 114, 'label': 0}, {'idx': 115, 'label': 1}, {'idx': 116, 'label': 0}, {'idx': 117, 'label': 1}, {'idx': 118, 'label': 1}, {'idx': 119, 'label': 0}, {'idx': 120, 'label': 0}, {'idx': 121, 'label': 0}, {'idx': 122, 'label': 1}, {'idx': 123, 'label': 1}, {'idx': 124, 'label': 0}, {'idx': 125, 'label': 0}, {'idx': 126, 'label': 0}, {'idx': 127, 'label': 0}, {'idx': 128, 'label': 0}, {'idx': 129, 'label': 0}, {'idx': 130, 'label': 1}, {'idx': 131, 'label': 1}, {'idx': 132, 'label': 1}, {'idx': 133, 'label': 1}, {'idx': 134, 'label': 0}, {'idx': 135, 'label': 1}, {'idx': 136, 'label': 0}, {'idx': 137, 'label': 1}, {'idx': 138, 'label': 0}, {'idx': 139, 'label': 0}, {'idx': 140, 'label': 0}, {'idx': 141, 'label': 1}, {'idx': 142, 'label': 1}, {'idx': 143, 'label': 1}, {'idx': 144, 'label': 1}, {'idx': 145, 'label': 1}, {'idx': 146, 'label': 0}, {'idx': 147, 'label': 1}, {'idx': 148, 'label': 0}, {'idx': 149, 'label': 1}, {'idx': 150, 'label': 1}, {'idx': 151, 'label': 0}, {'idx': 152, 'label': 1}, {'idx': 153, 'label': 1}, {'idx': 154, 'label': 1}, {'idx': 155, 'label': 0}, {'idx': 156, 'label': 1}, {'idx': 157, 'label': 1}, {'idx': 158, 'label': 1}, {'idx': 159, 'label': 0}, {'idx': 160, 'label': 1}, {'idx': 161, 'label': 0}, {'idx': 162, 'label': 0}, {'idx': 163, 'label': 0}, {'idx': 164, 'label': 0}, {'idx': 165, 'label': 1}, {'idx': 166, 'label': 0}, {'idx': 167, 'label': 1}, {'idx': 168, 'label': 0}, {'idx': 169, 'label': 0}, {'idx': 170, 'label': 1}, {'idx': 171, 'label': 0}, {'idx': 172, 'label': 1}, {'idx': 173, 'label': 1}, {'idx': 174, 'label': 0}, {'idx': 175, 'label': 0}, {'idx': 176, 'label': 1}, {'idx': 177, 'label': 0}, {'idx': 178, 'label': 1}, {'idx': 179, 'label': 1}, {'idx': 180, 'label': 1}, {'idx': 181, 'label': 1}, {'idx': 182, 'label': 0}, {'idx': 183, 'label': 1}, {'idx': 184, 'label': 0}, {'idx': 185, 'label': 1}, {'idx': 186, 'label': 0}, {'idx': 187, 'label': 1}, {'idx': 188, 'label': 0}, {'idx': 189, 'label': 1}, {'idx': 190, 'label': 0}, {'idx': 191, 'label': 1}, {'idx': 192, 'label': 1}, {'idx': 193, 'label': 1}, {'idx': 194, 'label': 1}, {'idx': 195, 'label': 0}, {'idx': 196, 'label': 0}, {'idx': 197, 'label': 1}, {'idx': 198, 'label': 1}, {'idx': 199, 'label': 1}, {'idx': 200, 'label': 0}, {'idx': 201, 'label': 0}, {'idx': 202, 'label': 1}, {'idx': 203, 'label': 0}, {'idx': 204, 'label': 0}, {'idx': 205, 'label': 0}, {'idx': 206, 'label': 1}, {'idx': 207, 'label': 1}, {'idx': 208, 'label': 1}, {'idx': 209, 'label': 1}, {'idx': 210, 'label': 0}, {'idx': 211, 'label': 1}, {'idx': 212, 'label': 0}, {'idx': 213, 'label': 1}, {'idx': 214, 'label': 0}, {'idx': 215, 'label': 1}, {'idx': 216, 'label': 1}, {'idx': 217, 'label': 1}, {'idx': 218, 'label': 1}, {'idx': 219, 'label': 1}, {'idx': 220, 'label': 1}, {'idx': 221, 'label': 1}, {'idx': 222, 'label': 0}, {'idx': 223, 'label': 0}, {'idx': 224, 'label': 1}, {'idx': 225, 'label': 1}, {'idx': 226, 'label': 1}, {'idx': 227, 'label': 1}, {'idx': 228, 'label': 1}, {'idx': 229, 'label': 1}, {'idx': 230, 'label': 0}, {'idx': 231, 'label': 1}, {'idx': 232, 'label': 1}, {'idx': 233, 'label': 1}, {'idx': 234, 'label': 1}, {'idx': 235, 'label': 0}, {'idx': 236, 'label': 1}, {'idx': 237, 'label': 1}, {'idx': 238, 'label': 0}, {'idx': 239, 'label': 0}, {'idx': 240, 'label': 1}, {'idx': 241, 'label': 0}, {'idx': 242, 'label': 1}, {'idx': 243, 'label': 1}, {'idx': 244, 'label': 0}, {'idx': 245, 'label': 0}, {'idx': 246, 'label': 1}, {'idx': 247, 'label': 1}, {'idx': 248, 'label': 0}, {'idx': 249, 'label': 1}, {'idx': 250, 'label': 1}, {'idx': 251, 'label': 1}, {'idx': 252, 'label': 1}, {'idx': 253, 'label': 0}, {'idx': 254, 'label': 0}, {'idx': 255, 'label': 1}, {'idx': 256, 'label': 1}, {'idx': 257, 'label': 1}, {'idx': 258, 'label': 1}, {'idx': 259, 'label': 1}, {'idx': 260, 'label': 1}, {'idx': 261, 'label': 1}, {'idx': 262, 'label': 1}, {'idx': 263, 'label': 1}, {'idx': 264, 'label': 1}, {'idx': 265, 'label': 1}, {'idx': 266, 'label': 1}, {'idx': 267, 'label': 1}, {'idx': 268, 'label': 1}, {'idx': 269, 'label': 0}, {'idx': 270, 'label': 1}, {'idx': 271, 'label': 0}, {'idx': 272, 'label': 1}, {'idx': 273, 'label': 0}, {'idx': 274, 'label': 1}, {'idx': 275, 'label': 1}, {'idx': 276, 'label': 0}, {'idx': 277, 'label': 0}, {'idx': 278, 'label': 0}, {'idx': 279, 'label': 0}, {'idx': 280, 'label': 0}, {'idx': 281, 'label': 1}, {'idx': 282, 'label': 1}, {'idx': 283, 'label': 1}, {'idx': 284, 'label': 0}, {'idx': 285, 'label': 1}, {'idx': 286, 'label': 1}, {'idx': 287, 'label': 1}, {'idx': 288, 'label': 1}, {'idx': 289, 'label': 1}, {'idx': 290, 'label': 1}, {'idx': 291, 'label': 1}, {'idx': 292, 'label': 1}, {'idx': 293, 'label': 0}, {'idx': 294, 'label': 1}, {'idx': 295, 'label': 1}, {'idx': 296, 'label': 1}, {'idx': 297, 'label': 0}, {'idx': 298, 'label': 1}, {'idx': 299, 'label': 0}, {'idx': 300, 'label': 1}, {'idx': 301, 'label': 1}, {'idx': 302, 'label': 0}, {'idx': 303, 'label': 0}, {'idx': 304, 'label': 1}, {'idx': 305, 'label': 1}, {'idx': 306, 'label': 0}, {'idx': 307, 'label': 1}, {'idx': 308, 'label': 1}, {'idx': 309, 'label': 1}, {'idx': 310, 'label': 1}, {'idx': 311, 'label': 1}, {'idx': 312, 'label': 0}, {'idx': 313, 'label': 0}, {'idx': 314, 'label': 0}, {'idx': 315, 'label': 1}, {'idx': 316, 'label': 1}, {'idx': 317, 'label': 1}, {'idx': 318, 'label': 1}, {'idx': 319, 'label': 0}, {'idx': 320, 'label': 1}, {'idx': 321, 'label': 0}, {'idx': 322, 'label': 1}, {'idx': 323, 'label': 0}, {'idx': 324, 'label': 0}, {'idx': 325, 'label': 1}, {'idx': 326, 'label': 1}, {'idx': 327, 'label': 1}, {'idx': 328, 'label': 0}, {'idx': 329, 'label': 0}, {'idx': 330, 'label': 1}, {'idx': 331, 'label': 1}, {'idx': 332, 'label': 1}, {'idx': 333, 'label': 1}, {'idx': 334, 'label': 1}, {'idx': 335, 'label': 1}, {'idx': 336, 'label': 1}, {'idx': 337, 'label': 1}, {'idx': 338, 'label': 0}, {'idx': 339, 'label': 1}, {'idx': 340, 'label': 1}, {'idx': 341, 'label': 1}, {'idx': 342, 'label': 1}, {'idx': 343, 'label': 0}, {'idx': 344, 'label': 0}, {'idx': 345, 'label': 1}, {'idx': 346, 'label': 1}, {'idx': 347, 'label': 1}, {'idx': 348, 'label': 0}, {'idx': 349, 'label': 1}, {'idx': 350, 'label': 0}, {'idx': 351, 'label': 0}, {'idx': 352, 'label': 1}, {'idx': 353, 'label': 0}, {'idx': 354, 'label': 0}, {'idx': 355, 'label': 1}, {'idx': 356, 'label': 1}, {'idx': 357, 'label': 0}, {'idx': 358, 'label': 1}, {'idx': 359, 'label': 0}, {'idx': 360, 'label': 1}, {'idx': 361, 'label': 1}, {'idx': 362, 'label': 1}, {'idx': 363, 'label': 1}, {'idx': 364, 'label': 1}, {'idx': 365, 'label': 0}, {'idx': 366, 'label': 1}, {'idx': 367, 'label': 1}, {'idx': 368, 'label': 1}, {'idx': 369, 'label': 1}, {'idx': 370, 'label': 1}, {'idx': 371, 'label': 1}, {'idx': 372, 'label': 0}, {'idx': 373, 'label': 1}, {'idx': 374, 'label': 1}, {'idx': 375, 'label': 1}, {'idx': 376, 'label': 1}, {'idx': 377, 'label': 1}, {'idx': 378, 'label': 1}, {'idx': 379, 'label': 1}, {'idx': 380, 'label': 0}, {'idx': 381, 'label': 1}, {'idx': 382, 'label': 0}, {'idx': 383, 'label': 0}, {'idx': 384, 'label': 0}, {'idx': 385, 'label': 1}, {'idx': 386, 'label': 0}, {'idx': 387, 'label': 1}, {'idx': 388, 'label': 1}, {'idx': 389, 'label': 0}, {'idx': 390, 'label': 1}, {'idx': 391, 'label': 1}, {'idx': 392, 'label': 0}, {'idx': 393, 'label': 1}, {'idx': 394, 'label': 1}, {'idx': 395, 'label': 1}, {'idx': 396, 'label': 1}, {'idx': 397, 'label': 0}, {'idx': 398, 'label': 0}, {'idx': 399, 'label': 1}, {'idx': 400, 'label': 0}, {'idx': 401, 'label': 1}, {'idx': 402, 'label': 0}, {'idx': 403, 'label': 0}, {'idx': 404, 'label': 1}, {'idx': 405, 'label': 0}, {'idx': 406, 'label': 1}, {'idx': 407, 'label': 1}, {'idx': 408, 'label': 1}, {'idx': 409, 'label': 1}, {'idx': 410, 'label': 1}, {'idx': 411, 'label': 1}, {'idx': 412, 'label': 0}, {'idx': 413, 'label': 0}, {'idx': 414, 'label': 1}, {'idx': 415, 'label': 1}, {'idx': 416, 'label': 1}, {'idx': 417, 'label': 1}, {'idx': 418, 'label': 0}, {'idx': 419, 'label': 0}, {'idx': 420, 'label': 1}, {'idx': 421, 'label': 1}, {'idx': 422, 'label': 0}, {'idx': 423, 'label': 0}, {'idx': 424, 'label': 1}, {'idx': 425, 'label': 1}, {'idx': 426, 'label': 1}, {'idx': 427, 'label': 1}, {'idx': 428, 'label': 0}, {'idx': 429, 'label': 1}, {'idx': 430, 'label': 1}, {'idx': 431, 'label': 1}, {'idx': 432, 'label': 0}, {'idx': 433, 'label': 1}, {'idx': 434, 'label': 1}, {'idx': 435, 'label': 1}, {'idx': 436, 'label': 1}, {'idx': 437, 'label': 0}, {'idx': 438, 'label': 0}, {'idx': 439, 'label': 1}, {'idx': 440, 'label': 1}, {'idx': 441, 'label': 1}, {'idx': 442, 'label': 1}, {'idx': 443, 'label': 0}, {'idx': 444, 'label': 1}, {'idx': 445, 'label': 0}, {'idx': 446, 'label': 1}, {'idx': 447, 'label': 1}, {'idx': 448, 'label': 1}, {'idx': 449, 'label': 1}, {'idx': 450, 'label': 1}, {'idx': 451, 'label': 1}, {'idx': 452, 'label': 1}, {'idx': 453, 'label': 0}, {'idx': 454, 'label': 1}, {'idx': 455, 'label': 1}, {'idx': 456, 'label': 1}, {'idx': 457, 'label': 1}, {'idx': 458, 'label': 1}, {'idx': 459, 'label': 1}, {'idx': 460, 'label': 1}, {'idx': 461, 'label': 0}, {'idx': 462, 'label': 1}, {'idx': 463, 'label': 1}, {'idx': 464, 'label': 1}, {'idx': 465, 'label': 1}, {'idx': 466, 'label': 1}, {'idx': 467, 'label': 0}, {'idx': 468, 'label': 1}, {'idx': 469, 'label': 1}, {'idx': 470, 'label': 1}, {'idx': 471, 'label': 1}, {'idx': 472, 'label': 0}, {'idx': 473, 'label': 1}, {'idx': 474, 'label': 0}, {'idx': 475, 'label': 1}, {'idx': 476, 'label': 1}, {'idx': 477, 'label': 0}, {'idx': 478, 'label': 1}, {'idx': 479, 'label': 0}, {'idx': 480, 'label': 1}, {'idx': 481, 'label': 0}, {'idx': 482, 'label': 1}, {'idx': 483, 'label': 1}, {'idx': 484, 'label': 0}, {'idx': 485, 'label': 1}, {'idx': 486, 'label': 0}, {'idx': 487, 'label': 0}, {'idx': 488, 'label': 1}, {'idx': 489, 'label': 1}, {'idx': 490, 'label': 0}, {'idx': 491, 'label': 1}, {'idx': 492, 'label': 1}, {'idx': 493, 'label': 0}, {'idx': 494, 'label': 0}, {'idx': 495, 'label': 1}, {'idx': 496, 'label': 1}, {'idx': 497, 'label': 0}, {'idx': 498, 'label': 1}, {'idx': 499, 'label': 1}, {'idx': 500, 'label': 1}, {'idx': 501, 'label': 0}, {'idx': 502, 'label': 1}, {'idx': 503, 'label': 0}, {'idx': 504, 'label': 0}, {'idx': 505, 'label': 0}, {'idx': 506, 'label': 1}, {'idx': 507, 'label': 1}, {'idx': 508, 'label': 0}, {'idx': 509, 'label': 1}, {'idx': 510, 'label': 1}, {'idx': 511, 'label': 0}, {'idx': 512, 'label': 1}, {'idx': 513, 'label': 0}, {'idx': 514, 'label': 1}, {'idx': 515, 'label': 1}, {'idx': 516, 'label': 1}, {'idx': 517, 'label': 1}, {'idx': 518, 'label': 1}, {'idx': 519, 'label': 1}, {'idx': 520, 'label': 1}, {'idx': 521, 'label': 1}, {'idx': 522, 'label': 1}, {'idx': 523, 'label': 1}, {'idx': 524, 'label': 1}, {'idx': 525, 'label': 1}, {'idx': 526, 'label': 0}, {'idx': 527, 'label': 0}, {'idx': 528, 'label': 0}, {'idx': 529, 'label': 1}, {'idx': 530, 'label': 0}, {'idx': 531, 'label': 1}, {'idx': 532, 'label': 1}, {'idx': 533, 'label': 1}, {'idx': 534, 'label': 0}, {'idx': 535, 'label': 1}, {'idx': 536, 'label': 1}, {'idx': 537, 'label': 1}, {'idx': 538, 'label': 0}, {'idx': 539, 'label': 1}, {'idx': 540, 'label': 1}, {'idx': 541, 'label': 1}, {'idx': 542, 'label': 0}, {'idx': 543, 'label': 0}, {'idx': 544, 'label': 1}, {'idx': 545, 'label': 1}, {'idx': 546, 'label': 0}, {'idx': 547, 'label': 1}, {'idx': 548, 'label': 0}, {'idx': 549, 'label': 0}, {'idx': 550, 'label': 0}, {'idx': 551, 'label': 0}, {'idx': 552, 'label': 0}, {'idx': 553, 'label': 1}, {'idx': 554, 'label': 1}, {'idx': 555, 'label': 1}, {'idx': 556, 'label': 0}, {'idx': 557, 'label': 1}, {'idx': 558, 'label': 1}, {'idx': 559, 'label': 1}, {'idx': 560, 'label': 0}, {'idx': 561, 'label': 0}, {'idx': 562, 'label': 1}, {'idx': 563, 'label': 1}, {'idx': 564, 'label': 0}, {'idx': 565, 'label': 0}, {'idx': 566, 'label': 1}, {'idx': 567, 'label': 1}, {'idx': 568, 'label': 1}, {'idx': 569, 'label': 1}, {'idx': 570, 'label': 1}, {'idx': 571, 'label': 1}, {'idx': 572, 'label': 1}, {'idx': 573, 'label': 1}, {'idx': 574, 'label': 0}, {'idx': 575, 'label': 0}, {'idx': 576, 'label': 0}, {'idx': 577, 'label': 0}, {'idx': 578, 'label': 1}, {'idx': 579, 'label': 1}, {'idx': 580, 'label': 0}, {'idx': 581, 'label': 1}, {'idx': 582, 'label': 0}, {'idx': 583, 'label': 1}, {'idx': 584, 'label': 1}, {'idx': 585, 'label': 0}, {'idx': 586, 'label': 0}, {'idx': 587, 'label': 1}, {'idx': 588, 'label': 0}, {'idx': 589, 'label': 0}, {'idx': 590, 'label': 1}, {'idx': 591, 'label': 0}, {'idx': 592, 'label': 0}, {'idx': 593, 'label': 0}, {'idx': 594, 'label': 1}, {'idx': 595, 'label': 0}, {'idx': 596, 'label': 1}, {'idx': 597, 'label': 0}, {'idx': 598, 'label': 1}, {'idx': 599, 'label': 0}, {'idx': 600, 'label': 0}, {'idx': 601, 'label': 0}, {'idx': 602, 'label': 0}, {'idx': 603, 'label': 0}, {'idx': 604, 'label': 1}, {'idx': 605, 'label': 1}, {'idx': 606, 'label': 0}, {'idx': 607, 'label': 1}, {'idx': 608, 'label': 0}, {'idx': 609, 'label': 0}, {'idx': 610, 'label': 1}, {'idx': 611, 'label': 0}, {'idx': 612, 'label': 1}, {'idx': 613, 'label': 0}, {'idx': 614, 'label': 0}, {'idx': 615, 'label': 1}, {'idx': 616, 'label': 1}, {'idx': 617, 'label': 0}, {'idx': 618, 'label': 0}, {'idx': 619, 'label': 1}, {'idx': 620, 'label': 0}, {'idx': 621, 'label': 0}, {'idx': 622, 'label': 1}, {'idx': 623, 'label': 1}, {'idx': 624, 'label': 0}, {'idx': 625, 'label': 0}, {'idx': 626, 'label': 0}, {'idx': 627, 'label': 0}, {'idx': 628, 'label': 0}, {'idx': 629, 'label': 1}, {'idx': 630, 'label': 1}, {'idx': 631, 'label': 0}, {'idx': 632, 'label': 1}, {'idx': 633, 'label': 0}, {'idx': 634, 'label': 0}, {'idx': 635, 'label': 1}, {'idx': 636, 'label': 0}, {'idx': 637, 'label': 1}, {'idx': 638, 'label': 1}, {'idx': 639, 'label': 1}, {'idx': 640, 'label': 0}, {'idx': 641, 'label': 0}, {'idx': 642, 'label': 1}, {'idx': 643, 'label': 0}, {'idx': 644, 'label': 1}, {'idx': 645, 'label': 0}, {'idx': 646, 'label': 1}, {'idx': 647, 'label': 1}, {'idx': 648, 'label': 1}, {'idx': 649, 'label': 1}, {'idx': 650, 'label': 1}, {'idx': 651, 'label': 1}, {'idx': 652, 'label': 0}, {'idx': 653, 'label': 1}, {'idx': 654, 'label': 1}, {'idx': 655, 'label': 1}, {'idx': 656, 'label': 1}, {'idx': 657, 'label': 0}, {'idx': 658, 'label': 0}, {'idx': 659, 'label': 0}, {'idx': 660, 'label': 1}, {'idx': 661, 'label': 1}, {'idx': 662, 'label': 0}, {'idx': 663, 'label': 1}, {'idx': 664, 'label': 0}, {'idx': 665, 'label': 0}, {'idx': 666, 'label': 0}, {'idx': 667, 'label': 1}, {'idx': 668, 'label': 1}, {'idx': 669, 'label': 1}, {'idx': 670, 'label': 1}, {'idx': 671, 'label': 1}, {'idx': 672, 'label': 0}, {'idx': 673, 'label': 0}, {'idx': 674, 'label': 0}, {'idx': 675, 'label': 1}, {'idx': 676, 'label': 0}, {'idx': 677, 'label': 0}, {'idx': 678, 'label': 1}, {'idx': 679, 'label': 0}, {'idx': 680, 'label': 0}, {'idx': 681, 'label': 0}, {'idx': 682, 'label': 1}, {'idx': 683, 'label': 1}, {'idx': 684, 'label': 1}, {'idx': 685, 'label': 1}, {'idx': 686, 'label': 1}, {'idx': 687, 'label': 0}, {'idx': 688, 'label': 1}, {'idx': 689, 'label': 0}, {'idx': 690, 'label': 1}, {'idx': 691, 'label': 1}, {'idx': 692, 'label': 1}, {'idx': 693, 'label': 1}, {'idx': 694, 'label': 1}, {'idx': 695, 'label': 1}, {'idx': 696, 'label': 0}, {'idx': 697, 'label': 0}, {'idx': 698, 'label': 0}, {'idx': 699, 'label': 0}, {'idx': 700, 'label': 0}, {'idx': 701, 'label': 1}, {'idx': 702, 'label': 1}, {'idx': 703, 'label': 1}, {'idx': 704, 'label': 1}, {'idx': 705, 'label': 0}, {'idx': 706, 'label': 1}, {'idx': 707, 'label': 0}, {'idx': 708, 'label': 0}, {'idx': 709, 'label': 0}, {'idx': 710, 'label': 0}, {'idx': 711, 'label': 1}, {'idx': 712, 'label': 0}, {'idx': 713, 'label': 0}, {'idx': 714, 'label': 0}, {'idx': 715, 'label': 1}, {'idx': 716, 'label': 1}, {'idx': 717, 'label': 0}, {'idx': 718, 'label': 1}, {'idx': 719, 'label': 1}, {'idx': 720, 'label': 1}, {'idx': 721, 'label': 1}, {'idx': 722, 'label': 1}, {'idx': 723, 'label': 1}, {'idx': 724, 'label': 0}, {'idx': 725, 'label': 0}, {'idx': 726, 'label': 1}, {'idx': 727, 'label': 1}, {'idx': 728, 'label': 1}, {'idx': 729, 'label': 1}, {'idx': 730, 'label': 0}, {'idx': 731, 'label': 0}, {'idx': 732, 'label': 0}, {'idx': 733, 'label': 1}, {'idx': 734, 'label': 0}, {'idx': 735, 'label': 0}, {'idx': 736, 'label': 1}, {'idx': 737, 'label': 0}, {'idx': 738, 'label': 1}, {'idx': 739, 'label': 1}, {'idx': 740, 'label': 1}, {'idx': 741, 'label': 0}, {'idx': 742, 'label': 0}, {'idx': 743, 'label': 1}, {'idx': 744, 'label': 0}, {'idx': 745, 'label': 0}, {'idx': 746, 'label': 1}, {'idx': 747, 'label': 1}, {'idx': 748, 'label': 0}, {'idx': 749, 'label': 1}, {'idx': 750, 'label': 1}, {'idx': 751, 'label': 0}, {'idx': 752, 'label': 1}, {'idx': 753, 'label': 1}, {'idx': 754, 'label': 1}, {'idx': 755, 'label': 0}, {'idx': 756, 'label': 1}, {'idx': 757, 'label': 0}, {'idx': 758, 'label': 1}, {'idx': 759, 'label': 1}, {'idx': 760, 'label': 1}, {'idx': 761, 'label': 1}, {'idx': 762, 'label': 1}, {'idx': 763, 'label': 1}, {'idx': 764, 'label': 1}, {'idx': 765, 'label': 1}, {'idx': 766, 'label': 1}, {'idx': 767, 'label': 0}, {'idx': 768, 'label': 0}, {'idx': 769, 'label': 0}, {'idx': 770, 'label': 1}, {'idx': 771, 'label': 1}, {'idx': 772, 'label': 1}, {'idx': 773, 'label': 0}, {'idx': 774, 'label': 0}, {'idx': 775, 'label': 1}, {'idx': 776, 'label': 1}, {'idx': 777, 'label': 1}, {'idx': 778, 'label': 1}, {'idx': 779, 'label': 0}, {'idx': 780, 'label': 0}, {'idx': 781, 'label': 1}, {'idx': 782, 'label': 0}, {'idx': 783, 'label': 1}, {'idx': 784, 'label': 1}, {'idx': 785, 'label': 1}, {'idx': 786, 'label': 1}, {'idx': 787, 'label': 1}, {'idx': 788, 'label': 0}, {'idx': 789, 'label': 1}, {'idx': 790, 'label': 0}, {'idx': 791, 'label': 0}, {'idx': 792, 'label': 1}, {'idx': 793, 'label': 0}, {'idx': 794, 'label': 1}, {'idx': 795, 'label': 0}, {'idx': 796, 'label': 1}, {'idx': 797, 'label': 1}, {'idx': 798, 'label': 0}, {'idx': 799, 'label': 0}, {'idx': 800, 'label': 0}, {'idx': 801, 'label': 1}, {'idx': 802, 'label': 1}, {'idx': 803, 'label': 0}, {'idx': 804, 'label': 1}, {'idx': 805, 'label': 1}, {'idx': 806, 'label': 0}, {'idx': 807, 'label': 1}, {'idx': 808, 'label': 1}, {'idx': 809, 'label': 1}, {'idx': 810, 'label': 1}, {'idx': 811, 'label': 1}, {'idx': 812, 'label': 0}, {'idx': 813, 'label': 1}, {'idx': 814, 'label': 1}, {'idx': 815, 'label': 0}, {'idx': 816, 'label': 1}, {'idx': 817, 'label': 1}, {'idx': 818, 'label': 1}, {'idx': 819, 'label': 1}, {'idx': 820, 'label': 1}, {'idx': 821, 'label': 1}, {'idx': 822, 'label': 0}, {'idx': 823, 'label': 1}, {'idx': 824, 'label': 1}, {'idx': 825, 'label': 1}, {'idx': 826, 'label': 1}, {'idx': 827, 'label': 1}, {'idx': 828, 'label': 1}, {'idx': 829, 'label': 1}, {'idx': 830, 'label': 1}, {'idx': 831, 'label': 1}, {'idx': 832, 'label': 0}, {'idx': 833, 'label': 1}, {'idx': 834, 'label': 1}, {'idx': 835, 'label': 0}, {'idx': 836, 'label': 0}, {'idx': 837, 'label': 1}, {'idx': 838, 'label': 0}, {'idx': 839, 'label': 0}, {'idx': 840, 'label': 1}, {'idx': 841, 'label': 1}, {'idx': 842, 'label': 1}, {'idx': 843, 'label': 1}, {'idx': 844, 'label': 1}, {'idx': 845, 'label': 0}, {'idx': 846, 'label': 1}, {'idx': 847, 'label': 1}, {'idx': 848, 'label': 1}, {'idx': 849, 'label': 1}, {'idx': 850, 'label': 0}, {'idx': 851, 'label': 0}, {'idx': 852, 'label': 1}, {'idx': 853, 'label': 0}, {'idx': 854, 'label': 1}, {'idx': 855, 'label': 1}, {'idx': 856, 'label': 0}, {'idx': 857, 'label': 1}, {'idx': 858, 'label': 1}, {'idx': 859, 'label': 1}, {'idx': 860, 'label': 1}, {'idx': 861, 'label': 1}, {'idx': 862, 'label': 1}, {'idx': 863, 'label': 1}, {'idx': 864, 'label': 1}, {'idx': 865, 'label': 1}, {'idx': 866, 'label': 0}, {'idx': 867, 'label': 1}, {'idx': 868, 'label': 1}, {'idx': 869, 'label': 1}, {'idx': 870, 'label': 0}, {'idx': 871, 'label': 0}, {'idx': 872, 'label': 0}, {'idx': 873, 'label': 1}, {'idx': 874, 'label': 1}, {'idx': 875, 'label': 0}, {'idx': 876, 'label': 1}, {'idx': 877, 'label': 0}, {'idx': 878, 'label': 1}, {'idx': 879, 'label': 0}, {'idx': 880, 'label': 0}, {'idx': 881, 'label': 0}, {'idx': 882, 'label': 1}, {'idx': 883, 'label': 1}, {'idx': 884, 'label': 1}, {'idx': 885, 'label': 1}, {'idx': 886, 'label': 1}, {'idx': 887, 'label': 1}, {'idx': 888, 'label': 1}, {'idx': 889, 'label': 0}, {'idx': 890, 'label': 1}, {'idx': 891, 'label': 0}, {'idx': 892, 'label': 1}, {'idx': 893, 'label': 1}, {'idx': 894, 'label': 1}, {'idx': 895, 'label': 1}, {'idx': 896, 'label': 1}, {'idx': 897, 'label': 1}, {'idx': 898, 'label': 0}, {'idx': 899, 'label': 0}, {'idx': 900, 'label': 0}, {'idx': 901, 'label': 0}, {'idx': 902, 'label': 1}, {'idx': 903, 'label': 1}, {'idx': 904, 'label': 1}, {'idx': 905, 'label': 0}, {'idx': 906, 'label': 0}, {'idx': 907, 'label': 1}, {'idx': 908, 'label': 0}, {'idx': 909, 'label': 1}, {'idx': 910, 'label': 1}, {'idx': 911, 'label': 0}, {'idx': 912, 'label': 1}, {'idx': 913, 'label': 0}, {'idx': 914, 'label': 1}, {'idx': 915, 'label': 1}, {'idx': 916, 'label': 1}, {'idx': 917, 'label': 1}, {'idx': 918, 'label': 0}, {'idx': 919, 'label': 0}, {'idx': 920, 'label': 1}, {'idx': 921, 'label': 1}, {'idx': 922, 'label': 1}, {'idx': 923, 'label': 0}, {'idx': 924, 'label': 1}, {'idx': 925, 'label': 1}, {'idx': 926, 'label': 0}, {'idx': 927, 'label': 0}, {'idx': 928, 'label': 1}, {'idx': 929, 'label': 1}, {'idx': 930, 'label': 1}, {'idx': 931, 'label': 0}, {'idx': 932, 'label': 0}, {'idx': 933, 'label': 0}, {'idx': 934, 'label': 0}, {'idx': 935, 'label': 0}, {'idx': 936, 'label': 0}, {'idx': 937, 'label': 0}, {'idx': 938, 'label': 0}, {'idx': 939, 'label': 0}, {'idx': 940, 'label': 0}, {'idx': 941, 'label': 1}, {'idx': 942, 'label': 0}, {'idx': 943, 'label': 0}, {'idx': 944, 'label': 1}, {'idx': 945, 'label': 1}, {'idx': 946, 'label': 0}, {'idx': 947, 'label': 1}, {'idx': 948, 'label': 0}, {'idx': 949, 'label': 1}, {'idx': 950, 'label': 1}, {'idx': 951, 'label': 1}, {'idx': 952, 'label': 0}, {'idx': 953, 'label': 1}, {'idx': 954, 'label': 1}, {'idx': 955, 'label': 0}, {'idx': 956, 'label': 1}, {'idx': 957, 'label': 1}, {'idx': 958, 'label': 0}, {'idx': 959, 'label': 0}, {'idx': 960, 'label': 0}, {'idx': 961, 'label': 1}, {'idx': 962, 'label': 0}, {'idx': 963, 'label': 1}, {'idx': 964, 'label': 0}, {'idx': 965, 'label': 1}, {'idx': 966, 'label': 1}, {'idx': 967, 'label': 0}, {'idx': 968, 'label': 0}, {'idx': 969, 'label': 1}, {'idx': 970, 'label': 0}, {'idx': 971, 'label': 1}, {'idx': 972, 'label': 1}, {'idx': 973, 'label': 1}, {'idx': 974, 'label': 1}, {'idx': 975, 'label': 0}, {'idx': 976, 'label': 1}, {'idx': 977, 'label': 0}, {'idx': 978, 'label': 1}, {'idx': 979, 'label': 0}, {'idx': 980, 'label': 0}, {'idx': 981, 'label': 1}, {'idx': 982, 'label': 0}, {'idx': 983, 'label': 0}, {'idx': 984, 'label': 1}, {'idx': 985, 'label': 0}, {'idx': 986, 'label': 0}, {'idx': 987, 'label': 1}, {'idx': 988, 'label': 0}, {'idx': 989, 'label': 1}, {'idx': 990, 'label': 1}, {'idx': 991, 'label': 1}, {'idx': 992, 'label': 1}, {'idx': 993, 'label': 1}, {'idx': 994, 'label': 1}, {'idx': 995, 'label': 1}, {'idx': 996, 'label': 0}, {'idx': 997, 'label': 0}, {'idx': 998, 'label': 1}, {'idx': 999, 'label': 1}, {'idx': 1000, 'label': 1}, {'idx': 1001, 'label': 1}, {'idx': 1002, 'label': 1}, {'idx': 1003, 'label': 1}, {'idx': 1004, 'label': 0}, {'idx': 1005, 'label': 1}, {'idx': 1006, 'label': 1}, {'idx': 1007, 'label': 0}, {'idx': 1008, 'label': 1}, {'idx': 1009, 'label': 0}, {'idx': 1010, 'label': 1}, {'idx': 1011, 'label': 0}, {'idx': 1012, 'label': 1}, {'idx': 1013, 'label': 1}, {'idx': 1014, 'label': 1}, {'idx': 1015, 'label': 1}, {'idx': 1016, 'label': 1}, {'idx': 1017, 'label': 1}, {'idx': 1018, 'label': 0}, {'idx': 1019, 'label': 0}, {'idx': 1020, 'label': 1}, {'idx': 1021, 'label': 1}, {'idx': 1022, 'label': 1}, {'idx': 1023, 'label': 1}, {'idx': 1024, 'label': 1}, {'idx': 1025, 'label': 1}, {'idx': 1026, 'label': 1}, {'idx': 1027, 'label': 1}, {'idx': 1028, 'label': 1}, {'idx': 1029, 'label': 1}, {'idx': 1030, 'label': 1}, {'idx': 1031, 'label': 0}, {'idx': 1032, 'label': 1}, {'idx': 1033, 'label': 0}, {'idx': 1034, 'label': 0}, {'idx': 1035, 'label': 1}, {'idx': 1036, 'label': 0}, {'idx': 1037, 'label': 1}, {'idx': 1038, 'label': 1}, {'idx': 1039, 'label': 1}, {'idx': 1040, 'label': 0}, {'idx': 1041, 'label': 0}, {'idx': 1042, 'label': 0}, {'idx': 1043, 'label': 0}, {'idx': 1044, 'label': 0}, {'idx': 1045, 'label': 1}, {'idx': 1046, 'label': 1}, {'idx': 1047, 'label': 1}, {'idx': 1048, 'label': 1}, {'idx': 1049, 'label': 0}, {'idx': 1050, 'label': 0}, {'idx': 1051, 'label': 0}, {'idx': 1052, 'label': 1}, {'idx': 1053, 'label': 1}, {'idx': 1054, 'label': 1}, {'idx': 1055, 'label': 0}, {'idx': 1056, 'label': 0}, {'idx': 1057, 'label': 0}, {'idx': 1058, 'label': 0}, {'idx': 1059, 'label': 1}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8D2zJz6S-wn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}