{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b16889af7490482f937d62c7bb1a8dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e2ed038804421a8388d38c3f09ca0d",
              "IPY_MODEL_b7802262fd3d4c40b6c4ab2ba23fe325",
              "IPY_MODEL_eec978a1d682412b93be1bc8c3212307"
            ],
            "layout": "IPY_MODEL_e981d6de3b0a481f8c9cdcd681615b75"
          }
        },
        "c4e2ed038804421a8388d38c3f09ca0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0234ebcdaf47b3bababf2d3c8c7cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_914d3e71ced64e34a1bb9c2171dff3dd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b7802262fd3d4c40b6c4ab2ba23fe325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1047bc68c0a64d9e80d8432cfda5f1f5",
            "max": 432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92fc3abf2667454fb0fc97b5c14fca02",
            "value": 432
          }
        },
        "eec978a1d682412b93be1bc8c3212307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f90ab133bf6444a1b9448472ac4f32c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e1e85c09be594fd9bc8b046affc04223",
            "value": " 432/432 [00:00&lt;00:00, 23.8kB/s]"
          }
        },
        "e981d6de3b0a481f8c9cdcd681615b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0234ebcdaf47b3bababf2d3c8c7cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "914d3e71ced64e34a1bb9c2171dff3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1047bc68c0a64d9e80d8432cfda5f1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92fc3abf2667454fb0fc97b5c14fca02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f90ab133bf6444a1b9448472ac4f32c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e85c09be594fd9bc8b046affc04223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d098d39b7040dfaa2e9168e842c25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_491762f1bbf944b4a9d9a47634e81e35",
              "IPY_MODEL_e44b5cdc0ed141cab04300e745b38905",
              "IPY_MODEL_55f86abc02024991a396fe22c54b20e7"
            ],
            "layout": "IPY_MODEL_e9331df2463e4e949c90758dc7bbf421"
          }
        },
        "491762f1bbf944b4a9d9a47634e81e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5375ba7fe9f84f7483a39f6ae98df236",
            "placeholder": "​",
            "style": "IPY_MODEL_c7c3c89973664906acdbf19ab1ef347e",
            "value": "spiece.model: 100%"
          }
        },
        "e44b5cdc0ed141cab04300e745b38905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a82ecb19fa5b4d4895301e4bbbfa49a4",
            "max": 371427,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e78c6a4c61b9409288d7d4a22a5abd55",
            "value": 371427
          }
        },
        "55f86abc02024991a396fe22c54b20e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88da8733cb2646f4b8c2f4d45f78a4dd",
            "placeholder": "​",
            "style": "IPY_MODEL_e6eb58fd023b4876b9cff3408a93b14c",
            "value": " 371k/371k [00:00&lt;00:00, 5.10MB/s]"
          }
        },
        "e9331df2463e4e949c90758dc7bbf421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5375ba7fe9f84f7483a39f6ae98df236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c3c89973664906acdbf19ab1ef347e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a82ecb19fa5b4d4895301e4bbbfa49a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e78c6a4c61b9409288d7d4a22a5abd55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88da8733cb2646f4b8c2f4d45f78a4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6eb58fd023b4876b9cff3408a93b14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd36dc05480e488f81f1567378f0a7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_588f2378386c4b2cbd6707f021054a68",
              "IPY_MODEL_67b1436054ca472dabc989012a7a289e",
              "IPY_MODEL_24715661b79147a590ecfd414b8a762a"
            ],
            "layout": "IPY_MODEL_a89357411fc347699827b23e54e5c9a2"
          }
        },
        "588f2378386c4b2cbd6707f021054a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f1e3b8961b41bbb8ae2eb68c59d655",
            "placeholder": "​",
            "style": "IPY_MODEL_5d9487d65d404ad6a8796f448e4cd9fe",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "67b1436054ca472dabc989012a7a289e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bdaa19b85684e5390697e294cd9190a",
            "max": 244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c26f52927b44b691e87b9034ca8a9d",
            "value": 244
          }
        },
        "24715661b79147a590ecfd414b8a762a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2518889e828f4961bc144e37697e906d",
            "placeholder": "​",
            "style": "IPY_MODEL_721010663e474bb98dd8a15352a37658",
            "value": " 244/244 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "a89357411fc347699827b23e54e5c9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f1e3b8961b41bbb8ae2eb68c59d655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d9487d65d404ad6a8796f448e4cd9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bdaa19b85684e5390697e294cd9190a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c26f52927b44b691e87b9034ca8a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2518889e828f4961bc144e37697e906d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721010663e474bb98dd8a15352a37658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ca87fd3b49b4321ac8131a847027c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b315c23d5cf347738515d65bca666b3a",
              "IPY_MODEL_7fa6d08c73ab4087b24881a457c3ad02",
              "IPY_MODEL_b322954fb4f348ce993e7dd18f297a55"
            ],
            "layout": "IPY_MODEL_ce3b6917fa99489488c56efaeb01f5a7"
          }
        },
        "b315c23d5cf347738515d65bca666b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09b40c556d5411e8d757685124b184c",
            "placeholder": "​",
            "style": "IPY_MODEL_f97f548963ba4bf8a39da3e7847c7843",
            "value": "config.json: 100%"
          }
        },
        "7fa6d08c73ab4087b24881a457c3ad02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcba43b635ed43d199806c911f360a8f",
            "max": 535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54b7b87faa534a9d813d1fba7085e845",
            "value": 535
          }
        },
        "b322954fb4f348ce993e7dd18f297a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f0018a9209431babd53176ff2291fc",
            "placeholder": "​",
            "style": "IPY_MODEL_69f77a4c4c894d7fbbfdf5f186950459",
            "value": " 535/535 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "ce3b6917fa99489488c56efaeb01f5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09b40c556d5411e8d757685124b184c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97f548963ba4bf8a39da3e7847c7843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcba43b635ed43d199806c911f360a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54b7b87faa534a9d813d1fba7085e845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35f0018a9209431babd53176ff2291fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f77a4c4c894d7fbbfdf5f186950459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc47d842670049a5affeffbbf6f8629f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_412246406f844bca9f3769c59af50ac4",
              "IPY_MODEL_c874fd15911f492ab8507d6abcca3252",
              "IPY_MODEL_5dba152fe157488bb0d59bea43c1d4f3"
            ],
            "layout": "IPY_MODEL_8782fb3c22c148778731aab0c7ec8a6f"
          }
        },
        "412246406f844bca9f3769c59af50ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ad143ff1524cb7b1d3915a9b166c80",
            "placeholder": "​",
            "style": "IPY_MODEL_c0fa8544d60d486b9d01667a1c4607a3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c874fd15911f492ab8507d6abcca3252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e5b406cdc64d07a3c29c7d7c1b639b",
            "max": 368792544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97a3ba1cb7124a37836a19ac5ec6b5fd",
            "value": 368792544
          }
        },
        "5dba152fe157488bb0d59bea43c1d4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8a017813674ca5a98eb48fb7ab3302",
            "placeholder": "​",
            "style": "IPY_MODEL_40e3b9d01ec34c0e948c4b53462aa434",
            "value": " 369M/369M [00:03&lt;00:00, 113MB/s]"
          }
        },
        "8782fb3c22c148778731aab0c7ec8a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ad143ff1524cb7b1d3915a9b166c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fa8544d60d486b9d01667a1c4607a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52e5b406cdc64d07a3c29c7d7c1b639b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a3ba1cb7124a37836a19ac5ec6b5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d8a017813674ca5a98eb48fb7ab3302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e3b9d01ec34c0e948c4b53462aa434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LightGreenWorld/Proj_NLP_Kobert/blob/main/Grammatical_fixing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAgF_2xzyEnT",
        "outputId": "ef025ac2-41ad-4fa0-8fe2-b7f1736661f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yxJzt9AyRuW",
        "outputId": "22abb4a3-9f44-4f17-8bef-2c6980c75542"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, SequentialSampler, RandomSampler, random_split\n",
        "if torch.cuda.is_available(): # GPU 이용 가능하다면,\n",
        "\n",
        "  device = torch.device(\"cuda\")   # 파이토치에게 GPU(\"cuda\") 사용하라고 말해; CUDA(Computed Unified Device Architecture)\n",
        "\n",
        "  print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
        "  print(\"We will use the GPU:\", torch.cuda.get_device_name(0))  # GPU 장치 이름 출력\n",
        "\n",
        "else:\n",
        "  print(\"No GPU available, using the CPU instead\")\n",
        "  device = torch.device(\"cpu\")    # GPU가 없다면/GPU를 이용할 수 없다면 파이토치에게 CPU(\"cpu\") 사용하라고 말해줘"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukdoulEu2hoI",
        "outputId": "d368cb80-b2ae-4a08-c0cf-f7124067a2fc"
      },
      "source": [
        "import pandas as pd # tsv파일 열기 위한 라이브러리\n",
        "\n",
        "# Train(훈련) / Dev(검증) / Test(테스트) dataset\n",
        "dataset_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Grammar_Detection/NIKL_CoLA_train.tsv\", delimiter = '\\t', header=None, names = ['sentence_source_train', 'label_train', 'label_notes', 'sentence_train'])\n",
        "dataset_dev = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Grammar_Detection/NIKL_CoLA_dev.tsv\", delimiter = '\\t', header = None, names = ['sentence_source_dev', 'label_dev', 'lable_notes_dev', 'sentence_dev'])\n",
        "dataset_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Grammar_Detection/NIKL_CoLA_test.tsv\", delimiter = '\\t', header = None, names = ['index', 'sentence_test'])\n",
        "\n",
        "# 문장 개수 확인\n",
        "print(\"Number of training sentence: {:,}\\n\".format(dataset_train.shape[0]))\n",
        "print(\"Number of dev sentence: {:,}\\n\".format(dataset_dev.shape[0]))\n",
        "print(\"Number of test sentence: {:,}\\n\".format(dataset_test.shape[0]))\n",
        "\n",
        "# To check the table frame\n",
        "print(f' train: {dataset_train.head(10)}')\n",
        "print(f' test: {dataset_test.head(10)}')\n",
        "\n",
        "# 랜덤으로 10개 문장 확인\n",
        "# dataset_train.sample(10)\n",
        "# dataset_dev.sample(10)\n",
        "# dataset_test.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentence: 15,877\n",
            "\n",
            "Number of dev sentence: 2,033\n",
            "\n",
            "Number of test sentence: 1,061\n",
            "\n",
            " train:   sentence_source_train          label_train        label_notes  \\\n",
            "0                source  acceptability_label  source_annotation   \n",
            "1                T00001                    1                NaN   \n",
            "2                T00001                    0                  *   \n",
            "3                T00002                    1                NaN   \n",
            "4                T00003                    1                NaN   \n",
            "5                T00004                    1                NaN   \n",
            "6                T00004                    0                  *   \n",
            "7                T00005                    1                NaN   \n",
            "8                T00005                    0                  ?   \n",
            "9                T00006                    1                NaN   \n",
            "\n",
            "    sentence_train  \n",
            "0         sentence  \n",
            "1        높은 달이 떴다.  \n",
            "2       달이 뜸이 높았다.  \n",
            "3  실없는 사람이 까불까불한다.  \n",
            "4  나는 철수에게 공을 던졌다.  \n",
            "5  내가 순이와 둘이서 다툰다.  \n",
            "6  내가 순이와 우리가 다툰다.  \n",
            "7     나는 부지런히 뛰었다.  \n",
            "8    나는 부지런히 뛰어졌다.  \n",
            "9      사랑이 죄는 아니다.  \n",
            " test:    index              sentence_test\n",
            "0  index                   sentence\n",
            "1      0        나는 철수에게 공을 던져다 주었다.\n",
            "2      1          먹은 것을 다 소화시켜야 한다.\n",
            "3      2    그가 노래를 부르고는 내가 피아노를 쳤다.\n",
            "4      3  철수가 영수의 손을 잡아서 눈물을 글썽거렸다.\n",
            "5      4             그의 업적은 길이 빛난다.\n",
            "6      5                 별이 반짝반짝한다.\n",
            "7      6             영수와 철수가 같이하였다.\n",
            "8      7       화초가 시들었다. 꽃밭에 물을 줄까?\n",
            "9      8       철호가 성실하다고 나에 의해 보인다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMCwl9epHfn"
      },
      "source": [
        "### dataset_train & dataset_dev 테이블 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llCK3KmE2nR9",
        "outputId": "f3a50ddd-2d45-4612-94e8-e74ba1846ff3"
      },
      "source": [
        "# 데이터 전처리\n",
        "import numpy as np\n",
        "\n",
        "# to convert each column of train data to list excluding column's name and index\n",
        "sentences_train = dataset_train.sentence_train.values[1:]\n",
        "labels_train = dataset_train.label_train.values[1:].astype(np.int64)\n",
        "#print(\"Train_sentences: \", sentences_train)\n",
        "#print(\"Train_labels: \", labels_train)\n",
        "\n",
        "# to convert each column of dev data to list excluding column's name and index\n",
        "sentences_dev = dataset_dev.sentence_dev.values[1:]\n",
        "labels_dev = dataset_dev.label_dev.values[1:].astype(np.int64) # To change to integer\n",
        "#print(\"Dev_sentences: \", sentences_dev)\n",
        "#print(\"Dev_labels: \", labels_dev)\n",
        "\n",
        "# to convert each column of test data to list excluding column's name and index\n",
        "sentences_test = dataset_test.sentence_test.values[1:]\n",
        "index_test = dataset_test.index.values[1:].astype(np.int64) # To change to integer\n",
        "#print(\"Test_sentences: \", sentences_test)\n",
        "#print(\"Test_index: \", index_test)\n",
        "\n",
        "# to convert the whole columns of train/dev/test data to list excluding column's name and index\n",
        "dataset_train = dataset_train.values[1:]\n",
        "dataset_dev = dataset_dev.values[1:]\n",
        "dataset_test = dataset_test.values[1:]\n",
        "\n",
        "print(\"--------------------------\")\n",
        "print(f'The whole train dataset: \\n {dataset_train}')\n",
        "print(f'The whole dev dataset: \\n {dataset_dev}')\n",
        "print(f'The whole test dataset: \\n {dataset_test}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------\n",
            "The whole train dataset: \n",
            " [['T00001' '1' nan '높은 달이 떴다.']\n",
            " ['T00001' '0' '*' '달이 뜸이 높았다.']\n",
            " ['T00002' '1' nan '실없는 사람이 까불까불한다.']\n",
            " ...\n",
            " ['T09999' '1' nan '선생님이 순희에게 책을 읽게 하시나 순희는 책을 읽지 않는다.']\n",
            " ['T09999' '0' '*' '선생님이 순희에게 책을 읽히시나 순희는 책을 읽지 않는다']\n",
            " ['T10000' '1' nan '그의 부주의로 말미암아 사건이 터졌다.']]\n",
            "The whole dev dataset: \n",
            " [['T00002' '0' '*' '실없는 사람이 까불한다.']\n",
            " ['T00029' '1' nan '순희에게는 아무리 좋은 옷도 어울리지 않는다.']\n",
            " ['T00033' '0' '*' '사람은 언제나 젊는 수는 없다.']\n",
            " ...\n",
            " ['T09994' '0' '*' '밤새 그 술을 다 먹었는 것이다.']\n",
            " ['T09997' '1' nan '학교에서 철수는 놀았고, 순이는 공부했다.']\n",
            " ['T10000' '0' '*' '그의 부주의에 말미암아 사건이 터졌다.']]\n",
            "The whole test dataset: \n",
            " [['0' '나는 철수에게 공을 던져다 주었다.']\n",
            " ['1' '먹은 것을 다 소화시켜야 한다.']\n",
            " ['2' '그가 노래를 부르고는 내가 피아노를 쳤다.']\n",
            " ...\n",
            " ['1057' '그는 나를 바보 여긴다.']\n",
            " ['1058' '수호는 모든 일에 전혀 무감각하다.']\n",
            " ['1059' '나는 할아버지가 제일 무서우시다.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XU4Er400Fc"
      },
      "source": [
        "### SKT-Kobert 인스톨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b16889af7490482f937d62c7bb1a8dc1",
            "c4e2ed038804421a8388d38c3f09ca0d",
            "b7802262fd3d4c40b6c4ab2ba23fe325",
            "eec978a1d682412b93be1bc8c3212307",
            "e981d6de3b0a481f8c9cdcd681615b75",
            "ce0234ebcdaf47b3bababf2d3c8c7cf6",
            "914d3e71ced64e34a1bb9c2171dff3dd",
            "1047bc68c0a64d9e80d8432cfda5f1f5",
            "92fc3abf2667454fb0fc97b5c14fca02",
            "f90ab133bf6444a1b9448472ac4f32c5",
            "e1e85c09be594fd9bc8b046affc04223",
            "d8d098d39b7040dfaa2e9168e842c25e",
            "491762f1bbf944b4a9d9a47634e81e35",
            "e44b5cdc0ed141cab04300e745b38905",
            "55f86abc02024991a396fe22c54b20e7",
            "e9331df2463e4e949c90758dc7bbf421",
            "5375ba7fe9f84f7483a39f6ae98df236",
            "c7c3c89973664906acdbf19ab1ef347e",
            "a82ecb19fa5b4d4895301e4bbbfa49a4",
            "e78c6a4c61b9409288d7d4a22a5abd55",
            "88da8733cb2646f4b8c2f4d45f78a4dd",
            "e6eb58fd023b4876b9cff3408a93b14c",
            "bd36dc05480e488f81f1567378f0a7f5",
            "588f2378386c4b2cbd6707f021054a68",
            "67b1436054ca472dabc989012a7a289e",
            "24715661b79147a590ecfd414b8a762a",
            "a89357411fc347699827b23e54e5c9a2",
            "75f1e3b8961b41bbb8ae2eb68c59d655",
            "5d9487d65d404ad6a8796f448e4cd9fe",
            "5bdaa19b85684e5390697e294cd9190a",
            "69c26f52927b44b691e87b9034ca8a9d",
            "2518889e828f4961bc144e37697e906d",
            "721010663e474bb98dd8a15352a37658"
          ]
        },
        "id": "_m8C1S64orDf",
        "outputId": "165f9369-87d5-4125-8eb3-cf9791aeb870"
      },
      "source": [
        "!pip install kobert-transformers\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "#KoBert\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kobert-transformers\n",
            "  Downloading kobert_transformers-0.5.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->kobert-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->kobert-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->kobert-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kobert-transformers\n",
            "Successfully installed kobert-transformers-0.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-gdnrz545/kobert-tokenizer_80cba69da401474992d8fa706c29f33a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-gdnrz545/kobert-tokenizer_80cba69da401474992d8fa706c29f33a\n",
            "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kobert_tokenizer\n",
            "  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4633 sha256=4cf9c77fb52083ba418b83baa70b4c9a92b3652c134d3144287d44f297987841\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rluyzxh9/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n",
            "Successfully built kobert_tokenizer\n",
            "Installing collected packages: kobert_tokenizer\n",
            "Successfully installed kobert_tokenizer-0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b16889af7490482f937d62c7bb1a8dc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/371k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8d098d39b7040dfaa2e9168e842c25e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd36dc05480e488f81f1567378f0a7f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u4a3A5q1DMP"
      },
      "source": [
        "### 데이터 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYb3wKMF2p2y",
        "outputId": "a1268fc1-7f22-41f3-d259-97392a83fab5"
      },
      "source": [
        "# 샘플 데이터로 토크나이저 잘 되나 확인\n",
        "print(\"Train_Original: \", sentences_train[0])\n",
        "print(\"Train_Tokenized: \", tokenizer.tokenize(sentences_train[0]))\n",
        "print(\"Train_Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))\n",
        "\n",
        "print(\"Dev_Original: \", sentences_dev[0])\n",
        "print(\"Dev_Tokenized: \", tokenizer.tokenize(sentences_dev[0]))\n",
        "print(\"Dev_Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_dev[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Original:  높은 달이 떴다.\n",
            "Train_Tokenized:  ['▁높은', '▁달', '이', '▁', '떴', '다', '.']\n",
            "Train_Token IDs:  [1520, 1597, 7096, 517, 5974, 5782, 54]\n",
            "Dev_Original:  실없는 사람이 까불한다.\n",
            "Dev_Tokenized:  ['▁실', '없는', '▁사람이', '▁', '까', '불', '한다', '.']\n",
            "Dev_Token IDs:  [3036, 6882, 2589, 517, 5591, 6424, 7831, 54]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check maxx length of tokenized sentences\n",
        "\n",
        "\n",
        "def find_sentence_with_most_tokens(sentences):\n",
        "    # Initialize the sentence with the most tokens and the maximum token count\n",
        "    resultsentence = \"\"\n",
        "    maxtokens = 0\n",
        "\n",
        "    for singlesent in sentences:\n",
        "        tokens = tokenizer.tokenize(singlesent)\n",
        "        numtokens = len(tokens)\n",
        "\n",
        "        # Update if the current sentence has more tokens\n",
        "        if numtokens > maxtokens:\n",
        "            resultsentence = singlesent\n",
        "            maxtokens = numtokens\n",
        "\n",
        "    return resultsentence, maxtokens\n",
        "\n",
        "result_sentence_train, max_tokens_train = find_sentence_with_most_tokens(sentences_train)\n",
        "result_sentence_dev, max_tokens_dev = find_sentence_with_most_tokens(sentences_dev)\n",
        "result_sentence_test, max_tokens_test = find_sentence_with_most_tokens(sentences_test)\n",
        "\n",
        "print(f'Train - Max Tokens: {max_tokens_train}, Corresponding sentence: {result_sentence_train}')\n",
        "print(f'Dev - Max Tokens: {max_tokens_dev}, Corresponding sentence: {result_sentence_dev}')\n",
        "print(f'Test - Max Tokens: {max_tokens_test}, Corresponding sentence: {result_sentence_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maDQxeSVuhRa",
        "outputId": "d01a1987-598d-4d76-f410-b2dfb0dd50e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Max Tokens: 36, Corresponding sentence: 이 기간 중 투자율은 25.2퍼센트에 달하여 계획치를 크게 상회하였으나, 국내 저축률은 계획치를 약간 상회하였다.\n",
            "Dev - Max Tokens: 33, Corresponding sentence: 철수는 영희가 몇 명의 학생을 가르쳤다고 예은이에게 말했니, 세 명 가르쳤다고 예은이에게 말했니?\n",
            "Test - Max Tokens: 28, Corresponding sentence: 마르고 유약해 보이는 용모를 가진 한 남자 가수가 분장실 바닥에 쭈그리면서 앉아 있다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2smwi0Roh1h"
      },
      "source": [
        "dataset_train의 encoded_dict\n",
        "\n",
        "dataset_dev의 encoded_dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd-Hd7GEt4Dp",
        "outputId": "e3d4430d-7694-4fd6-cd6e-ef1f92c42837"
      },
      "source": [
        "# Train_data_Tokenize\n",
        "# 모든 문장을 토크나이즈 한 후 토큰들을 그것들의 단어 ID에 대응·매치시키는 작업\n",
        "\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# 모든 문장에 대하여\n",
        "for sent in sentences_train:\n",
        "    # `encode_plus`는:\n",
        "    #   (1) 문장을 토크나이저.\n",
        "    #   (2) [CLS]를 모든 문장의 가장 앞에 삽입.\n",
        "    #   (3) [SEP]을 모든 문장의 가장 뒤에 삽입.\n",
        "    #       CLS, SEP는 토큰 임베딩 분야의 특수 토큰으로,\n",
        "    #       CLS는 special CLaSsification token, SEP은 sepcial SEParator token을 의미\n",
        "    #   (4) 토큰들을 그들의 단어 아이디와 매치시킴.\n",
        "    #   (5) 문장의 길이는 'max_length' 수치에 맞게 늘려주거나 줄여줌.\n",
        "    #       Pad: 특정 형상의 배열로 변형할 때 빈자리를 0으로 채워준다는 의미\n",
        "    #   (6) [PAD] 토큰을 위한 attention mask 생성\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                         # 인코딩할 문장 자리 / 문장을 인코딩\n",
        "                        add_special_tokens = True,    # 특수 토큰 [CLS]와 [SEP] 추가\n",
        "                        max_length = 40,              # max_length에 맞게 모든 문장 패딩 & 축소\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True, # Attention Mask 구축 / 자료 구조는 tensor 형태\n",
        "                                                      # Attention Mask는 단어 배치와 동일하게 \"1\" 생성\n",
        "                        return_tensors = 'pt',        # 인코딩된 문장을 pytorch 텐서 형태로 변경\n",
        "                                                      # tensorflow를 사용하고 있다면 return_tensors = 'tf'라고 씀\n",
        "                   )\n",
        "\n",
        "    # 인코딩된 문장들을 글로벌 선언한 List [input_ids_train]에 넣기\n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # Attention mask 인자들 List[attention_masks_train]에 넣기 (simply differentiates padding from non-padding).\n",
        "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids_train = torch.cat(input_ids_train, dim=0) # dim은 축·차원의 수 axis0부터 시작, dim=0는 축 1개 or 1차원\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "# print(\"Train_labels_array: \", labels_train)\n",
        "labels_train = torch.tensor(labels_train)\n",
        "\n",
        "# Train 데이터의 문장과 ID 출력. (인코딩이 잘 됐는지 확인하는 작업)\n",
        "print(f'Train_Original: {sentences_train[0]}') # 1차원\n",
        "print(f'Train_Token IDs: {input_ids_train},\\nTrain_input_ids_shape: {input_ids_train.shape}, \\nTrain_input_ids_dim: {input_ids_train.ndim}')\n",
        "print(f'Train_labels: {labels_train}, \\nTrain_labels_shape: {labels_train.shape}, \\nTrain_labels_dim: {labels_train.ndim}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Original: 높은 달이 떴다.\n",
            "Train_Token IDs: tensor([[   2, 1520, 1597,  ...,    1,    1,    1],\n",
            "        [   2, 1597, 7096,  ...,    1,    1,    1],\n",
            "        [   2, 3036, 6882,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2, 2752, 7096,  ...,    1,    1,    1],\n",
            "        [   2, 2752, 7096,  ...,    1,    1,    1],\n",
            "        [   2, 1214, 2423,  ...,    1,    1,    1]]),\n",
            "Train_input_ids_shape: torch.Size([15876, 40]), \n",
            "Train_input_ids_dim: 2\n",
            "Train_labels: tensor([1, 0, 1,  ..., 1, 0, 1]), \n",
            "Train_labels_shape: torch.Size([15876]), \n",
            "Train_labels_dim: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-08262d06b2de>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_train = torch.tensor(labels_train)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dev_data_Tokenize\n",
        "# 모든 문장을 토크나이즈 한 후 토큰들을 그것들의 단어 ID에 대응·매치시키는 작업\n",
        "input_ids_dev = []\n",
        "attention_masks_dev = []\n",
        "\n",
        "# 위와 동일하게 모든 문장에 encode_plus 적용\n",
        "for sent in sentences_dev:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 40,\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "\n",
        "    # encode_dict로 인코딩된 문장을 input_ids_dev 리스트에 추가\n",
        "    input_ids_dev.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # econde_dict의 어텐션마스크를 attention mask_dev 리스트에 추가 (simply differentiates padding from non-padding).\n",
        "    attention_masks_dev.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# 리스트를 텐서 형태로 변경\n",
        "input_ids_dev = torch.cat(input_ids_dev, dim=0)\n",
        "attention_masks_dev = torch.cat(attention_masks_dev, dim=0)\n",
        "labels_dev = torch.tensor(labels_dev)\n",
        "\n",
        "# 0번째 문장, 토큰, 라벨 아이디 출력\n",
        "print(f'Dev_Original: {sentences_dev[0]}') # 1차원\n",
        "print(f'Dev_Token IDs: {input_ids_dev},\\nDev_input_ids_shape: {input_ids_dev.shape}, \\nDev_input_ids_dim: {input_ids_dev.ndim}')\n",
        "print(f'Dev_labels: {labels_dev}, \\nDev_labels_shape: {labels_dev.shape}, \\nDev_labels_dim: {labels_dev.ndim}')\n",
        "\n",
        "\n",
        "## Create the DataLoader.\n",
        "#prediction_data = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "#prediction_sampler = SequentialSampler(prediction_data)\n",
        "#prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "btCSYeEtnox3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf85583-0b45-488c-c8c9-6d9cecf15659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev_Original: 실없는 사람이 까불한다.\n",
            "Dev_Token IDs: tensor([[   2, 3036, 6882,  ...,    1,    1,    1],\n",
            "        [   2, 2912, 7993,  ...,    1,    1,    1],\n",
            "        [   2, 2587, 3245,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2, 2265, 6536,  ...,    1,    1,    1],\n",
            "        [   2, 4949, 6903,  ...,    1,    1,    1],\n",
            "        [   2, 1214, 2423,  ...,    1,    1,    1]]),\n",
            "Dev_input_ids_shape: torch.Size([2032, 40]), \n",
            "Dev_input_ids_dim: 2\n",
            "Dev_labels: tensor([0, 1, 0,  ..., 0, 1, 0]), \n",
            "Dev_labels_shape: torch.Size([2032]), \n",
            "Dev_labels_dim: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-28df6bf0be9e>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_dev = torch.tensor(labels_dev)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqOjz3cc3XBn",
        "outputId": "345b69a3-da80-43e4-96fc-264ff538e07a"
      },
      "source": [
        "# TensorDataset()은 텐서를 감싸는 (wrapping) Dataset으로, 길이와 인덱싱 방식을 정의\n",
        "# Dataset을 상속한 클래스로, 학습데이터·독립변수X(input_ids_train, attention_mask_train)와 레이블·종속변수Y(labels_train)를 묶어 놓는 컨테이너\n",
        "# TensorDataset()을 DataLoader에 전달하면, 반복문(for문)에서 데이터의 일부분만 간단히 추출할 수 있다.\n",
        "# TensorDataset()은 텐서만 전달 가능하며, Variable은 전달 불가.\n",
        "\n",
        "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dev_dataset = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "\n",
        "# print(\"train_dataset: \", train_dataset)\n",
        "# print(\"train_dataset[input_ids_train]: \", train_dataset[input_ids_train])\n",
        "\n",
        "# 트레이닝 데이터 & 검증 데이터 크기 다시 한 번 확인\n",
        "print(f'Number of train sentence: {int(len(train_dataset))}')\n",
        "print(f'Number of dev sentence: {int(len(dev_dataset))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train sentence: 15876\n",
            "Number of dev sentence: 2032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuzp4sc7VV7",
        "outputId": "2f883a16-a24a-4ff4-884a-b51e95aa077f"
      },
      "source": [
        "# DataLoader는 데이터를 학습시키기 위해 batch size를 알아야 하기 때문에, batch size를 설정해줄 것.\n",
        "# Fine-tuning BERT를 만들기 위해, batch size를 16 또는 32을 추천\n",
        "batch_size = 32\n",
        "\n",
        "# Train Dataloader 생성\n",
        "train_dataloader = DataLoader(\n",
        "                              train_dataset, # Train samples.\n",
        "                              sampler = RandomSampler(train_dataset),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "# Dev Dataloader 생성\n",
        "dev_dataloader = DataLoader(\n",
        "                            dev_dataset, # Dev samples.\n",
        "                            sampler = RandomSampler(dev_dataset),\n",
        "                            batch_size = batch_size)\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(dev_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "497\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960,
          "referenced_widgets": [
            "8ca87fd3b49b4321ac8131a847027c59",
            "b315c23d5cf347738515d65bca666b3a",
            "7fa6d08c73ab4087b24881a457c3ad02",
            "b322954fb4f348ce993e7dd18f297a55",
            "ce3b6917fa99489488c56efaeb01f5a7",
            "e09b40c556d5411e8d757685124b184c",
            "f97f548963ba4bf8a39da3e7847c7843",
            "fcba43b635ed43d199806c911f360a8f",
            "54b7b87faa534a9d813d1fba7085e845",
            "35f0018a9209431babd53176ff2291fc",
            "69f77a4c4c894d7fbbfdf5f186950459",
            "fc47d842670049a5affeffbbf6f8629f",
            "412246406f844bca9f3769c59af50ac4",
            "c874fd15911f492ab8507d6abcca3252",
            "5dba152fe157488bb0d59bea43c1d4f3",
            "8782fb3c22c148778731aab0c7ec8a6f",
            "05ad143ff1524cb7b1d3915a9b166c80",
            "c0fa8544d60d486b9d01667a1c4607a3",
            "52e5b406cdc64d07a3c29c7d7c1b639b",
            "97a3ba1cb7124a37836a19ac5ec6b5fd",
            "3d8a017813674ca5a98eb48fb7ab3302",
            "40e3b9d01ec34c0e948c4b53462aa434"
          ]
        },
        "id": "8tn1Vd0N7nHZ",
        "outputId": "49167e3c-9144-46ce-c2b4-385449a6fdff"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# BertForSequenceClassification 설치\n",
        "# 가장 위 레이어에 단일 linear classification 레이어를 가진, 사전 학습된 BERT 모델\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'skt/kobert-base-v1',\n",
        "    num_labels = 2, # 레이블의 개수는 2진분류가 디폴트.\n",
        "                    # 하지만 멀티 클래스 태스크를 증가시킬 수 있다(?)\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Pytorch에게 이 모델을 GPU에서 사용하라고 요청\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/535 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ca87fd3b49b4321ac8131a847027c59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/369M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc47d842670049a5affeffbbf6f8629f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exUI-o-b_XRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f615d78b-28f6-4799-f6a0-30b2cefbf029"
      },
      "source": [
        "# 튜플들의 리스트 형태로 모델의 모든 파라미터들 추출\n",
        "\n",
        "params = list(model.named_parameters())\n",
        "print(f'The BERT model has {len(params):} different named paraeters.\\n')\n",
        "\n",
        "print('===== Embedding Layer =====\\n')\n",
        "for p in params [0:5]:\n",
        "  print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params [5:21]:\n",
        "  print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params [-4:]:\n",
        "  print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named paraeters.\n",
            "\n",
            "===== Embedding Layer =====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                   (8002, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Ct1jMS8vJw"
      },
      "source": [
        "# 참고: AdamW은 huggingface 라이브러리에 있는 클래스. (PyTorch와 대조적으로)\n",
        "# 아마도 W는 \"Weight Decay fix\"를 의미하는 것으로 추정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5,   # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyItV69M9qPl"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# 학습 epochs 설정. 글쓴이는 2~4 추천, 일단 4로 해보고, 오버 피팅되면 조절\n",
        "epochs = 4\n",
        "\n",
        "# 학습 횟수·단계 설정: [batch의 개수] x [epochs의 개수]. (batch size ≠ batch의 개수)\n",
        "# ※학습 샘플 수와 같지 않음\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Learning Rate 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipaOG-MP-jM3"
      },
      "source": [
        "# 예측 대비 레이블의 정확성 계산을 위한 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten() # flatten(): to convert # dimension data form to 1 dimension data form\n",
        "                                                 # argmax: to return index\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# preds = np.array([[0.9, 0.2], [0.8, 0.3], [0.2, 0.8], [0.9, 0.1]])\n",
        "# labels = np.array([1, 0, 1, 0])\n",
        "# accuracy = flat_accuracy(preds, labels)\n",
        "# print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6u-AXG__dcc"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  '''\n",
        "  Takes a time in seconds and returns a string hh:mm:ss\n",
        "  '''\n",
        "  # 1초 단위로 반올림\n",
        "  elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "  # 시간형태: hh:mm:ss\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-H8_H4ST4J_"
      },
      "source": [
        "### To Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQZ28klAM2K",
        "outputId": "5da421d3-a099-4b6d-b68d-6bdff206527c"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible. 하지만 42는 큰 의미 없는 수\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val) # 생성된 난수 중 씨드값 42의 수 출력(고정)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 학습값 손실, 검증값 손실, 검증데이터 정확성, 시간 등 여러 측정 상태 저장 및 출력\n",
        "training_stats = []\n",
        "\n",
        "# 전체 학습 시간 측정\n",
        "total_t0 = time.time()\n",
        "\n",
        "# each epoch에 대해서...\n",
        "for epoch_i in range(0, epochs): # epochs = 4\n",
        "\n",
        "    '''\n",
        "    ========================================\n",
        "                    Training\n",
        "    ========================================\n",
        "    '''\n",
        "\n",
        "    print(f'\\n======== Epoch {epoch_i + 1:} / {epochs:} ======== \\nTraining...')\n",
        "\n",
        "    # epoch 도는데 걸리는 시간 측정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # each epoch에 대한 총 학습값 손실 0으로 리셋\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # 모델(model = BertForSequenceClassification.from_pretrained)을 트레이닝 모드에 넣음.\n",
        "    # Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # print(\"step: {}, batch: {}\".format(step, batch))\n",
        "\n",
        "        # 40 배치씩 결과 출력\n",
        "        ctime= time.time()\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "\n",
        "            # elapsed = format_time(time.time() - t0)\n",
        "            elapsed = format_time(ctime - t0)\n",
        "            print(\"current time: \", format_time(ctime))\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Train_dataloader의 트레이닝 batch 해체 분석.\n",
        "        # batch를 해체시킬 때, 각 tensor를 'to' 메소드를 사용하는 GPU(device = torch.device(\"cuda\"))에 복사\n",
        "        # `batch` contains three pytorch tensors\n",
        "        # [0]: input ids, [1]: attention masks, [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # b_input_ids: 2차원, b_labels: 1차원\n",
        "\n",
        "        # 항상 이전에 계산된 gradients들은, backward pass를 수행하기 전에 초기화하여 0으로 만들어 줘야함\n",
        "        # PyTorch는 이것을 자동으로 해주지 않음.\n",
        "        # 왜냐하면 RNNs을 학습시키는 동안에 gradients를 계산하는 것이 편리하기 때문에\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # 전방 전달(forward pass) 수행 (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "\n",
        "        '''\n",
        "        전방 전달(forward pass)은 입력부터 출력까지 값을 계산한다.\n",
        "        그리고 나서 후방 전달(backward pass)은 역전파(back propagation)을 수행하는데,\n",
        "        이는 끝에서 시작해서 반복적으로 연쇄 법칙을 적용해 회로 입력에 대한 모든 길에서\n",
        "        그라디언트 값을 계산한다. 그라디언트 값은 회로를 통해 거꾸로 흐르는 것으로 볼 수 있다.\n",
        "\n",
        "        순전파(forwards propagation)은 뉴럴 네트워크의 그래프를 계산하기 위해서\n",
        "        중간 변수들을 순서대로 계산하고 저장한다. 즉, 입력층부터 시작해서 출력층까지 처리한다.\n",
        "        역전파(back propagation)은 중간 변수와 파라미터에 대한 그래디언트(gradient)를\n",
        "        반대 방향으로 계산하고 저장한다.\n",
        "        '''\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss = loss.float()\n",
        "        # print(\"loss:\", loss) # loss값 확인\n",
        "\n",
        "        # 모든 batch에 대한 학습 손실값을 축적\n",
        "        # 그래서 우리는 마지막에 평균 손실값을 구할 수 있다.\n",
        "\n",
        "        # 'loss'는 단일 값을 포함한 Tensor.\n",
        "        # '.item()'함수는 tensor로부터 Python 값을 리턴.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # gradients를 계산하기 위해 loss에 대해 후방 전달(backward pass) 수행\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Development\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Development...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #  [0]: input ids, [1]: attention masks, [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "            logits = outputs[0]\n",
        "            logits = logits.float()\n",
        "\n",
        "        # Accumulate the development loss.\n",
        "        total_eval_loss += logits.item()\n",
        "\n",
        "        dev_logits = outputs[1]\n",
        "        # print(\"dev_logits: \", dev_logits) - dev_logits: 2차원, b_labels: 1차원\n",
        "\n",
        "        # (log_)softmax 함수는 tensor 형태로 들어가야함\n",
        "        # dev_logits = F.log_softmax(dev_logits, dim=1)\n",
        "        # print(\"DIM_dev_logits: {}, dev_logits: {}\".format(dev_logits.ndim, dev_logits))\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        # argmax 함수는 numpy 형태로 들어가야함\n",
        "        dev_logits = dev_logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(dev_logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this development run.\n",
        "    avg_dev_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_dev_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_dev_loss = total_eval_loss / len(dev_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    development_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Development Loss: {0:.2f}\".format(avg_dev_loss))\n",
        "    print(\"  Development took: {:}\".format(development_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Train Loss': avg_train_loss,\n",
        "            'Dev Loss': avg_dev_loss,\n",
        "            'Dev Accur.': avg_dev_accuracy,\n",
        "            'Train Time': training_time,\n",
        "            'Dev Time': development_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f'Training Complete!\\nTotal training took {format_time(time.time()-total_t0):} (h:mm:ss)')\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "        [-0.0439,  0.5469],\n",
            "        [-0.2548,  0.6849],\n",
            "        [ 0.2340,  0.0405],\n",
            "        [ 0.4148, -0.1270],\n",
            "        [-0.5149,  1.0253],\n",
            "        [ 0.4506, -0.1625],\n",
            "        [-0.7373,  1.1472],\n",
            "        [-0.1141,  0.3716],\n",
            "        [-0.1606,  0.6404],\n",
            "        [ 0.7723, -0.8222],\n",
            "        [-0.5093,  1.0136],\n",
            "        [ 0.9821, -0.9800]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9370, -0.8918],\n",
            "        [-0.5575,  1.0585],\n",
            "        [ 0.1806, -0.0455],\n",
            "        [ 0.2276,  0.1638],\n",
            "        [ 0.7881, -0.8753],\n",
            "        [ 0.3927, -0.3654],\n",
            "        [ 0.1009,  0.3072],\n",
            "        [-0.7770,  1.1841],\n",
            "        [-0.8162,  1.2527],\n",
            "        [-0.4675,  0.8825],\n",
            "        [-0.8069,  1.2788],\n",
            "        [ 0.3784, -0.0016],\n",
            "        [-0.5915,  1.0631],\n",
            "        [-0.9022,  1.2863],\n",
            "        [ 0.3794,  0.0219],\n",
            "        [-0.6418,  1.1017],\n",
            "        [ 0.1947,  0.2274],\n",
            "        [ 0.9250, -0.9720],\n",
            "        [-0.0580,  0.5932],\n",
            "        [ 0.0424,  0.3737],\n",
            "        [ 0.2835,  0.0490],\n",
            "        [ 0.2516, -0.0139],\n",
            "        [-0.6379,  1.0639],\n",
            "        [-0.3600,  0.7940],\n",
            "        [ 1.0300, -1.2113],\n",
            "        [ 0.1408,  0.3539],\n",
            "        [ 0.2485,  0.2107],\n",
            "        [ 0.0195,  0.3652],\n",
            "        [ 0.3808, -0.1837],\n",
            "        [-0.1380,  0.5600],\n",
            "        [-0.1706,  0.6603],\n",
            "        [-0.7825,  1.2105]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4157, -0.1791],\n",
            "        [-0.0924,  0.5071],\n",
            "        [-0.1856,  0.7577],\n",
            "        [-0.6715,  1.2091],\n",
            "        [-0.8220,  1.2039],\n",
            "        [-0.5496,  1.0660],\n",
            "        [ 0.1705,  0.1913],\n",
            "        [ 0.8016, -0.8445],\n",
            "        [ 0.4558, -0.1121],\n",
            "        [ 0.7256, -0.4637],\n",
            "        [-0.6286,  1.0583],\n",
            "        [-0.4334,  0.8089],\n",
            "        [ 0.6353, -0.3736],\n",
            "        [ 0.3695,  0.0656],\n",
            "        [ 0.3545,  0.0609],\n",
            "        [-0.0624,  0.4347],\n",
            "        [-0.7890,  1.2409],\n",
            "        [ 0.2025,  0.0933],\n",
            "        [ 0.1801,  0.2684],\n",
            "        [ 0.7826, -0.6541],\n",
            "        [ 0.4940, -0.0425],\n",
            "        [ 0.1306,  0.0920],\n",
            "        [ 0.7944, -0.8600],\n",
            "        [-0.6544,  1.0343],\n",
            "        [ 0.6204, -0.4989],\n",
            "        [-0.8824,  1.2689],\n",
            "        [-0.6247,  1.1464],\n",
            "        [ 0.8187, -0.7739],\n",
            "        [-0.3810,  0.8744],\n",
            "        [ 1.0376, -1.0210],\n",
            "        [ 0.6327, -0.2687],\n",
            "        [ 0.6056, -0.4892]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7096,  1.2216],\n",
            "        [ 0.4429, -0.0669],\n",
            "        [-0.9238,  1.3296],\n",
            "        [ 0.4933, -0.1499],\n",
            "        [-0.1465,  0.6105],\n",
            "        [-0.0842,  0.6591],\n",
            "        [-0.7993,  1.2470],\n",
            "        [-0.6833,  1.1731],\n",
            "        [ 0.6157, -0.5298],\n",
            "        [-0.2167,  0.7494],\n",
            "        [ 0.0090,  0.4807],\n",
            "        [-0.0147,  0.3948],\n",
            "        [ 0.3422, -0.0769],\n",
            "        [-0.8201,  1.1945],\n",
            "        [-0.7097,  1.2059],\n",
            "        [-0.8236,  1.2520],\n",
            "        [-0.5491,  1.0327],\n",
            "        [ 1.1076, -1.2090],\n",
            "        [ 0.6382, -0.4410],\n",
            "        [-0.0539,  0.5440],\n",
            "        [-0.7485,  1.2599],\n",
            "        [-0.6911,  1.1982],\n",
            "        [ 0.0862,  0.3285],\n",
            "        [ 0.7060, -0.5521],\n",
            "        [ 0.2767,  0.1176],\n",
            "        [-0.7712,  1.2589],\n",
            "        [-0.8772,  1.2882],\n",
            "        [-0.3671,  0.8522],\n",
            "        [ 0.5000, -0.0975],\n",
            "        [ 0.9492, -0.9682],\n",
            "        [-0.6957,  1.0315],\n",
            "        [ 0.1827,  0.2597]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.8483, -0.8149],\n",
            "        [ 0.6457, -0.4773],\n",
            "        [-0.8777,  1.2667],\n",
            "        [ 0.7869, -0.6979],\n",
            "        [ 0.8031, -0.7917],\n",
            "        [-0.4686,  0.7760],\n",
            "        [-0.4150,  0.8484],\n",
            "        [ 0.7190, -0.6156],\n",
            "        [-0.4346,  0.8715],\n",
            "        [-0.2917,  0.7246],\n",
            "        [-0.0765,  0.4787],\n",
            "        [ 0.4799, -0.1600],\n",
            "        [-0.2674,  0.7490],\n",
            "        [-0.3948,  0.9222],\n",
            "        [-0.4130,  0.7682],\n",
            "        [-0.5894,  1.1058],\n",
            "        [ 0.3497, -0.0906],\n",
            "        [ 0.7231, -0.5035],\n",
            "        [ 0.4503, -0.1555],\n",
            "        [ 0.8293, -0.7677],\n",
            "        [-0.4508,  0.9223],\n",
            "        [ 0.3261,  0.1586],\n",
            "        [ 0.6760, -0.6797],\n",
            "        [ 0.8252, -0.7581],\n",
            "        [ 0.3740, -0.2304],\n",
            "        [ 0.4639, -0.0095],\n",
            "        [ 0.5726, -0.3747],\n",
            "        [ 0.3593, -0.0427],\n",
            "        [ 0.4716, -0.3270],\n",
            "        [-0.3182,  0.7857],\n",
            "        [-0.7242,  1.1886],\n",
            "        [-0.1905,  0.5949]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.2114,  0.6871],\n",
            "        [-0.0384,  0.4449],\n",
            "        [-0.5541,  1.0196],\n",
            "        [-0.3318,  0.8382],\n",
            "        [ 0.5892, -0.3048],\n",
            "        [ 0.0786,  0.0381],\n",
            "        [ 0.6707, -0.5173],\n",
            "        [-0.4862,  1.0018],\n",
            "        [-0.6627,  1.1023],\n",
            "        [-0.6165,  1.0692],\n",
            "        [ 0.7112, -0.5050],\n",
            "        [ 0.5008, -0.3043],\n",
            "        [-0.7803,  1.2612],\n",
            "        [-0.5872,  1.0156],\n",
            "        [-0.5388,  1.0283],\n",
            "        [-0.1691,  0.6030],\n",
            "        [ 0.1800,  0.1627],\n",
            "        [-0.9088,  1.2634],\n",
            "        [ 0.0560,  0.2989],\n",
            "        [ 0.3255,  0.1316],\n",
            "        [ 0.7834, -1.0060],\n",
            "        [ 0.9847, -1.0834],\n",
            "        [ 0.2231,  0.1970],\n",
            "        [ 0.9532, -0.9381],\n",
            "        [ 0.1936,  0.2493],\n",
            "        [-0.3002,  0.7151],\n",
            "        [ 0.5015, -0.3251],\n",
            "        [-0.7006,  1.1740],\n",
            "        [ 0.8499, -0.6519],\n",
            "        [-0.4860,  1.0140],\n",
            "        [ 0.7017, -0.3943],\n",
            "        [-0.3816,  0.8519]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9545, -1.0316],\n",
            "        [ 0.0849,  0.3291],\n",
            "        [-0.0120,  0.4753],\n",
            "        [-0.7274,  1.2174],\n",
            "        [-0.0481,  0.5005],\n",
            "        [ 0.2019,  0.2760],\n",
            "        [ 0.7857, -0.6054],\n",
            "        [-0.7071,  1.1142],\n",
            "        [-0.8397,  1.2777],\n",
            "        [-0.5757,  1.0315],\n",
            "        [ 0.4574, -0.2372],\n",
            "        [ 0.6660, -0.4647],\n",
            "        [-0.4145,  0.8191],\n",
            "        [-0.7300,  1.1534],\n",
            "        [-0.7896,  1.1434],\n",
            "        [ 0.3332,  0.1968],\n",
            "        [ 0.7090, -0.5990],\n",
            "        [-0.8587,  1.3008],\n",
            "        [-0.4310,  0.8443],\n",
            "        [-0.7603,  1.2612],\n",
            "        [-0.8208,  1.2302],\n",
            "        [ 0.4426, -0.2799],\n",
            "        [-0.6401,  1.1387],\n",
            "        [-0.8998,  1.3288],\n",
            "        [ 0.4762, -0.3132],\n",
            "        [ 0.1559,  0.2851],\n",
            "        [ 0.7146, -0.5594],\n",
            "        [ 0.8258, -1.0180],\n",
            "        [-0.2386,  0.6989],\n",
            "        [ 0.3988, -0.2127],\n",
            "        [ 0.8307, -0.7012],\n",
            "        [ 0.8554, -0.7079]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.7007, -0.4070],\n",
            "        [-0.7628,  1.1566],\n",
            "        [ 0.2082,  0.0261],\n",
            "        [ 0.6158, -0.5225],\n",
            "        [-0.0095,  0.4702],\n",
            "        [-0.1628,  0.5078],\n",
            "        [ 0.1279,  0.2201],\n",
            "        [-0.8175,  1.2614],\n",
            "        [ 0.5864, -0.3771],\n",
            "        [-0.5178,  0.9211],\n",
            "        [-0.8153,  1.2863],\n",
            "        [ 0.2928,  0.0492],\n",
            "        [-0.9167,  1.3281],\n",
            "        [ 0.5379, -0.0329],\n",
            "        [ 0.3804,  0.0363],\n",
            "        [ 0.3683, -0.0262],\n",
            "        [ 0.4087,  0.0652],\n",
            "        [ 0.3889,  0.0117],\n",
            "        [ 0.4767, -0.1184],\n",
            "        [ 0.9402, -0.9291],\n",
            "        [ 0.6660, -0.3619],\n",
            "        [ 0.0750,  0.2766],\n",
            "        [-0.0941,  0.5546],\n",
            "        [-0.7919,  1.2387],\n",
            "        [-0.8261,  1.2779],\n",
            "        [-0.3392,  0.9377],\n",
            "        [ 0.9478, -0.8641],\n",
            "        [ 0.2149,  0.2438],\n",
            "        [ 0.3334, -0.1265],\n",
            "        [-0.4801,  0.9373],\n",
            "        [ 0.5584, -0.3715],\n",
            "        [ 0.2152,  0.1373]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0112,  0.3904],\n",
            "        [-0.8839,  1.2566],\n",
            "        [ 0.1184, -0.0035],\n",
            "        [-0.8618,  1.3053],\n",
            "        [-0.7416,  1.2260],\n",
            "        [ 0.1377,  0.3532],\n",
            "        [ 0.8163, -0.7871],\n",
            "        [-0.2971,  0.6750],\n",
            "        [ 0.6871, -0.5606],\n",
            "        [ 0.2548,  0.1164],\n",
            "        [-0.8404,  1.2337],\n",
            "        [ 0.9699, -1.0330],\n",
            "        [-0.7311,  1.1936],\n",
            "        [ 0.1280,  0.3555],\n",
            "        [-0.7282,  1.1884],\n",
            "        [ 0.0805,  0.1689],\n",
            "        [-0.7826,  1.0988],\n",
            "        [-0.0533,  0.4619],\n",
            "        [ 1.0105, -1.1114],\n",
            "        [ 0.2043,  0.2854],\n",
            "        [ 0.1463,  0.1568],\n",
            "        [ 0.2708,  0.1729],\n",
            "        [-0.7569,  1.1788],\n",
            "        [-0.0074,  0.3688],\n",
            "        [-0.8104,  1.2649],\n",
            "        [ 0.5162, -0.2814],\n",
            "        [ 0.7820, -0.7712],\n",
            "        [ 0.3997, -0.0585],\n",
            "        [ 0.2121,  0.1603],\n",
            "        [-0.0419,  0.3810],\n",
            "        [ 0.6416, -0.4891],\n",
            "        [ 0.5632, -0.2231]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.5793,  0.9346],\n",
            "        [-0.1739,  0.6328],\n",
            "        [ 0.6421, -0.4201],\n",
            "        [ 0.6652, -0.5530],\n",
            "        [ 0.3059,  0.0716],\n",
            "        [-0.9876,  1.3566],\n",
            "        [-0.5966,  1.1135],\n",
            "        [ 1.0398, -1.1866],\n",
            "        [ 0.1382,  0.3509],\n",
            "        [ 0.5441, -0.5064],\n",
            "        [-0.2195,  0.5548],\n",
            "        [-0.6183,  1.0670],\n",
            "        [ 0.5345, -0.1356],\n",
            "        [ 1.0221, -1.1606],\n",
            "        [ 0.5279, -0.3838],\n",
            "        [-0.2989,  0.8043],\n",
            "        [ 0.7431, -0.4987],\n",
            "        [ 0.1658,  0.1446],\n",
            "        [-0.6405,  1.0741],\n",
            "        [ 0.2876,  0.1126],\n",
            "        [-0.7551,  1.2030],\n",
            "        [-0.8111,  1.2143],\n",
            "        [-0.0871,  0.4625],\n",
            "        [-0.0968,  0.5094],\n",
            "        [ 0.1511,  0.3769],\n",
            "        [-0.2391,  0.6235],\n",
            "        [-0.0110,  0.5991],\n",
            "        [-0.8405,  1.2896],\n",
            "        [-0.4008,  0.9760],\n",
            "        [-0.4477,  0.8744],\n",
            "        [ 0.7252, -0.5549],\n",
            "        [-0.0021,  0.4066]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3429, -0.0126],\n",
            "        [-0.2700,  0.9147],\n",
            "        [ 0.3434,  0.0285],\n",
            "        [-0.0832,  0.3745],\n",
            "        [-0.7125,  1.1289],\n",
            "        [ 0.2374,  0.2354],\n",
            "        [ 0.4328, -0.1409],\n",
            "        [-0.2887,  0.7959],\n",
            "        [-0.8190,  1.2668],\n",
            "        [-0.5259,  0.9738],\n",
            "        [-0.0796,  0.5877],\n",
            "        [-0.4624,  0.8957],\n",
            "        [-0.0711,  0.3485],\n",
            "        [-0.5541,  0.9341],\n",
            "        [-0.8384,  1.3180],\n",
            "        [-0.0339,  0.4811],\n",
            "        [-0.5765,  1.0081],\n",
            "        [ 0.6285, -0.4583],\n",
            "        [ 0.6100, -0.4328],\n",
            "        [-0.5169,  0.9228],\n",
            "        [-0.8599,  1.2668],\n",
            "        [-0.6812,  1.1583],\n",
            "        [-0.2065,  0.6332],\n",
            "        [-0.0338,  0.4556],\n",
            "        [ 0.8951, -0.7706],\n",
            "        [-0.2590,  0.7319],\n",
            "        [ 0.1603,  0.2662],\n",
            "        [ 0.0369,  0.3080],\n",
            "        [-0.7660,  1.1789],\n",
            "        [-0.0095,  0.3911],\n",
            "        [ 0.5912, -0.2268],\n",
            "        [-0.6897,  1.1384]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4654, -0.0849],\n",
            "        [-0.3078,  0.8365],\n",
            "        [-0.5826,  1.0420],\n",
            "        [ 0.2725,  0.1795],\n",
            "        [ 0.0356,  0.4676],\n",
            "        [-0.3777,  0.8421],\n",
            "        [-0.0984,  0.5136],\n",
            "        [-0.2605,  0.6544],\n",
            "        [-0.0014,  0.3122],\n",
            "        [-0.1975,  0.6300],\n",
            "        [ 0.6996, -0.5786],\n",
            "        [ 0.8323, -0.7714],\n",
            "        [-0.4715,  0.8835],\n",
            "        [-0.0625,  0.4357],\n",
            "        [-0.2334,  0.7138],\n",
            "        [ 0.2213,  0.1113],\n",
            "        [-0.1456,  0.5083],\n",
            "        [-0.0349,  0.3884],\n",
            "        [ 0.2168,  0.2532],\n",
            "        [-0.2836,  0.8384],\n",
            "        [ 0.8380, -0.7382],\n",
            "        [ 0.2120,  0.2176],\n",
            "        [-0.3625,  0.8695],\n",
            "        [ 0.7987, -0.6287],\n",
            "        [ 0.5571, -0.2862],\n",
            "        [ 0.3714, -0.1706],\n",
            "        [ 0.5428, -0.2797],\n",
            "        [-0.7817,  1.2085],\n",
            "        [ 0.5657, -0.2548],\n",
            "        [-0.5609,  1.0108],\n",
            "        [-0.1865,  0.6135],\n",
            "        [ 0.1718,  0.2865]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4139, -0.2147],\n",
            "        [-0.2168,  0.6154],\n",
            "        [ 0.5347, -0.2926],\n",
            "        [-0.0644,  0.4542],\n",
            "        [ 0.5201, -0.5353],\n",
            "        [ 0.2531,  0.0782],\n",
            "        [ 0.4705, -0.0328],\n",
            "        [ 0.8527, -0.7960],\n",
            "        [ 0.4275, -0.2205],\n",
            "        [ 0.6317, -0.5092],\n",
            "        [-0.1695,  0.6064],\n",
            "        [-0.2517,  0.7421],\n",
            "        [-0.1790,  0.5476],\n",
            "        [ 0.4223,  0.0033],\n",
            "        [ 0.4789, -0.0554],\n",
            "        [ 0.2037,  0.0444],\n",
            "        [-0.0660,  0.5840],\n",
            "        [-0.2848,  0.7079],\n",
            "        [-0.7858,  1.2566],\n",
            "        [-0.8035,  1.2361],\n",
            "        [-0.4830,  0.9749],\n",
            "        [ 0.7728, -0.6330],\n",
            "        [-0.5382,  1.0340],\n",
            "        [-0.7998,  1.2283],\n",
            "        [ 0.0766,  0.2734],\n",
            "        [-0.7789,  1.2226],\n",
            "        [ 0.7956, -0.9928],\n",
            "        [-0.0140,  0.3537],\n",
            "        [-0.4835,  1.0173],\n",
            "        [ 0.2603,  0.0215],\n",
            "        [ 0.7125, -0.8742],\n",
            "        [ 0.0694,  0.2591]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3908,  0.1385],\n",
            "        [ 0.5776, -0.3267],\n",
            "        [ 0.8900, -0.7458],\n",
            "        [-0.7815,  1.2191],\n",
            "        [ 0.4939, -0.0975],\n",
            "        [ 0.7659, -0.6751],\n",
            "        [-0.7779,  1.1765],\n",
            "        [-0.4279,  0.7769],\n",
            "        [-0.0061,  0.2690],\n",
            "        [-0.8112,  1.2405],\n",
            "        [-0.4607,  0.9612],\n",
            "        [-0.5452,  1.0079],\n",
            "        [ 0.8283, -0.5757],\n",
            "        [ 0.6121, -0.4105],\n",
            "        [-0.0297,  0.4088],\n",
            "        [ 0.0689,  0.3144],\n",
            "        [-0.4225,  0.9022],\n",
            "        [ 0.8229, -0.7359],\n",
            "        [-0.4425,  0.8471],\n",
            "        [ 0.2988,  0.2472],\n",
            "        [ 0.3982, -0.1460],\n",
            "        [ 0.6275, -0.2171],\n",
            "        [ 0.2742,  0.0686],\n",
            "        [ 0.1388,  0.3474],\n",
            "        [-0.6993,  1.1730],\n",
            "        [-0.7615,  1.2332],\n",
            "        [ 0.6686, -0.5399],\n",
            "        [-0.7622,  1.1493],\n",
            "        [ 0.5401, -0.3922],\n",
            "        [-0.6091,  1.0907],\n",
            "        [-0.7004,  1.1435],\n",
            "        [ 0.4129, -0.2664]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.2641,  0.7799],\n",
            "        [-0.9067,  1.2968],\n",
            "        [ 0.7606, -0.6203],\n",
            "        [-0.0245,  0.5285],\n",
            "        [-0.3225,  0.8419],\n",
            "        [-0.1792,  0.6070],\n",
            "        [-0.7709,  1.2029],\n",
            "        [-0.6353,  1.1087],\n",
            "        [-0.5535,  1.0110],\n",
            "        [ 0.6881, -0.3390],\n",
            "        [-0.6499,  1.1724],\n",
            "        [ 0.1697,  0.2703],\n",
            "        [ 0.3838, -0.0879],\n",
            "        [-0.4132,  0.9025],\n",
            "        [ 0.5422, -0.1815],\n",
            "        [ 0.2889,  0.2211],\n",
            "        [-0.8103,  1.2954],\n",
            "        [-0.7161,  1.2383],\n",
            "        [ 0.3139,  0.1622],\n",
            "        [ 0.1726,  0.3189],\n",
            "        [ 0.2407,  0.1406],\n",
            "        [ 0.5967, -0.3863],\n",
            "        [ 1.0963, -1.2036],\n",
            "        [ 0.7114, -0.4854],\n",
            "        [ 0.6342, -0.4064],\n",
            "        [ 0.8454, -0.7428],\n",
            "        [-0.3308,  0.7461],\n",
            "        [ 0.1064,  0.1510],\n",
            "        [-0.6154,  1.0286],\n",
            "        [-0.6122,  1.1303],\n",
            "        [ 0.2596,  0.0953],\n",
            "        [-0.2855,  0.5666]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0039,  0.5308],\n",
            "        [ 0.4472, -0.1295],\n",
            "        [ 0.1380,  0.3284],\n",
            "        [ 0.4871, -0.2588],\n",
            "        [ 0.4367, -0.0205],\n",
            "        [ 0.0489,  0.3912],\n",
            "        [-0.6730,  1.0095],\n",
            "        [ 0.6117, -0.3918],\n",
            "        [-0.0206,  0.4628],\n",
            "        [-0.8126,  1.1805],\n",
            "        [-0.5558,  1.0766],\n",
            "        [-0.1263,  0.6254],\n",
            "        [-0.0384,  0.4379],\n",
            "        [-0.3219,  0.8806],\n",
            "        [ 0.1745,  0.3114],\n",
            "        [-0.1318,  0.4695],\n",
            "        [ 0.8241, -0.6595],\n",
            "        [ 0.5798, -0.2673],\n",
            "        [ 0.1273,  0.2363],\n",
            "        [-0.0148,  0.4356],\n",
            "        [ 0.4819, -0.3498],\n",
            "        [-0.6663,  1.1854],\n",
            "        [ 0.9501, -0.9567],\n",
            "        [ 0.5593, -0.3369],\n",
            "        [ 0.9056, -0.9161],\n",
            "        [ 0.5307, -0.1487],\n",
            "        [-0.0681,  0.3741],\n",
            "        [-0.8046,  1.2760],\n",
            "        [ 0.3275,  0.0387],\n",
            "        [-0.7792,  1.2547],\n",
            "        [-0.8944,  1.3336],\n",
            "        [-0.7364,  1.1746]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0958,  0.6635],\n",
            "        [ 0.8769, -0.7179],\n",
            "        [-0.5252,  1.0020],\n",
            "        [ 0.0069,  0.4548],\n",
            "        [-0.5153,  1.0118],\n",
            "        [-0.2014,  0.6136],\n",
            "        [ 0.0469,  0.4169],\n",
            "        [ 0.6659, -0.5413],\n",
            "        [-0.8995,  1.3515],\n",
            "        [ 0.7802, -0.7563],\n",
            "        [ 0.1062,  0.3832],\n",
            "        [ 0.6147, -0.6004],\n",
            "        [ 0.6066, -0.3252],\n",
            "        [ 0.3572,  0.0043],\n",
            "        [ 0.3972, -0.0361],\n",
            "        [-0.5232,  0.9951],\n",
            "        [ 0.8929, -1.0340],\n",
            "        [ 0.7910, -0.5684],\n",
            "        [ 0.3823, -0.1570],\n",
            "        [ 0.6135, -0.4227],\n",
            "        [ 0.0601,  0.3153],\n",
            "        [-0.1423,  0.5736],\n",
            "        [-0.2403,  0.7053],\n",
            "        [ 0.2394,  0.0203],\n",
            "        [ 0.4287, -0.1046],\n",
            "        [ 1.0008, -0.9315],\n",
            "        [ 0.8509, -1.0803],\n",
            "        [ 0.0850,  0.4004],\n",
            "        [-0.8546,  1.2589],\n",
            "        [-0.7490,  1.1658],\n",
            "        [-0.2699,  0.6861],\n",
            "        [ 0.2490,  0.0171]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.5249,  1.0119],\n",
            "        [ 0.3342, -0.0993],\n",
            "        [-0.0177,  0.4552],\n",
            "        [-0.2411,  0.5459],\n",
            "        [-0.8628,  1.2433],\n",
            "        [-0.6130,  1.0151],\n",
            "        [ 0.5807, -0.3776],\n",
            "        [-0.0041,  0.4420],\n",
            "        [ 0.0709,  0.4391],\n",
            "        [-0.0347,  0.4734],\n",
            "        [-0.4281,  0.9014],\n",
            "        [ 0.2787,  0.1425],\n",
            "        [-0.4204,  0.9195],\n",
            "        [ 0.9394, -1.0539],\n",
            "        [-0.4512,  0.9139],\n",
            "        [-0.4686,  0.7879],\n",
            "        [ 0.3059,  0.1806],\n",
            "        [ 0.3219,  0.1602],\n",
            "        [ 0.6929, -0.6142],\n",
            "        [-0.0756,  0.4496],\n",
            "        [ 1.0139, -1.3125],\n",
            "        [-0.5836,  1.0653],\n",
            "        [ 0.5290, -0.3187],\n",
            "        [-0.5914,  0.9695],\n",
            "        [-0.7518,  1.1880],\n",
            "        [ 0.1806,  0.1833],\n",
            "        [ 0.2755, -0.0741],\n",
            "        [ 0.8790, -0.8403],\n",
            "        [ 0.3104,  0.1567],\n",
            "        [ 0.7012, -0.5136],\n",
            "        [ 0.2483,  0.1916],\n",
            "        [ 1.0373, -1.2546]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.1013,  0.2463],\n",
            "        [ 0.4901, -0.1416],\n",
            "        [ 0.5478, -0.2129],\n",
            "        [ 0.6155, -0.4888],\n",
            "        [-0.3076,  0.8891],\n",
            "        [ 0.6666, -0.5628],\n",
            "        [ 0.2328, -0.0477],\n",
            "        [ 0.9295, -0.9492],\n",
            "        [-0.8383,  1.2610],\n",
            "        [-0.7846,  1.1918],\n",
            "        [ 0.2320,  0.0243],\n",
            "        [ 0.8536, -0.7854],\n",
            "        [-0.7369,  1.1678],\n",
            "        [ 0.2633,  0.1253],\n",
            "        [ 0.9662, -0.9530],\n",
            "        [-0.5880,  1.0294],\n",
            "        [-0.7634,  1.2068],\n",
            "        [ 0.9927, -1.0758],\n",
            "        [-0.4300,  0.8967],\n",
            "        [ 0.6041, -0.5865],\n",
            "        [ 0.8475, -0.8086],\n",
            "        [ 0.3636,  0.0391],\n",
            "        [-0.8322,  1.2195],\n",
            "        [-0.7753,  1.2063],\n",
            "        [ 0.9451, -1.0242],\n",
            "        [-0.8012,  1.1632],\n",
            "        [ 0.3253,  0.0063],\n",
            "        [ 0.9392, -0.8345],\n",
            "        [ 0.9041, -0.8040],\n",
            "        [ 0.5381, -0.0723],\n",
            "        [-0.6810,  1.1137],\n",
            "        [-0.1334,  0.4700]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9079, -0.8518],\n",
            "        [-0.7464,  1.2123],\n",
            "        [-0.8630,  1.2849],\n",
            "        [ 0.8228, -0.9935],\n",
            "        [-0.8222,  1.2547],\n",
            "        [-0.1766,  0.5904],\n",
            "        [-0.6274,  1.1748],\n",
            "        [ 0.3433, -0.0700],\n",
            "        [ 0.9996, -1.2703],\n",
            "        [ 0.1010,  0.3722],\n",
            "        [-0.7833,  1.2095],\n",
            "        [-0.6197,  1.0412],\n",
            "        [ 0.7770, -0.5691],\n",
            "        [-0.8619,  1.2861],\n",
            "        [ 0.6922, -0.6278],\n",
            "        [ 0.5834, -0.3693],\n",
            "        [ 0.4886, -0.2979],\n",
            "        [-0.8158,  1.2283],\n",
            "        [ 0.6151, -0.4627],\n",
            "        [ 0.8426, -0.7135],\n",
            "        [ 0.7819, -0.9204],\n",
            "        [-0.6377,  0.9884],\n",
            "        [-0.7982,  1.1901],\n",
            "        [ 0.8536, -1.0028],\n",
            "        [ 0.4396, -0.2395],\n",
            "        [ 0.7681, -0.5182],\n",
            "        [ 0.1763,  0.2093],\n",
            "        [-0.1828,  0.5917],\n",
            "        [ 0.0420,  0.4221],\n",
            "        [ 0.0440,  0.3676],\n",
            "        [-0.2957,  0.7925],\n",
            "        [ 0.1332,  0.2869]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4726,  0.9848],\n",
            "        [ 0.0096,  0.3845],\n",
            "        [ 0.1265,  0.3763],\n",
            "        [-0.4791,  0.8962],\n",
            "        [ 0.5515, -0.2888],\n",
            "        [-0.7397,  1.1776],\n",
            "        [-0.7410,  1.2330],\n",
            "        [-0.7621,  1.1955],\n",
            "        [ 0.9127, -1.1349],\n",
            "        [ 0.7754, -0.7977],\n",
            "        [ 0.6732, -0.5296],\n",
            "        [-0.0687,  0.4795],\n",
            "        [-0.6019,  1.0328],\n",
            "        [ 0.7685, -0.8589],\n",
            "        [-0.8583,  1.2221],\n",
            "        [-0.1019,  0.6253],\n",
            "        [-0.0911,  0.5386],\n",
            "        [-0.5377,  0.9065],\n",
            "        [ 0.7497, -0.6969],\n",
            "        [-0.3875,  0.8664],\n",
            "        [ 0.8029, -0.6019],\n",
            "        [ 0.3017,  0.2006],\n",
            "        [-0.0150,  0.4334],\n",
            "        [ 0.0199,  0.4400],\n",
            "        [-0.1392,  0.5962],\n",
            "        [-0.4507,  0.9054],\n",
            "        [-0.3772,  0.9613],\n",
            "        [ 0.4632, -0.1692],\n",
            "        [ 0.5294, -0.3559],\n",
            "        [ 0.6034, -0.3045],\n",
            "        [ 0.4852, -0.2348],\n",
            "        [ 0.0172,  0.4637]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0516,  0.3905],\n",
            "        [ 0.2600,  0.0233],\n",
            "        [ 0.0902,  0.1858],\n",
            "        [ 0.9485, -0.9587],\n",
            "        [-0.7698,  1.2168],\n",
            "        [-0.2249,  0.4688],\n",
            "        [ 0.2215,  0.1919],\n",
            "        [-0.8717,  1.2760],\n",
            "        [-0.4770,  0.9137],\n",
            "        [ 0.2658,  0.0757],\n",
            "        [-0.3854,  0.8704],\n",
            "        [ 0.5385, -0.3336],\n",
            "        [-0.1495,  0.4718],\n",
            "        [-0.4643,  0.9372],\n",
            "        [-0.2923,  0.8221],\n",
            "        [-0.3262,  0.6617],\n",
            "        [ 0.8907, -0.7674],\n",
            "        [-0.1699,  0.7215],\n",
            "        [ 0.6387, -0.4224],\n",
            "        [ 0.3161, -0.1198],\n",
            "        [ 0.2339,  0.1792],\n",
            "        [-0.1961,  0.6660],\n",
            "        [-0.7580,  1.1220],\n",
            "        [-0.0360,  0.5154],\n",
            "        [-0.7837,  1.1731],\n",
            "        [-0.6275,  1.0760],\n",
            "        [-0.8348,  1.2746],\n",
            "        [ 0.2472,  0.1907],\n",
            "        [ 0.3853, -0.0608],\n",
            "        [ 0.8661, -0.9082],\n",
            "        [-0.7146,  1.0771],\n",
            "        [ 0.2428,  0.1548]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.2008,  0.7658],\n",
            "        [ 0.5799, -0.3879],\n",
            "        [ 0.5463, -0.5146],\n",
            "        [ 0.8235, -0.7183],\n",
            "        [-0.0377,  0.4804],\n",
            "        [ 0.0797,  0.3322],\n",
            "        [-0.7095,  1.2078],\n",
            "        [ 0.2935,  0.0582],\n",
            "        [-0.0831,  0.5828],\n",
            "        [ 0.4025,  0.0871],\n",
            "        [ 0.4707, -0.1834],\n",
            "        [ 0.5655, -0.3675],\n",
            "        [-0.5215,  0.9851],\n",
            "        [-0.1455,  0.5526],\n",
            "        [-0.8035,  1.2348],\n",
            "        [-0.5915,  1.0780],\n",
            "        [-0.4471,  0.8539],\n",
            "        [ 0.8001, -0.6255],\n",
            "        [ 0.6291, -0.3554],\n",
            "        [-0.2758,  0.7172],\n",
            "        [ 0.1500,  0.1938],\n",
            "        [ 0.0984,  0.3761],\n",
            "        [-0.3939,  0.8349],\n",
            "        [-0.6806,  1.1299],\n",
            "        [-0.7811,  1.1906],\n",
            "        [-0.8852,  1.2665],\n",
            "        [ 0.0702,  0.4230],\n",
            "        [ 0.5920, -0.1808],\n",
            "        [ 0.7933, -0.7007],\n",
            "        [ 0.7894, -0.7001],\n",
            "        [-0.0606,  0.4631],\n",
            "        [ 0.6584, -0.6687]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0315,  0.5543],\n",
            "        [-0.8597,  1.2771],\n",
            "        [ 0.0195,  0.4715],\n",
            "        [ 0.2388,  0.0383],\n",
            "        [-0.7061,  1.1647],\n",
            "        [ 0.0881,  0.3904],\n",
            "        [-0.3617,  0.7070],\n",
            "        [ 0.5146, -0.1112],\n",
            "        [-0.0764,  0.4445],\n",
            "        [ 0.3473, -0.1203],\n",
            "        [ 0.0204,  0.4584],\n",
            "        [-0.1915,  0.7025],\n",
            "        [-0.0450,  0.5347],\n",
            "        [ 0.1823,  0.3147],\n",
            "        [ 0.3949, -0.1652],\n",
            "        [ 0.9434, -1.0874],\n",
            "        [-0.0023,  0.4661],\n",
            "        [ 0.6407, -0.2618],\n",
            "        [ 0.2147,  0.1807],\n",
            "        [ 0.8202, -0.7396],\n",
            "        [-0.9325,  1.3054],\n",
            "        [ 0.4331, -0.1766],\n",
            "        [-0.4438,  0.9403],\n",
            "        [-0.1269,  0.6373],\n",
            "        [-0.1225,  0.6133],\n",
            "        [-0.2244,  0.6359],\n",
            "        [ 0.4933, -0.3902],\n",
            "        [-0.2214,  0.6068],\n",
            "        [-0.7698,  1.1977],\n",
            "        [-0.3939,  0.7887],\n",
            "        [-0.9055,  1.3433],\n",
            "        [-0.2572,  0.7399]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.1678,  0.6885],\n",
            "        [-0.8010,  1.2008],\n",
            "        [-0.5751,  0.9161],\n",
            "        [ 0.0307,  0.3925],\n",
            "        [ 0.9940, -1.0802],\n",
            "        [ 0.0168,  0.3900],\n",
            "        [ 0.5156, -0.3745],\n",
            "        [-0.6962,  1.1868],\n",
            "        [ 0.7769, -0.7170],\n",
            "        [-0.4948,  0.9818],\n",
            "        [-0.0551,  0.5465],\n",
            "        [ 0.0243,  0.3275],\n",
            "        [-0.8409,  1.2961],\n",
            "        [ 0.8360, -0.7820],\n",
            "        [-0.7702,  1.2439],\n",
            "        [-0.8726,  1.2907],\n",
            "        [ 0.6867, -0.6578],\n",
            "        [-0.1554,  0.5252],\n",
            "        [ 0.4901, -0.3598],\n",
            "        [-0.5487,  0.9879],\n",
            "        [ 0.2913,  0.0042],\n",
            "        [ 0.7795, -0.7740],\n",
            "        [ 0.6692, -0.5774],\n",
            "        [ 0.1841,  0.1506],\n",
            "        [ 0.3474, -0.0768],\n",
            "        [ 0.3522,  0.1159],\n",
            "        [ 0.7314, -0.5754],\n",
            "        [-0.0988,  0.5920],\n",
            "        [-0.0590,  0.5790],\n",
            "        [ 0.6287, -0.3989],\n",
            "        [-0.0741,  0.5560],\n",
            "        [ 0.7248, -0.5745]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.5479, -0.3749],\n",
            "        [ 0.1952,  0.2259],\n",
            "        [-0.8085,  1.2382],\n",
            "        [-0.7733,  1.1525],\n",
            "        [-0.7102,  1.1519],\n",
            "        [-0.1608,  0.7374],\n",
            "        [-0.6945,  1.1858],\n",
            "        [ 0.2615, -0.0255],\n",
            "        [-0.4794,  0.9577],\n",
            "        [ 0.5347, -0.2178],\n",
            "        [ 0.1200,  0.3946],\n",
            "        [-0.7736,  1.2592],\n",
            "        [-0.6236,  1.0219],\n",
            "        [ 0.8074, -0.7231],\n",
            "        [ 0.5127, -0.1291],\n",
            "        [ 0.3037,  0.1260],\n",
            "        [-0.7778,  1.2007],\n",
            "        [-0.5464,  0.9381],\n",
            "        [-0.9038,  1.2970],\n",
            "        [-0.8719,  1.2459],\n",
            "        [-0.2263,  0.6563],\n",
            "        [ 0.6128, -0.4713],\n",
            "        [ 0.1498,  0.3894],\n",
            "        [ 0.9050, -1.0929],\n",
            "        [-0.9325,  1.2884],\n",
            "        [ 0.1291,  0.2888],\n",
            "        [ 0.7919, -0.6429],\n",
            "        [-0.2037,  0.5163],\n",
            "        [ 0.3902, -0.0600],\n",
            "        [-0.2087,  0.7262],\n",
            "        [-0.4424,  0.8632],\n",
            "        [ 0.0699,  0.4224]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.7555, -0.6613],\n",
            "        [ 0.7654, -0.5460],\n",
            "        [ 1.0339, -1.0199],\n",
            "        [-0.7505,  1.1703],\n",
            "        [-0.7412,  1.1665],\n",
            "        [-0.0049,  0.3613],\n",
            "        [ 0.3307, -0.0524],\n",
            "        [ 0.1735,  0.0425],\n",
            "        [-0.9081,  1.3389],\n",
            "        [-0.8473,  1.2856],\n",
            "        [-0.2101,  0.6430],\n",
            "        [ 0.4543, -0.2811],\n",
            "        [ 0.1858,  0.1708],\n",
            "        [-0.3044,  0.8162],\n",
            "        [ 0.6208, -0.2125],\n",
            "        [ 0.7312, -0.6733],\n",
            "        [ 0.8649, -0.7760],\n",
            "        [-0.1073,  0.5835],\n",
            "        [ 0.0656,  0.2770],\n",
            "        [-0.1140,  0.5151],\n",
            "        [-0.6785,  1.1429],\n",
            "        [ 0.9333, -0.9105],\n",
            "        [-0.6351,  0.9860],\n",
            "        [-0.4472,  0.9170],\n",
            "        [-0.0809,  0.5442],\n",
            "        [-0.8331,  1.3296],\n",
            "        [-0.5881,  0.9802],\n",
            "        [ 0.1132,  0.0987],\n",
            "        [ 0.9418, -1.0008],\n",
            "        [ 0.0414,  0.4613],\n",
            "        [ 0.2865,  0.0987],\n",
            "        [ 0.5100, -0.2470]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7508,  1.1943],\n",
            "        [-0.3777,  0.8600],\n",
            "        [ 0.3738, -0.1588],\n",
            "        [ 0.6015, -0.4434],\n",
            "        [ 0.1343,  0.3476],\n",
            "        [ 0.2187,  0.2786],\n",
            "        [ 0.9283, -1.0148],\n",
            "        [-0.1281,  0.7263],\n",
            "        [-0.8431,  1.1997],\n",
            "        [ 0.1774,  0.1665],\n",
            "        [-0.8776,  1.2768],\n",
            "        [-0.7344,  1.1818],\n",
            "        [-0.5008,  1.0540],\n",
            "        [-0.1342,  0.6224],\n",
            "        [-0.5759,  1.0263],\n",
            "        [ 0.4681, -0.1234]], device='cuda:0')\n",
            "  Accuracy: 0.64\n",
            "  Development Loss: 0.64\n",
            "  Development took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ======== \n",
            "Training...\n",
            "current time:  19877 days, 12:13:56\n",
            "  Batch    40  of    497.    Elapsed: 0:00:09.\n",
            "current time:  19877 days, 12:14:05\n",
            "  Batch    80  of    497.    Elapsed: 0:00:17.\n",
            "current time:  19877 days, 12:14:14\n",
            "  Batch   120  of    497.    Elapsed: 0:00:26.\n",
            "current time:  19877 days, 12:14:22\n",
            "  Batch   160  of    497.    Elapsed: 0:00:34.\n",
            "current time:  19877 days, 12:14:31\n",
            "  Batch   200  of    497.    Elapsed: 0:00:43.\n",
            "current time:  19877 days, 12:14:39\n",
            "  Batch   240  of    497.    Elapsed: 0:00:51.\n",
            "current time:  19877 days, 12:14:48\n",
            "  Batch   280  of    497.    Elapsed: 0:01:00.\n",
            "current time:  19877 days, 12:14:57\n",
            "  Batch   320  of    497.    Elapsed: 0:01:09.\n",
            "current time:  19877 days, 12:15:05\n",
            "  Batch   360  of    497.    Elapsed: 0:01:17.\n",
            "current time:  19877 days, 12:15:14\n",
            "  Batch   400  of    497.    Elapsed: 0:01:26.\n",
            "current time:  19877 days, 12:15:22\n",
            "  Batch   440  of    497.    Elapsed: 0:01:34.\n",
            "current time:  19877 days, 12:15:31\n",
            "  Batch   480  of    497.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epoch took: 0:01:46\n",
            "\n",
            "Running Development...\n",
            "dev_logits:  tensor([[-0.5704,  0.9229],\n",
            "        [ 0.6242, -0.3931],\n",
            "        [-0.3450,  0.8457],\n",
            "        [ 0.6088, -0.3567],\n",
            "        [-0.6449,  0.8635],\n",
            "        [ 0.3931, -0.3199],\n",
            "        [-0.9773,  1.3824],\n",
            "        [ 0.0649,  0.0614],\n",
            "        [-1.1689,  1.5801],\n",
            "        [ 0.1904,  0.1666],\n",
            "        [-1.1142,  1.4876],\n",
            "        [-0.7584,  1.1633],\n",
            "        [-0.7323,  1.0468],\n",
            "        [-0.3836,  0.6122],\n",
            "        [ 0.1531,  0.1571],\n",
            "        [-1.0515,  1.3891],\n",
            "        [ 0.0518,  0.3356],\n",
            "        [ 0.6909, -0.6785],\n",
            "        [-0.2225,  0.6075],\n",
            "        [-0.9800,  1.4065],\n",
            "        [-0.9476,  1.4271],\n",
            "        [ 0.6573, -0.3626],\n",
            "        [ 0.1795,  0.0471],\n",
            "        [-0.2665,  0.6643],\n",
            "        [ 0.2201,  0.1290],\n",
            "        [-0.9251,  1.2897],\n",
            "        [ 1.1189, -1.4274],\n",
            "        [-0.1058,  0.4793],\n",
            "        [-0.1669,  0.5624],\n",
            "        [ 0.5173, -0.2995],\n",
            "        [ 0.0641,  0.4692],\n",
            "        [-0.5770,  0.8947]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6013,  1.0767],\n",
            "        [ 0.7337, -0.6229],\n",
            "        [ 0.3080, -0.0996],\n",
            "        [-1.1561,  1.5271],\n",
            "        [-0.6128,  0.9863],\n",
            "        [ 0.8847, -1.1509],\n",
            "        [ 0.2364,  0.0926],\n",
            "        [-0.9233,  1.3935],\n",
            "        [ 0.3354, -0.0241],\n",
            "        [-0.4954,  1.0053],\n",
            "        [ 0.1427,  0.1954],\n",
            "        [-1.0791,  1.5112],\n",
            "        [ 0.2881,  0.0907],\n",
            "        [ 0.5742, -0.5702],\n",
            "        [ 0.2852,  0.0409],\n",
            "        [-0.9869,  1.3865],\n",
            "        [-0.2406,  0.6183],\n",
            "        [-0.8613,  1.3491],\n",
            "        [-0.7457,  1.1902],\n",
            "        [-0.8542,  1.3099],\n",
            "        [ 0.0510,  0.0832],\n",
            "        [ 0.0990,  0.2194],\n",
            "        [-0.3016,  0.6738],\n",
            "        [-0.6774,  1.1057],\n",
            "        [ 0.0933,  0.1984],\n",
            "        [-0.3365,  0.5420],\n",
            "        [-0.4689,  1.0110],\n",
            "        [-0.7705,  1.2571],\n",
            "        [ 0.0082,  0.5059],\n",
            "        [-0.6036,  0.9850],\n",
            "        [ 0.0689, -0.0017],\n",
            "        [-0.9814,  1.4523]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9703,  1.4001],\n",
            "        [-0.7356,  1.3067],\n",
            "        [-1.0431,  1.3516],\n",
            "        [ 1.0640, -1.2692],\n",
            "        [-0.5019,  0.7330],\n",
            "        [ 0.7457, -0.8571],\n",
            "        [-1.1378,  1.4914],\n",
            "        [ 0.0092,  0.3328],\n",
            "        [-1.1587,  1.4550],\n",
            "        [-1.0120,  1.4566],\n",
            "        [ 0.9686, -1.2487],\n",
            "        [-0.6997,  1.0724],\n",
            "        [-1.1401,  1.4880],\n",
            "        [-0.6557,  1.0890],\n",
            "        [ 0.0441,  0.2087],\n",
            "        [-0.1078,  0.4059],\n",
            "        [ 0.5119, -0.6196],\n",
            "        [-0.9462,  1.3599],\n",
            "        [-0.7100,  0.9887],\n",
            "        [-0.8442,  1.1916],\n",
            "        [-0.7900,  1.1256],\n",
            "        [-1.0177,  1.3700],\n",
            "        [-0.9359,  1.3225],\n",
            "        [-0.2436,  0.6832],\n",
            "        [ 0.4255, -0.3257],\n",
            "        [ 0.0346,  0.3991],\n",
            "        [ 0.6755, -0.8057],\n",
            "        [-0.3691,  0.8111],\n",
            "        [-1.0850,  1.4472],\n",
            "        [-0.7140,  1.1511],\n",
            "        [-0.5865,  0.9835],\n",
            "        [-0.2041,  0.5658]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4776,  0.8593],\n",
            "        [ 0.5292, -0.5782],\n",
            "        [-0.1395,  0.5781],\n",
            "        [-0.6937,  1.0671],\n",
            "        [-1.1770,  1.5105],\n",
            "        [-0.4368,  0.9146],\n",
            "        [-0.4669,  0.8311],\n",
            "        [-0.8062,  1.2384],\n",
            "        [-0.4786,  0.6946],\n",
            "        [ 0.5521, -0.3103],\n",
            "        [-0.3133,  0.7674],\n",
            "        [-0.4500,  1.0235],\n",
            "        [-0.8344,  1.1533],\n",
            "        [-0.5737,  1.0448],\n",
            "        [ 0.1023,  0.0693],\n",
            "        [-1.0247,  1.4586],\n",
            "        [-0.6517,  0.9479],\n",
            "        [-0.8194,  1.2868],\n",
            "        [-1.1574,  1.5176],\n",
            "        [-0.8084,  1.1235],\n",
            "        [-0.8532,  1.1696],\n",
            "        [ 0.2146,  0.1035],\n",
            "        [ 0.3735, -0.1927],\n",
            "        [ 0.7339, -0.6136],\n",
            "        [ 0.4300, -0.1094],\n",
            "        [ 0.2716,  0.1699],\n",
            "        [-0.9681,  1.3584],\n",
            "        [ 0.5999, -0.5048],\n",
            "        [ 0.4068, -0.2717],\n",
            "        [ 0.2195,  0.1472],\n",
            "        [-0.1046,  0.5172],\n",
            "        [-0.5106,  0.6731]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.3707,  0.5301],\n",
            "        [-1.0180,  1.4356],\n",
            "        [-0.5230,  0.9119],\n",
            "        [-0.2404,  0.6199],\n",
            "        [-0.0687,  0.3388],\n",
            "        [ 0.2702,  0.1040],\n",
            "        [ 0.0272,  0.2515],\n",
            "        [-0.9948,  1.3363],\n",
            "        [ 0.1720,  0.0871],\n",
            "        [ 0.0752,  0.1507],\n",
            "        [-0.3268,  0.7558],\n",
            "        [-0.0139,  0.4181],\n",
            "        [ 0.8790, -0.9195],\n",
            "        [-0.5641,  1.0099],\n",
            "        [-0.8833,  1.2361],\n",
            "        [ 0.7503, -0.5565],\n",
            "        [-0.1622,  0.5177],\n",
            "        [-0.7385,  1.1137],\n",
            "        [-0.3170,  0.6187],\n",
            "        [-0.6699,  1.0210],\n",
            "        [ 0.7457, -0.7408],\n",
            "        [ 1.2282, -1.4276],\n",
            "        [-0.4963,  1.0981],\n",
            "        [-1.1818,  1.5429],\n",
            "        [-0.5914,  1.1209],\n",
            "        [ 0.8781, -0.9550],\n",
            "        [-0.1036,  0.5063],\n",
            "        [-0.5703,  0.9757],\n",
            "        [ 0.3914, -0.4300],\n",
            "        [-0.4973,  0.9644],\n",
            "        [-0.3088,  0.6490],\n",
            "        [-0.0630,  0.2737]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0068,  0.2896],\n",
            "        [-0.9934,  1.3688],\n",
            "        [ 0.3955, -0.2449],\n",
            "        [ 1.0568, -1.1080],\n",
            "        [ 0.1592,  0.2934],\n",
            "        [ 0.0763,  0.3250],\n",
            "        [ 0.5222, -0.3410],\n",
            "        [ 0.2412,  0.0266],\n",
            "        [ 0.2307, -0.0235],\n",
            "        [ 0.3453, -0.1110],\n",
            "        [ 0.6677, -0.7305],\n",
            "        [ 0.0434,  0.2212],\n",
            "        [-0.2350,  0.8036],\n",
            "        [-0.3160,  0.7233],\n",
            "        [ 0.5856, -0.4145],\n",
            "        [-0.4862,  0.9119],\n",
            "        [-0.2456,  0.4055],\n",
            "        [-0.7853,  1.1405],\n",
            "        [ 0.8507, -0.8882],\n",
            "        [-0.1852,  0.6011],\n",
            "        [ 0.6074, -0.5567],\n",
            "        [ 0.3449, -0.0075],\n",
            "        [-0.1334,  0.4653],\n",
            "        [ 0.0209,  0.3746],\n",
            "        [-0.8432,  1.3290],\n",
            "        [ 0.8018, -0.7678],\n",
            "        [-0.8395,  1.2362],\n",
            "        [ 0.3936, -0.3051],\n",
            "        [-0.8984,  1.2796],\n",
            "        [-0.4251,  0.6308],\n",
            "        [-0.9761,  1.2952],\n",
            "        [ 0.5539, -0.1980]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.3278,  0.7253],\n",
            "        [-0.2068,  0.6190],\n",
            "        [ 0.1023,  0.1878],\n",
            "        [-0.1035,  0.2514],\n",
            "        [-0.0532,  0.4985],\n",
            "        [-0.0192,  0.3106],\n",
            "        [-0.5664,  1.0016],\n",
            "        [-0.8118,  1.2753],\n",
            "        [ 0.2721,  0.0596],\n",
            "        [ 0.8640, -0.8185],\n",
            "        [-0.2904,  0.6884],\n",
            "        [-0.5061,  0.8696],\n",
            "        [ 0.5891, -0.4418],\n",
            "        [ 0.2723, -0.1970],\n",
            "        [ 0.6129, -0.3176],\n",
            "        [-1.0999,  1.4661],\n",
            "        [-0.9319,  1.3922],\n",
            "        [ 0.7831, -0.8667],\n",
            "        [ 0.0559,  0.3555],\n",
            "        [-0.6543,  0.9748],\n",
            "        [-0.3960,  0.8704],\n",
            "        [-1.1697,  1.5894],\n",
            "        [-1.0286,  1.4416],\n",
            "        [ 0.8816, -0.9383],\n",
            "        [-0.3066,  0.6678],\n",
            "        [ 0.2138,  0.1521],\n",
            "        [ 0.1520,  0.0901],\n",
            "        [-0.4208,  0.7121],\n",
            "        [-1.0337,  1.3299],\n",
            "        [-0.3748,  0.7890],\n",
            "        [-1.0127,  1.4628],\n",
            "        [-0.5467,  0.9584]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9598, -0.9272],\n",
            "        [-1.0505,  1.4747],\n",
            "        [ 0.0984,  0.3905],\n",
            "        [ 0.5395, -0.2683],\n",
            "        [-0.8525,  1.1667],\n",
            "        [-0.1463,  0.4386],\n",
            "        [-1.1342,  1.5078],\n",
            "        [-0.7982,  1.2212],\n",
            "        [-0.5593,  0.9761],\n",
            "        [-0.9018,  1.2862],\n",
            "        [ 0.2179, -0.2289],\n",
            "        [-0.3094,  0.6718],\n",
            "        [-0.4165,  0.7831],\n",
            "        [ 0.3782, -0.0702],\n",
            "        [-0.7251,  0.9302],\n",
            "        [ 0.7072, -0.4883],\n",
            "        [-0.2715,  0.6676],\n",
            "        [ 0.1577,  0.2830],\n",
            "        [-0.3656,  0.8311],\n",
            "        [ 0.1433,  0.2246],\n",
            "        [-0.3356,  0.6492],\n",
            "        [ 0.3603, -0.0986],\n",
            "        [ 0.5473, -0.1316],\n",
            "        [-0.2981,  0.6103],\n",
            "        [ 0.6752, -0.5889],\n",
            "        [-0.9644,  1.3989],\n",
            "        [-0.1134,  0.5454],\n",
            "        [-0.5623,  1.0394],\n",
            "        [-1.0339,  1.4572],\n",
            "        [ 0.4611, -0.1721],\n",
            "        [ 0.8532, -0.8183],\n",
            "        [ 0.3615, -0.3189]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0310,  1.4550],\n",
            "        [-0.5649,  0.9073],\n",
            "        [-0.0553,  0.5137],\n",
            "        [-0.8545,  1.2261],\n",
            "        [ 0.5813, -0.2809],\n",
            "        [-1.2504,  1.5713],\n",
            "        [-0.1918,  0.5420],\n",
            "        [-0.2304,  0.5568],\n",
            "        [-0.1945,  0.5151],\n",
            "        [ 0.5260, -0.4741],\n",
            "        [ 0.5004, -0.1828],\n",
            "        [ 0.2990,  0.0513],\n",
            "        [ 0.2032,  0.0932],\n",
            "        [ 0.0835,  0.3192],\n",
            "        [-0.0553,  0.2957],\n",
            "        [ 0.8544, -1.1165],\n",
            "        [-0.7512,  1.2733],\n",
            "        [-0.7397,  1.2827],\n",
            "        [ 1.0149, -1.1168],\n",
            "        [-0.1784,  0.6360],\n",
            "        [-0.1969,  0.3542],\n",
            "        [-0.5353,  0.9354],\n",
            "        [ 0.1458,  0.2733],\n",
            "        [ 1.1632, -1.3922],\n",
            "        [ 0.0573,  0.3206],\n",
            "        [ 0.6713, -0.5839],\n",
            "        [ 0.3783, -0.2291],\n",
            "        [ 0.6704, -0.6295],\n",
            "        [-0.2360,  0.4639],\n",
            "        [ 0.3768, -0.2573],\n",
            "        [-0.4349,  0.8778],\n",
            "        [-0.6040,  0.9354]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.2480,  0.6571],\n",
            "        [-0.3117,  0.6038],\n",
            "        [ 0.3190,  0.0949],\n",
            "        [-0.3717,  0.7549],\n",
            "        [ 0.4944, -0.2956],\n",
            "        [-1.1507,  1.4743],\n",
            "        [-0.2975,  0.7595],\n",
            "        [-0.4363,  0.9282],\n",
            "        [-0.1122,  0.5915],\n",
            "        [-0.2873,  0.8338],\n",
            "        [-0.9383,  1.2537],\n",
            "        [ 0.9435, -1.1141],\n",
            "        [-1.0584,  1.4745],\n",
            "        [-1.0938,  1.3733],\n",
            "        [-0.0788,  0.3483],\n",
            "        [-0.5986,  1.0829],\n",
            "        [-1.1527,  1.5447],\n",
            "        [ 0.8936, -0.9436],\n",
            "        [-0.1141,  0.5331],\n",
            "        [-1.1188,  1.4994],\n",
            "        [ 0.9403, -0.8675],\n",
            "        [-0.1217,  0.2542],\n",
            "        [ 0.5046, -0.1325],\n",
            "        [-0.9921,  1.3590],\n",
            "        [ 0.5217, -0.2963],\n",
            "        [-0.9985,  1.3629],\n",
            "        [-0.5094,  0.8760],\n",
            "        [-1.0277,  1.4609],\n",
            "        [-1.1559,  1.4843],\n",
            "        [-1.1726,  1.5797],\n",
            "        [ 0.4722, -0.6148],\n",
            "        [-0.8106,  1.2389]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.8452,  1.2163],\n",
            "        [ 0.0839,  0.2926],\n",
            "        [-1.0228,  1.3217],\n",
            "        [ 0.6403, -0.6291],\n",
            "        [ 1.0784, -1.1542],\n",
            "        [-0.8994,  1.3221],\n",
            "        [ 0.4780, -0.2910],\n",
            "        [ 1.0723, -1.0949],\n",
            "        [ 0.2419,  0.1109],\n",
            "        [-1.0492,  1.3410],\n",
            "        [-0.9171,  1.2617],\n",
            "        [ 1.0021, -1.1181],\n",
            "        [-0.5281,  0.9593],\n",
            "        [ 0.4222, -0.2445],\n",
            "        [ 0.3187, -0.0175],\n",
            "        [ 0.8724, -0.8587],\n",
            "        [ 0.7448, -0.6663],\n",
            "        [-1.1519,  1.5322],\n",
            "        [ 0.0732,  0.2431],\n",
            "        [-0.4582,  0.8278],\n",
            "        [ 1.0604, -1.2552],\n",
            "        [-0.9585,  1.3403],\n",
            "        [ 0.7370, -0.8722],\n",
            "        [-0.8685,  1.2578],\n",
            "        [-0.6569,  1.0339],\n",
            "        [-0.3112,  0.4276],\n",
            "        [-0.0815,  0.3223],\n",
            "        [ 0.6214, -0.6072],\n",
            "        [ 0.9754, -1.0419],\n",
            "        [-1.0272,  1.3463],\n",
            "        [ 0.3366, -0.1343],\n",
            "        [ 0.1019,  0.1586]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0335,  1.4443],\n",
            "        [-0.7755,  1.3217],\n",
            "        [-0.0087,  0.3623],\n",
            "        [-0.5003,  0.9177],\n",
            "        [-0.3065,  0.8088],\n",
            "        [-0.4824,  0.9757],\n",
            "        [-0.0169,  0.4648],\n",
            "        [-0.6657,  1.0581],\n",
            "        [-0.1362,  0.5924],\n",
            "        [-1.0673,  1.3986],\n",
            "        [-0.6181,  0.9126],\n",
            "        [ 1.0043, -0.9555],\n",
            "        [-0.3281,  0.7412],\n",
            "        [ 0.1347,  0.2321],\n",
            "        [ 0.0606,  0.3418],\n",
            "        [ 0.1146,  0.1762],\n",
            "        [-0.4231,  0.8341],\n",
            "        [-1.1037,  1.5113],\n",
            "        [ 0.5714, -0.4582],\n",
            "        [ 0.3172, -0.0070],\n",
            "        [ 1.1353, -1.3805],\n",
            "        [ 0.2483,  0.1429],\n",
            "        [ 1.0208, -1.2365],\n",
            "        [ 0.2709, -0.1734],\n",
            "        [-0.8100,  1.1302],\n",
            "        [-0.4574,  0.7958],\n",
            "        [ 0.0340,  0.4226],\n",
            "        [ 0.5348, -0.1697],\n",
            "        [-0.0966,  0.3156],\n",
            "        [-1.1156,  1.5444],\n",
            "        [-0.1690,  0.4639],\n",
            "        [-0.6566,  1.0633]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9162, -0.9427],\n",
            "        [-0.7850,  1.1573],\n",
            "        [ 0.3928, -0.1947],\n",
            "        [-0.0061,  0.4373],\n",
            "        [ 0.2531, -0.0171],\n",
            "        [-0.2616,  0.7257],\n",
            "        [-0.9693,  1.4215],\n",
            "        [-0.3131,  0.6852],\n",
            "        [-1.1277,  1.3918],\n",
            "        [ 0.4898, -0.4970],\n",
            "        [-0.8122,  1.3082],\n",
            "        [-0.4560,  0.8807],\n",
            "        [ 0.0681,  0.4233],\n",
            "        [-0.9100,  1.2696],\n",
            "        [-0.9909,  1.3838],\n",
            "        [ 0.5015, -0.3769],\n",
            "        [ 0.4542, -0.2065],\n",
            "        [ 0.8372, -0.7449],\n",
            "        [-0.2900,  0.7178],\n",
            "        [ 0.5825, -0.6330],\n",
            "        [-1.1044,  1.5340],\n",
            "        [-0.1047,  0.4215],\n",
            "        [-0.3497,  0.7012],\n",
            "        [-0.6973,  1.2026],\n",
            "        [-0.7732,  1.0804],\n",
            "        [-0.8370,  1.2697],\n",
            "        [-1.1081,  1.5178],\n",
            "        [ 0.3307,  0.0811],\n",
            "        [ 0.9556, -1.1368],\n",
            "        [-0.7665,  1.2747],\n",
            "        [-0.4052,  0.6981],\n",
            "        [-1.0515,  1.4323]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7611,  1.1475],\n",
            "        [ 0.9323, -1.0953],\n",
            "        [ 0.1976,  0.2486],\n",
            "        [-0.2062,  0.5686],\n",
            "        [-0.2694,  0.6294],\n",
            "        [-0.5508,  1.0753],\n",
            "        [-0.5765,  0.7115],\n",
            "        [ 0.2909, -0.0837],\n",
            "        [ 0.4168, -0.1890],\n",
            "        [ 0.7899, -1.0153],\n",
            "        [ 0.2885, -0.0212],\n",
            "        [-1.1043,  1.4960],\n",
            "        [-0.4268,  0.8661],\n",
            "        [-0.0680,  0.4719],\n",
            "        [-0.7238,  1.1899],\n",
            "        [-1.0316,  1.3958],\n",
            "        [-0.9612,  1.2789],\n",
            "        [ 1.1809, -1.4341],\n",
            "        [-0.0413,  0.3965],\n",
            "        [-1.1028,  1.4842],\n",
            "        [ 0.5521, -0.1930],\n",
            "        [-1.1289,  1.5290],\n",
            "        [-0.9659,  1.3551],\n",
            "        [-0.2533,  0.5377],\n",
            "        [-0.2420,  0.5525],\n",
            "        [-0.7673,  1.1050],\n",
            "        [ 0.7680, -0.6466],\n",
            "        [-0.2191,  0.5425],\n",
            "        [ 0.8552, -1.1014],\n",
            "        [-0.8286,  1.2516],\n",
            "        [-0.2221,  0.5332],\n",
            "        [-0.5745,  1.0678]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4320,  0.9191],\n",
            "        [ 0.6532, -0.4681],\n",
            "        [-0.6979,  1.1748],\n",
            "        [ 0.0362,  0.1253],\n",
            "        [-0.8004,  1.2700],\n",
            "        [-0.6207,  1.0662],\n",
            "        [-0.9789,  1.3600],\n",
            "        [ 0.5512, -0.4341],\n",
            "        [-0.5589,  0.9074],\n",
            "        [-1.0484,  1.4318],\n",
            "        [ 0.3290, -0.0986],\n",
            "        [-0.3122,  0.6421],\n",
            "        [-0.3529,  0.8018],\n",
            "        [ 0.6454, -0.6799],\n",
            "        [-0.2815,  0.8064],\n",
            "        [-0.0874,  0.5731],\n",
            "        [-0.2470,  0.6236],\n",
            "        [-0.2930,  0.7380],\n",
            "        [-0.2736,  0.7429],\n",
            "        [ 0.2305, -0.0252],\n",
            "        [ 1.0829, -1.2166],\n",
            "        [-1.1142,  1.5004],\n",
            "        [ 0.1292,  0.3433],\n",
            "        [-0.8461,  1.3056],\n",
            "        [ 0.1084,  0.3142],\n",
            "        [-0.4983,  0.9584],\n",
            "        [ 0.7642, -0.9076],\n",
            "        [ 0.7023, -0.6717],\n",
            "        [-0.2973,  0.7650],\n",
            "        [-1.1249,  1.4899],\n",
            "        [-0.6304,  1.1541],\n",
            "        [-1.1216,  1.5121]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9797,  1.3459],\n",
            "        [-0.2800,  0.5854],\n",
            "        [ 0.5534, -0.4181],\n",
            "        [-1.0772,  1.3939],\n",
            "        [-1.1131,  1.4684],\n",
            "        [-1.0986,  1.5322],\n",
            "        [-0.9713,  1.3780],\n",
            "        [-1.1199,  1.5026],\n",
            "        [-0.8548,  1.1449],\n",
            "        [-0.2750,  0.7474],\n",
            "        [-1.0289,  1.4304],\n",
            "        [ 0.5256, -0.2831],\n",
            "        [-0.3419,  0.8305],\n",
            "        [-0.9530,  1.3909],\n",
            "        [-1.1335,  1.5153],\n",
            "        [ 0.0168,  0.2985],\n",
            "        [-0.3864,  0.7160],\n",
            "        [-0.5361,  1.0267],\n",
            "        [-0.8489,  1.3619],\n",
            "        [ 0.6158, -0.5389],\n",
            "        [-1.0187,  1.3635],\n",
            "        [-0.4130,  0.6488],\n",
            "        [-0.3576,  0.8012],\n",
            "        [-0.1431,  0.5975],\n",
            "        [-0.1274,  0.4896],\n",
            "        [-0.3276,  0.8207],\n",
            "        [ 0.0852,  0.2239],\n",
            "        [-0.7520,  1.1024],\n",
            "        [-0.0373,  0.3847],\n",
            "        [-0.1403,  0.5307],\n",
            "        [-0.9231,  1.2850],\n",
            "        [-1.1833,  1.4993]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1651e+00,  1.5086e+00],\n",
            "        [-4.1289e-01,  7.7023e-01],\n",
            "        [-2.6519e-01,  7.1461e-01],\n",
            "        [ 4.0031e-01, -1.0865e-02],\n",
            "        [ 2.5836e-01,  6.9229e-02],\n",
            "        [ 8.3311e-01, -9.2357e-01],\n",
            "        [-6.3415e-01,  1.0483e+00],\n",
            "        [ 5.0836e-01, -5.1346e-01],\n",
            "        [-1.0671e+00,  1.4645e+00],\n",
            "        [-7.2617e-01,  1.2311e+00],\n",
            "        [ 3.7483e-01, -1.1453e-03],\n",
            "        [-6.5758e-01,  1.1130e+00],\n",
            "        [-9.0279e-01,  1.2469e+00],\n",
            "        [-7.8324e-01,  1.2409e+00],\n",
            "        [-7.9306e-01,  1.1477e+00],\n",
            "        [-9.0888e-01,  1.2849e+00],\n",
            "        [-8.6209e-01,  1.2868e+00],\n",
            "        [ 1.1750e+00, -1.2360e+00],\n",
            "        [-1.0923e+00,  1.4789e+00],\n",
            "        [-1.5538e-01,  6.0254e-01],\n",
            "        [-4.0296e-01,  7.9517e-01],\n",
            "        [ 1.8403e-01,  1.3535e-01],\n",
            "        [-1.6825e-01,  6.2527e-01],\n",
            "        [ 6.6039e-01, -4.9768e-01],\n",
            "        [-1.2670e-01,  5.9228e-01],\n",
            "        [-3.5588e-01,  8.2934e-01],\n",
            "        [-4.6406e-01,  9.6719e-01],\n",
            "        [-1.0329e+00,  1.4128e+00],\n",
            "        [ 1.2044e+00, -1.3981e+00],\n",
            "        [-1.0078e+00,  1.3750e+00],\n",
            "        [-6.2230e-01,  1.0198e+00],\n",
            "        [-1.0495e+00,  1.4573e+00]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1789,  1.5658],\n",
            "        [-0.4001,  0.7711],\n",
            "        [-0.1625,  0.5023],\n",
            "        [-0.4139,  0.7896],\n",
            "        [ 0.4586, -0.3458],\n",
            "        [ 0.7701, -0.6774],\n",
            "        [-0.4601,  0.8818],\n",
            "        [-0.0121,  0.3364],\n",
            "        [ 0.3906, -0.2113],\n",
            "        [ 0.3407, -0.1130],\n",
            "        [-0.1431,  0.5388],\n",
            "        [-1.2461,  1.5919],\n",
            "        [ 1.0516, -1.1839],\n",
            "        [-0.0734,  0.4734],\n",
            "        [-1.1816,  1.5381],\n",
            "        [-0.3775,  0.7938],\n",
            "        [ 0.5768, -0.3188],\n",
            "        [-0.0162,  0.5306],\n",
            "        [ 0.6160, -0.6667],\n",
            "        [-0.6437,  1.0403],\n",
            "        [-0.0227,  0.3567],\n",
            "        [-0.1276,  0.2527],\n",
            "        [-0.3788,  0.6822],\n",
            "        [ 0.3065, -0.1642],\n",
            "        [ 0.0603,  0.2765],\n",
            "        [-0.1549,  0.4510],\n",
            "        [-0.6709,  0.9720],\n",
            "        [-0.5541,  0.9196],\n",
            "        [-1.1628,  1.5315],\n",
            "        [-0.5024,  0.8374],\n",
            "        [-0.6962,  0.9909],\n",
            "        [-0.8373,  1.3077]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.1222,  0.5799],\n",
            "        [-0.6303,  1.1080],\n",
            "        [-1.1144,  1.4903],\n",
            "        [-0.8480,  1.2290],\n",
            "        [ 0.7953, -0.8946],\n",
            "        [ 0.9946, -1.1595],\n",
            "        [-0.6272,  1.1211],\n",
            "        [ 0.0042,  0.3408],\n",
            "        [-1.0132,  1.4500],\n",
            "        [ 0.8509, -0.9767],\n",
            "        [-0.5862,  0.8856],\n",
            "        [-1.0006,  1.3841],\n",
            "        [-0.4276,  0.9128],\n",
            "        [-0.9814,  1.3417],\n",
            "        [-0.2008,  0.7238],\n",
            "        [ 0.3868, -0.2170],\n",
            "        [-0.3254,  0.6415],\n",
            "        [-0.4309,  0.8805],\n",
            "        [-0.9801,  1.3507],\n",
            "        [ 0.3968, -0.5509],\n",
            "        [ 0.3019,  0.0292],\n",
            "        [-0.1278,  0.5793],\n",
            "        [-0.3067,  0.8644],\n",
            "        [-0.7816,  1.1164],\n",
            "        [-0.5874,  1.0304],\n",
            "        [-0.7162,  1.1252],\n",
            "        [ 0.2810, -0.0963],\n",
            "        [-0.2031,  0.6665],\n",
            "        [-0.8104,  1.3125],\n",
            "        [ 0.7412, -0.7686],\n",
            "        [ 0.2447, -0.0139],\n",
            "        [ 0.2169,  0.1088]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.8240, -0.7108],\n",
            "        [-0.3402,  0.5586],\n",
            "        [ 0.9632, -1.0250],\n",
            "        [ 0.3823, -0.5674],\n",
            "        [ 0.1959, -0.0543],\n",
            "        [-0.1614,  0.5385],\n",
            "        [ 0.2259,  0.1920],\n",
            "        [-1.0778,  1.4294],\n",
            "        [-0.1691,  0.6024],\n",
            "        [ 0.0942,  0.4129],\n",
            "        [-0.2984,  0.5411],\n",
            "        [-0.0273,  0.3153],\n",
            "        [-1.1217,  1.5086],\n",
            "        [ 0.1211,  0.2135],\n",
            "        [ 0.3238, -0.0663],\n",
            "        [-0.1271,  0.5953],\n",
            "        [-0.7339,  1.0742],\n",
            "        [ 0.3232, -0.0542],\n",
            "        [-0.2799,  0.6093],\n",
            "        [-1.0540,  1.4378],\n",
            "        [ 0.2107,  0.1912],\n",
            "        [ 1.1155, -1.1613],\n",
            "        [ 0.5287, -0.3479],\n",
            "        [-0.7251,  1.0866],\n",
            "        [-0.5309,  1.0223],\n",
            "        [-0.8817,  1.1662],\n",
            "        [-1.1070,  1.5413],\n",
            "        [-0.0056,  0.2150],\n",
            "        [-0.3351,  0.7306],\n",
            "        [-0.3396,  0.5899],\n",
            "        [ 0.2746,  0.0366],\n",
            "        [-0.2769,  0.8216]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0143,  0.2375],\n",
            "        [ 0.1775,  0.0250],\n",
            "        [-0.3316,  0.8008],\n",
            "        [-0.5607,  1.0441],\n",
            "        [-1.0847,  1.4543],\n",
            "        [ 0.4020, -0.1802],\n",
            "        [ 0.2335,  0.0396],\n",
            "        [-0.7572,  1.2377],\n",
            "        [ 0.3922, -0.1883],\n",
            "        [ 0.9535, -0.9015],\n",
            "        [ 0.7287, -0.7569],\n",
            "        [ 0.4184, -0.2855],\n",
            "        [-0.1998,  0.5827],\n",
            "        [ 0.7699, -0.8107],\n",
            "        [-0.3693,  0.8027],\n",
            "        [ 0.4259, -0.2203],\n",
            "        [ 0.2329, -0.1627],\n",
            "        [-0.7946,  1.2339],\n",
            "        [-1.0418,  1.4385],\n",
            "        [-1.0011,  1.4101],\n",
            "        [-0.8897,  1.2995],\n",
            "        [-0.8462,  1.0589],\n",
            "        [-0.9768,  1.3802],\n",
            "        [ 0.8272, -1.0764],\n",
            "        [ 0.8434, -0.7204],\n",
            "        [-0.7171,  1.0672],\n",
            "        [-1.1735,  1.5277],\n",
            "        [-1.0962,  1.3824],\n",
            "        [-0.9595,  1.4195],\n",
            "        [-0.0660,  0.5576],\n",
            "        [-0.2069,  0.6641],\n",
            "        [ 0.4211, -0.3266]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.1835, -0.0504],\n",
            "        [-0.3532,  0.7349],\n",
            "        [-0.6212,  1.0570],\n",
            "        [ 0.1363,  0.0921],\n",
            "        [-0.5842,  0.9662],\n",
            "        [-0.4401,  0.9540],\n",
            "        [ 0.7382, -0.8512],\n",
            "        [ 0.7352, -0.6901],\n",
            "        [ 0.3523, -0.1151],\n",
            "        [-0.8603,  1.2920],\n",
            "        [-0.3162,  0.6634],\n",
            "        [-0.7611,  1.1239],\n",
            "        [-1.0275,  1.2916],\n",
            "        [ 1.0487, -1.2240],\n",
            "        [-1.1464,  1.4781],\n",
            "        [ 0.0333,  0.4296],\n",
            "        [-0.7099,  1.1095],\n",
            "        [-0.1308,  0.5817],\n",
            "        [-0.7145,  1.2057],\n",
            "        [ 0.1328,  0.1696],\n",
            "        [-0.8146,  1.2755],\n",
            "        [-0.2500,  0.8016],\n",
            "        [-0.8443,  1.0760],\n",
            "        [ 0.3126, -0.0597],\n",
            "        [-0.5597,  0.7603],\n",
            "        [ 0.1287,  0.1138],\n",
            "        [ 0.3824, -0.1812],\n",
            "        [-1.1230,  1.4932],\n",
            "        [-0.6833,  1.0225],\n",
            "        [-0.4290,  0.8050],\n",
            "        [-1.0836,  1.5219],\n",
            "        [ 0.1898,  0.0851]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.5046,  0.8517],\n",
            "        [-0.8309,  0.9867],\n",
            "        [ 0.2529,  0.1098],\n",
            "        [-0.7701,  1.1444],\n",
            "        [-1.1511,  1.4762],\n",
            "        [ 1.0411, -1.1211],\n",
            "        [ 0.9903, -1.1260],\n",
            "        [ 0.7989, -0.7750],\n",
            "        [ 0.5526, -0.6233],\n",
            "        [-0.9737,  1.3926],\n",
            "        [-1.0334,  1.4261],\n",
            "        [-0.2264,  0.4522],\n",
            "        [ 0.3235, -0.1693],\n",
            "        [-0.9301,  1.3550],\n",
            "        [-0.8914,  1.3063],\n",
            "        [ 1.0044, -1.0672],\n",
            "        [ 0.1470,  0.1048],\n",
            "        [ 0.3853, -0.2925],\n",
            "        [ 0.9476, -0.9391],\n",
            "        [-1.0697,  1.5184],\n",
            "        [-0.9029,  1.3155],\n",
            "        [ 0.2215, -0.0545],\n",
            "        [-0.7586,  1.2092],\n",
            "        [-0.8990,  1.1740],\n",
            "        [-0.5560,  1.0518],\n",
            "        [-0.2051,  0.4036],\n",
            "        [-0.9224,  1.3358],\n",
            "        [-1.1481,  1.5171],\n",
            "        [ 0.6064, -0.5139],\n",
            "        [-0.7770,  1.1393],\n",
            "        [-1.0368,  1.3823],\n",
            "        [ 0.2192, -0.0027]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.1080,  0.5326],\n",
            "        [-0.0907,  0.5488],\n",
            "        [-0.8574,  1.3182],\n",
            "        [-0.1586,  0.6593],\n",
            "        [ 0.0875,  0.3667],\n",
            "        [ 0.7713, -0.9299],\n",
            "        [-0.6167,  1.0265],\n",
            "        [-0.1185,  0.3748],\n",
            "        [-0.1622,  0.3932],\n",
            "        [-0.2192,  0.5343],\n",
            "        [ 0.7279, -0.7707],\n",
            "        [ 0.5881, -0.7294],\n",
            "        [-0.0067,  0.4839],\n",
            "        [-0.8499,  1.2450],\n",
            "        [ 0.4867, -0.3392],\n",
            "        [-0.7394,  1.1221],\n",
            "        [-0.3073,  0.7603],\n",
            "        [-0.5235,  0.9979],\n",
            "        [-1.0731,  1.4606],\n",
            "        [-0.4874,  0.8518],\n",
            "        [-0.0352,  0.3479],\n",
            "        [ 0.6936, -0.5443],\n",
            "        [-0.9474,  1.3701],\n",
            "        [ 0.5613, -0.5637],\n",
            "        [ 0.2467, -0.0366],\n",
            "        [ 0.6663, -0.5725],\n",
            "        [-0.9101,  1.2720],\n",
            "        [ 0.1439,  0.1646],\n",
            "        [ 0.4472, -0.2445],\n",
            "        [ 1.1139, -1.3717],\n",
            "        [ 0.0393,  0.4516],\n",
            "        [-0.6148,  1.0159]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6435,  1.0044],\n",
            "        [ 0.3228, -0.2801],\n",
            "        [-1.0586,  1.4487],\n",
            "        [-1.0070,  1.3781],\n",
            "        [ 0.2431,  0.1612],\n",
            "        [-0.8424,  1.1489],\n",
            "        [ 0.5752, -0.5939],\n",
            "        [ 0.9042, -0.9604],\n",
            "        [-0.8083,  1.2363],\n",
            "        [ 0.9765, -0.9432],\n",
            "        [-0.0933,  0.4835],\n",
            "        [-0.5124,  0.8855],\n",
            "        [ 0.1187,  0.2507],\n",
            "        [-0.9043,  1.3008],\n",
            "        [-0.9331,  1.3490],\n",
            "        [-0.5492,  0.9429],\n",
            "        [ 0.7788, -0.6734],\n",
            "        [-1.0010,  1.3569],\n",
            "        [-0.9720,  1.4442],\n",
            "        [-1.0692,  1.4642],\n",
            "        [ 0.0483,  0.4603],\n",
            "        [-0.3220,  0.7962],\n",
            "        [ 0.2262,  0.2311],\n",
            "        [-0.1968,  0.5787],\n",
            "        [-0.8615,  1.3339],\n",
            "        [-0.7471,  1.2494],\n",
            "        [ 0.2159,  0.0686],\n",
            "        [-0.9299,  1.3182],\n",
            "        [ 0.9583, -1.0949],\n",
            "        [-0.9437,  1.2780],\n",
            "        [-0.9122,  1.3052],\n",
            "        [ 0.3889, -0.1867]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0744e-03,  3.6536e-01],\n",
            "        [-1.0413e+00,  1.4052e+00],\n",
            "        [-4.0754e-01,  8.5778e-01],\n",
            "        [ 3.0776e-01, -2.6394e-02],\n",
            "        [-2.0855e-01,  5.3939e-01],\n",
            "        [ 8.2605e-01, -7.2139e-01],\n",
            "        [-6.6090e-01,  1.0514e+00],\n",
            "        [ 4.4669e-01, -3.8396e-01],\n",
            "        [ 2.7607e-01, -4.2900e-02],\n",
            "        [-4.2668e-01,  7.1182e-01],\n",
            "        [-2.5718e-01,  5.5838e-01],\n",
            "        [-2.1414e-01,  5.9659e-01],\n",
            "        [ 1.7441e-01,  1.6138e-02],\n",
            "        [-1.0046e+00,  1.4419e+00],\n",
            "        [-4.2284e-01,  7.8274e-01],\n",
            "        [-5.0422e-01,  9.7946e-01],\n",
            "        [-7.9881e-02,  2.4367e-01],\n",
            "        [ 3.9509e-01, -1.2872e-01],\n",
            "        [-7.4193e-01,  1.0507e+00],\n",
            "        [ 7.0691e-01, -7.4342e-01],\n",
            "        [ 4.2650e-01, -3.6961e-01],\n",
            "        [ 1.2033e-01,  2.7772e-01],\n",
            "        [ 1.5162e-01,  9.8333e-02],\n",
            "        [-1.0976e-01,  5.5887e-01],\n",
            "        [ 6.3881e-02, -1.3731e-02],\n",
            "        [-4.4447e-01,  6.9831e-01],\n",
            "        [-3.5382e-01,  6.0763e-01],\n",
            "        [ 2.1125e-01,  1.2434e-01],\n",
            "        [-9.2638e-01,  1.2713e+00],\n",
            "        [ 7.0363e-01, -7.1863e-01],\n",
            "        [ 7.4741e-01, -6.6665e-01],\n",
            "        [ 7.4221e-01, -8.4402e-01]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6800,  1.0608],\n",
            "        [-0.7617,  1.0958],\n",
            "        [-0.0379,  0.4590],\n",
            "        [-0.7096,  1.0250],\n",
            "        [-0.9830,  1.3740],\n",
            "        [ 0.9386, -0.8727],\n",
            "        [-1.0735,  1.3564],\n",
            "        [-0.8993,  1.2653],\n",
            "        [ 0.4081, -0.1053],\n",
            "        [ 0.4611, -0.3225],\n",
            "        [-1.0278,  1.4739],\n",
            "        [-0.8542,  1.3812],\n",
            "        [-0.6657,  1.1479],\n",
            "        [-0.0279,  0.2759],\n",
            "        [ 0.1293,  0.0742],\n",
            "        [ 0.9303, -1.2056],\n",
            "        [-0.0220,  0.2730],\n",
            "        [-0.6289,  1.0853],\n",
            "        [ 0.1326,  0.0593],\n",
            "        [-1.0884,  1.4366],\n",
            "        [ 0.3108,  0.1396],\n",
            "        [-0.1286,  0.4752],\n",
            "        [-1.0274,  1.3754],\n",
            "        [ 0.7436, -0.6934],\n",
            "        [ 0.4573, -0.2112],\n",
            "        [-0.0914,  0.4434],\n",
            "        [-0.4842,  1.0050],\n",
            "        [-1.0891,  1.4597],\n",
            "        [-0.4559,  0.7704],\n",
            "        [ 0.2178,  0.1701],\n",
            "        [-0.3339,  0.8027],\n",
            "        [ 0.4230, -0.2027]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9423,  1.3506],\n",
            "        [ 0.1332,  0.3504],\n",
            "        [-0.9316,  1.3685],\n",
            "        [-0.0354,  0.2406],\n",
            "        [ 1.0462, -1.0769],\n",
            "        [-0.0034,  0.2489],\n",
            "        [ 0.1356,  0.3429],\n",
            "        [-0.8388,  1.1877],\n",
            "        [-0.5341,  0.8796],\n",
            "        [ 0.6846, -0.5557],\n",
            "        [ 0.2245,  0.0105],\n",
            "        [-1.2066,  1.5486],\n",
            "        [ 0.0520,  0.1095],\n",
            "        [-0.4715,  0.7913],\n",
            "        [-0.0682,  0.5095],\n",
            "        [ 0.2619,  0.3049],\n",
            "        [-0.6149,  1.0904],\n",
            "        [ 0.6678, -0.7708],\n",
            "        [ 0.5592, -0.4471],\n",
            "        [-0.4764,  0.8154],\n",
            "        [-0.4458,  0.7729],\n",
            "        [-0.9223,  1.2517],\n",
            "        [-0.2331,  0.6799],\n",
            "        [ 0.2066,  0.0068],\n",
            "        [-0.1818,  0.6087],\n",
            "        [-0.9394,  1.3486],\n",
            "        [ 0.1197, -0.0132],\n",
            "        [-0.0124,  0.3671],\n",
            "        [ 0.2855,  0.0989],\n",
            "        [-0.7298,  1.1734],\n",
            "        [ 0.3367, -0.1269],\n",
            "        [-0.4755,  0.8175]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7793,  1.1540],\n",
            "        [ 0.4672, -0.2876],\n",
            "        [-0.9028,  1.3431],\n",
            "        [-0.7878,  1.2487],\n",
            "        [-0.5041,  0.7133],\n",
            "        [ 0.4346, -0.2987],\n",
            "        [-1.1408,  1.4647],\n",
            "        [-0.1184,  0.5836],\n",
            "        [ 0.6513, -0.5060],\n",
            "        [ 0.1314, -0.0364],\n",
            "        [-0.8970,  1.3492],\n",
            "        [-0.5676,  0.9864],\n",
            "        [ 0.4980, -0.2743],\n",
            "        [ 0.6220, -0.4621],\n",
            "        [-1.0435,  1.4425],\n",
            "        [ 0.1259,  0.1052],\n",
            "        [-0.3013,  0.6120],\n",
            "        [-0.3682,  0.7852],\n",
            "        [-1.1501,  1.4895],\n",
            "        [-0.4186,  0.7540],\n",
            "        [ 0.3529,  0.0305],\n",
            "        [-0.9637,  1.3552],\n",
            "        [-1.1489,  1.5185],\n",
            "        [-0.9801,  1.3733],\n",
            "        [-0.2888,  0.7588],\n",
            "        [-0.0446,  0.4514],\n",
            "        [-0.0348,  0.4160],\n",
            "        [ 0.6772, -0.6512],\n",
            "        [-1.0451,  1.4571],\n",
            "        [ 0.8294, -0.9030],\n",
            "        [-0.4095,  0.7823],\n",
            "        [ 0.3726, -0.0735]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.1846,  0.3762],\n",
            "        [-1.0090,  1.4324],\n",
            "        [-0.0696,  0.4314],\n",
            "        [-0.0121,  0.4385],\n",
            "        [ 0.4337, -0.3606],\n",
            "        [-0.4014,  0.6668],\n",
            "        [-0.1353,  0.3369],\n",
            "        [ 1.0718, -1.2365],\n",
            "        [ 1.0028, -1.0558],\n",
            "        [-0.8898,  1.3039],\n",
            "        [ 0.5700, -0.2579],\n",
            "        [-0.6719,  0.9548],\n",
            "        [ 0.5019, -0.4293],\n",
            "        [ 0.4935, -0.1985],\n",
            "        [ 0.3296, -0.0146],\n",
            "        [ 0.4710, -0.2002],\n",
            "        [-0.4020,  0.8241],\n",
            "        [-0.8006,  1.2127],\n",
            "        [-0.1359,  0.6239],\n",
            "        [ 0.1037,  0.3886],\n",
            "        [-0.0771,  0.5660],\n",
            "        [-0.4355,  0.8467],\n",
            "        [ 0.0215,  0.4794],\n",
            "        [-0.0384,  0.4310],\n",
            "        [ 1.1242, -1.3467],\n",
            "        [-0.1745,  0.4862],\n",
            "        [ 0.6459, -0.4451],\n",
            "        [ 0.5940, -0.5558],\n",
            "        [-0.1922,  0.4822],\n",
            "        [-0.4712,  0.9733],\n",
            "        [-0.9476,  1.3911],\n",
            "        [ 0.6805, -0.6734]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9358, -1.0991],\n",
            "        [-0.8131,  1.0998],\n",
            "        [-0.5761,  1.0503],\n",
            "        [ 0.8096, -0.8128],\n",
            "        [ 0.8169, -0.9359],\n",
            "        [-1.0604,  1.4645],\n",
            "        [-0.8845,  1.3426],\n",
            "        [-0.9060,  1.2972],\n",
            "        [ 0.9419, -1.0247],\n",
            "        [-1.1872,  1.5824],\n",
            "        [ 0.2326,  0.1378],\n",
            "        [-0.3864,  0.7005],\n",
            "        [ 1.0698, -1.0878],\n",
            "        [ 0.5115, -0.4293],\n",
            "        [-1.1513,  1.5771],\n",
            "        [-0.7170,  1.0043],\n",
            "        [-0.6981,  1.1899],\n",
            "        [ 0.9002, -1.0442],\n",
            "        [-0.6449,  0.9036],\n",
            "        [-1.1055,  1.4716],\n",
            "        [-0.4443,  0.8160],\n",
            "        [ 0.1983,  0.1490],\n",
            "        [-0.8927,  1.2915],\n",
            "        [ 0.3523, -0.1636],\n",
            "        [-0.7634,  1.2024],\n",
            "        [-0.8545,  1.2204],\n",
            "        [-0.9475,  1.4054],\n",
            "        [-0.4196,  0.8859],\n",
            "        [ 1.0653, -1.2109],\n",
            "        [-0.4535,  0.9021],\n",
            "        [-0.7166,  1.0925],\n",
            "        [-0.6821,  0.9481]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4545,  0.8583],\n",
            "        [ 1.1284, -1.3299],\n",
            "        [-0.8450,  1.2585],\n",
            "        [-0.1154,  0.5845],\n",
            "        [ 0.0669,  0.2302],\n",
            "        [-1.0186,  1.3756],\n",
            "        [-1.0759,  1.4893],\n",
            "        [-0.1186,  0.5628],\n",
            "        [-0.3065,  0.7152],\n",
            "        [ 0.6084, -0.4922],\n",
            "        [-0.1865,  0.5484],\n",
            "        [-0.8596,  1.2560],\n",
            "        [ 0.4057, -0.1789],\n",
            "        [ 0.3668, -0.1226],\n",
            "        [ 0.3383, -0.1781],\n",
            "        [-0.3469,  0.5628],\n",
            "        [ 0.9905, -1.0233],\n",
            "        [-1.1053,  1.4884],\n",
            "        [-0.8727,  1.2881],\n",
            "        [-0.9663,  1.4077],\n",
            "        [-0.6029,  0.9336],\n",
            "        [-1.0411,  1.4134],\n",
            "        [ 0.1142,  0.3420],\n",
            "        [-1.0202,  1.4565],\n",
            "        [ 0.1933,  0.1743],\n",
            "        [-0.4185,  0.9910],\n",
            "        [-0.8785,  1.2917],\n",
            "        [-0.5102,  0.7451],\n",
            "        [-0.5144,  0.8009],\n",
            "        [-0.0619,  0.1076],\n",
            "        [-0.6323,  0.8684],\n",
            "        [ 0.4805, -0.2165]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9600,  1.3311],\n",
            "        [ 0.2558,  0.0103],\n",
            "        [ 0.1191,  0.0999],\n",
            "        [ 0.2393, -0.0253],\n",
            "        [ 0.6750, -0.6038],\n",
            "        [-1.1744,  1.5129],\n",
            "        [-0.3094,  0.6493],\n",
            "        [ 0.4993, -0.4988],\n",
            "        [ 0.7892, -0.7080],\n",
            "        [-0.5044,  0.7541],\n",
            "        [-0.1036,  0.4748],\n",
            "        [-0.1249,  0.2985],\n",
            "        [-1.1916,  1.5254],\n",
            "        [ 0.3630, -0.4384],\n",
            "        [-0.2683,  0.6341],\n",
            "        [-0.2330,  0.7624],\n",
            "        [ 0.8899, -0.9400],\n",
            "        [ 1.1077, -1.4029],\n",
            "        [-0.1290,  0.4284],\n",
            "        [-0.7956,  1.1983],\n",
            "        [-1.0887,  1.5189],\n",
            "        [-0.2882,  0.7936],\n",
            "        [-0.6338,  1.1310],\n",
            "        [-1.0271,  1.4359],\n",
            "        [ 0.3208, -0.0959],\n",
            "        [-0.0378,  0.4288],\n",
            "        [-0.3929,  0.6383],\n",
            "        [ 0.0162,  0.4001],\n",
            "        [ 0.2733, -0.0870],\n",
            "        [ 0.0767,  0.0384],\n",
            "        [-1.0793,  1.5030],\n",
            "        [ 0.3876, -0.0250]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.0270, -1.0962],\n",
            "        [ 0.4024, -0.0817],\n",
            "        [-0.3984,  0.8576],\n",
            "        [-1.0240,  1.4010],\n",
            "        [-1.0137,  1.4214],\n",
            "        [-0.0825,  0.2583],\n",
            "        [-0.1379,  0.3535],\n",
            "        [-0.2881,  0.6949],\n",
            "        [-0.3707,  0.8055],\n",
            "        [ 0.0731,  0.3959],\n",
            "        [-0.1285,  0.3998],\n",
            "        [-0.4075,  0.7433],\n",
            "        [-0.3931,  0.7751],\n",
            "        [-0.3934,  0.8458],\n",
            "        [-0.7388,  1.1409],\n",
            "        [-0.8472,  1.2521],\n",
            "        [ 0.1141,  0.2104],\n",
            "        [-0.8181,  1.1480],\n",
            "        [ 0.8589, -1.0150],\n",
            "        [-0.6471,  1.1609],\n",
            "        [ 0.5255, -0.1484],\n",
            "        [-0.8316,  1.2381],\n",
            "        [-0.1166,  0.4216],\n",
            "        [-0.3116,  0.7711],\n",
            "        [-0.4318,  0.8687],\n",
            "        [-0.0293,  0.3369],\n",
            "        [-0.1203,  0.4843],\n",
            "        [-0.5723,  0.9680],\n",
            "        [-0.9380,  1.3720],\n",
            "        [-0.4612,  0.9542],\n",
            "        [-0.7911,  1.2395],\n",
            "        [-0.9596,  1.2840]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.3239,  0.5886],\n",
            "        [ 0.4179, -0.0553],\n",
            "        [ 0.4747, -0.3831],\n",
            "        [ 0.4657, -0.2536],\n",
            "        [-0.3826,  0.6685],\n",
            "        [-0.8095,  1.2455],\n",
            "        [-1.0562,  1.3833],\n",
            "        [ 0.0480,  0.2332],\n",
            "        [-0.9835,  1.3774],\n",
            "        [-0.6482,  1.0062],\n",
            "        [-0.3811,  0.7475],\n",
            "        [ 0.9451, -1.2564],\n",
            "        [-0.8672,  1.3655],\n",
            "        [-0.3012,  0.7131],\n",
            "        [ 1.1647, -1.3276],\n",
            "        [-1.1418,  1.5098],\n",
            "        [-0.4679,  0.6929],\n",
            "        [-0.8665,  1.3378],\n",
            "        [ 0.9308, -0.8610],\n",
            "        [ 0.7920, -0.9299],\n",
            "        [-0.4394,  0.8376],\n",
            "        [ 0.2198,  0.2084],\n",
            "        [ 0.4223, -0.2106],\n",
            "        [-0.8459,  1.2130],\n",
            "        [-0.7615,  1.2451],\n",
            "        [-0.5586,  1.0247],\n",
            "        [-0.4226,  0.7510],\n",
            "        [-0.3104,  0.6723],\n",
            "        [ 0.3316, -0.0596],\n",
            "        [-1.1228,  1.5674],\n",
            "        [-0.4047,  0.7383],\n",
            "        [-0.3549,  0.6026]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7202,  1.1645],\n",
            "        [-0.5369,  0.9373],\n",
            "        [-0.4895,  0.7565],\n",
            "        [-0.9644,  1.4226],\n",
            "        [-0.7894,  1.1609],\n",
            "        [ 1.1874, -1.3423],\n",
            "        [ 0.0360,  0.2268],\n",
            "        [ 0.4151, -0.2779],\n",
            "        [-1.0080,  1.3509],\n",
            "        [ 0.0746,  0.3274],\n",
            "        [-0.2080,  0.6765],\n",
            "        [ 0.0710,  0.1066],\n",
            "        [-0.4095,  0.7296],\n",
            "        [ 0.2697,  0.0080],\n",
            "        [-1.0497,  1.3737],\n",
            "        [-0.6161,  1.0412],\n",
            "        [-0.1925,  0.5808],\n",
            "        [-0.5202,  0.9886],\n",
            "        [ 0.4389, -0.5448],\n",
            "        [ 0.5656, -0.3942],\n",
            "        [ 0.0373,  0.4568],\n",
            "        [-0.8496,  1.2357],\n",
            "        [ 0.7727, -0.8920],\n",
            "        [ 0.9410, -0.8688],\n",
            "        [-1.0699,  1.4195],\n",
            "        [-0.2247,  0.7334],\n",
            "        [-1.0082,  1.4396],\n",
            "        [ 0.6253, -0.6040],\n",
            "        [ 0.4652, -0.2238],\n",
            "        [-0.9134,  1.2570],\n",
            "        [ 1.0351, -1.1363],\n",
            "        [-0.4951,  0.9331]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9073,  1.3526],\n",
            "        [ 0.0243,  0.4195],\n",
            "        [-1.1669,  1.5637],\n",
            "        [ 1.1897, -1.4191],\n",
            "        [-0.0371,  0.3164],\n",
            "        [-0.7877,  1.0453],\n",
            "        [ 0.0269,  0.1656],\n",
            "        [ 0.1222,  0.2470],\n",
            "        [-0.3140,  0.5300],\n",
            "        [-0.0856,  0.5803],\n",
            "        [-0.1851,  0.4342],\n",
            "        [ 0.8343, -0.8301],\n",
            "        [ 0.0437,  0.4255],\n",
            "        [-1.2504,  1.5600],\n",
            "        [-0.3497,  0.7724],\n",
            "        [-0.8479,  1.2470],\n",
            "        [-0.9346,  1.3660],\n",
            "        [ 1.0287, -1.2343],\n",
            "        [-1.1774,  1.5324],\n",
            "        [-1.0805,  1.5105],\n",
            "        [ 0.2790,  0.1265],\n",
            "        [-0.8448,  1.2428],\n",
            "        [-0.2713,  0.5873],\n",
            "        [-0.1058,  0.4121],\n",
            "        [-0.3672,  0.8086],\n",
            "        [-1.1076,  1.4630],\n",
            "        [-0.9872,  1.3935],\n",
            "        [ 0.8651, -0.9452],\n",
            "        [-0.3684,  0.5831],\n",
            "        [-1.0990,  1.4939],\n",
            "        [-0.8246,  1.2191],\n",
            "        [-1.0249,  1.4611]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.1911,  0.1381],\n",
            "        [-1.0971,  1.4615],\n",
            "        [-0.2382,  0.4456],\n",
            "        [ 0.9515, -0.9378],\n",
            "        [-0.6662,  1.1578],\n",
            "        [-1.0410,  1.4424],\n",
            "        [ 0.4165, -0.2831],\n",
            "        [-1.2061,  1.5759],\n",
            "        [-0.4121,  0.7622],\n",
            "        [-0.2353,  0.7962],\n",
            "        [-0.9024,  1.3290],\n",
            "        [-1.0620,  1.4518],\n",
            "        [-0.0967,  0.5571],\n",
            "        [-0.5369,  0.9063],\n",
            "        [-1.0187,  1.2891],\n",
            "        [-0.5956,  1.0623],\n",
            "        [-0.0048,  0.4878],\n",
            "        [-0.9767,  1.3404],\n",
            "        [-0.4099,  0.8777],\n",
            "        [-1.0846,  1.4561],\n",
            "        [-0.0616,  0.2947],\n",
            "        [-0.8442,  1.1315],\n",
            "        [ 0.9091, -0.9745],\n",
            "        [-1.0452,  1.4637],\n",
            "        [-0.9180,  1.2245],\n",
            "        [-1.0011,  1.4292],\n",
            "        [-0.9361,  1.2548],\n",
            "        [-1.1194,  1.4606],\n",
            "        [-1.0336,  1.4781],\n",
            "        [ 0.3528, -0.0428],\n",
            "        [-0.0486,  0.4413],\n",
            "        [-0.0822,  0.3573]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4707,  0.6926],\n",
            "        [ 0.0134,  0.1385],\n",
            "        [ 0.3301,  0.0045],\n",
            "        [-0.1509,  0.5067],\n",
            "        [-0.8686,  1.1763],\n",
            "        [ 0.5116, -0.3578],\n",
            "        [-0.8735,  1.2124],\n",
            "        [ 0.0524,  0.1979],\n",
            "        [-1.0821,  1.4455],\n",
            "        [-0.8908,  1.2485],\n",
            "        [ 0.4387, -0.4749],\n",
            "        [-0.5589,  0.9319],\n",
            "        [-1.0490,  1.4059],\n",
            "        [ 0.2282,  0.1066],\n",
            "        [-0.4745,  0.6694],\n",
            "        [-0.7345,  1.0909],\n",
            "        [ 0.6708, -0.7075],\n",
            "        [ 0.4476, -0.1937],\n",
            "        [-0.7176,  1.2619],\n",
            "        [-0.1577,  0.4348],\n",
            "        [-0.5262,  0.9387],\n",
            "        [-0.4110,  0.9385],\n",
            "        [-1.1198,  1.5178],\n",
            "        [-0.0878,  0.5600],\n",
            "        [ 0.7937, -0.6478],\n",
            "        [-0.2520,  0.5511],\n",
            "        [ 0.8324, -0.8189],\n",
            "        [-1.1328,  1.4564],\n",
            "        [-1.1585,  1.5167],\n",
            "        [ 0.3919, -0.2171],\n",
            "        [-0.5016,  0.8960],\n",
            "        [-0.4256,  0.9228]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9144,  1.2207],\n",
            "        [-0.1280,  0.3157],\n",
            "        [-1.0085,  1.4405],\n",
            "        [-0.3000,  0.6696],\n",
            "        [-1.0092,  1.3304],\n",
            "        [-0.5598,  0.9755],\n",
            "        [-0.3117,  0.7288],\n",
            "        [-0.7495,  1.0674],\n",
            "        [-0.9526,  1.4025],\n",
            "        [-0.9261,  1.4261],\n",
            "        [-0.1594,  0.5065],\n",
            "        [-0.2680,  0.6005],\n",
            "        [-0.0966,  0.5736],\n",
            "        [-1.0538,  1.4419],\n",
            "        [-0.9682,  1.4400],\n",
            "        [-1.0393,  1.3894],\n",
            "        [-0.4269,  0.7787],\n",
            "        [ 0.8117, -0.8666],\n",
            "        [ 0.4561, -0.2247],\n",
            "        [-0.8078,  1.2127],\n",
            "        [-0.1487,  0.3389],\n",
            "        [ 1.1252, -1.3964],\n",
            "        [-0.6612,  1.1021],\n",
            "        [ 0.1688,  0.1200],\n",
            "        [-0.9160,  1.3025],\n",
            "        [-0.1899,  0.3757],\n",
            "        [ 0.4063, -0.1458],\n",
            "        [ 0.4513, -0.3675],\n",
            "        [-0.3597,  0.7248],\n",
            "        [-0.4767,  0.8057],\n",
            "        [-0.2584,  0.6414],\n",
            "        [ 0.2214,  0.2252]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3698, -0.1698],\n",
            "        [-1.0497,  1.4256],\n",
            "        [ 1.0156, -1.3482],\n",
            "        [-1.1558,  1.5407],\n",
            "        [ 0.7612, -0.7310],\n",
            "        [-0.8380,  1.2758],\n",
            "        [-0.2346,  0.5521],\n",
            "        [ 0.5397, -0.3609],\n",
            "        [-0.5196,  0.9270],\n",
            "        [-0.4816,  0.7960],\n",
            "        [-0.6007,  0.9314],\n",
            "        [ 0.4070, -0.2382],\n",
            "        [-0.6121,  0.9699],\n",
            "        [-0.5416,  0.9838],\n",
            "        [-1.1819,  1.5483],\n",
            "        [-1.1985,  1.5290],\n",
            "        [ 0.9433, -0.9517],\n",
            "        [ 0.2712,  0.0439],\n",
            "        [ 0.7023, -0.4812],\n",
            "        [-0.0176,  0.4207],\n",
            "        [-0.0364,  0.4864],\n",
            "        [ 0.6537, -0.6690],\n",
            "        [-0.8680,  1.3349],\n",
            "        [ 0.1425,  0.1134],\n",
            "        [-0.5581,  0.9806],\n",
            "        [ 0.6202, -0.5133],\n",
            "        [ 0.1682,  0.1430],\n",
            "        [ 0.2945, -0.1406],\n",
            "        [-0.1691,  0.4967],\n",
            "        [-0.3327,  0.6631],\n",
            "        [ 0.4073, -0.1923],\n",
            "        [-1.0483,  1.4555]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.2343,  0.6990],\n",
            "        [ 0.0908,  0.3325],\n",
            "        [ 0.0317,  0.2342],\n",
            "        [-0.2511,  0.6571],\n",
            "        [-0.5566,  1.0343],\n",
            "        [-0.4551,  0.7763],\n",
            "        [ 0.2051,  0.1540],\n",
            "        [ 0.1478,  0.2334],\n",
            "        [-0.1958,  0.4386],\n",
            "        [ 0.3643,  0.0145],\n",
            "        [-0.0028,  0.4306],\n",
            "        [ 0.1583,  0.0843],\n",
            "        [ 1.2595, -1.3943],\n",
            "        [ 0.1685,  0.1218],\n",
            "        [-1.0706,  1.4855],\n",
            "        [-1.0791,  1.4752],\n",
            "        [-1.0884,  1.5031],\n",
            "        [-0.6951,  1.1558],\n",
            "        [-0.0243,  0.3886],\n",
            "        [ 0.9509, -0.9415],\n",
            "        [-0.2246,  0.5412],\n",
            "        [-0.9863,  1.3347],\n",
            "        [-0.8323,  1.2507],\n",
            "        [ 0.9969, -0.8542],\n",
            "        [-0.3253,  0.7567],\n",
            "        [ 0.1858,  0.0933],\n",
            "        [-0.7687,  1.2453],\n",
            "        [-0.1760,  0.4901],\n",
            "        [-0.5192,  1.0030],\n",
            "        [-1.0593,  1.4808],\n",
            "        [ 0.4515, -0.1068],\n",
            "        [-0.7982,  1.1700]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3539, -0.0971],\n",
            "        [-0.2569,  0.7250],\n",
            "        [-0.4172,  0.8618],\n",
            "        [ 0.0883,  0.3533],\n",
            "        [-0.8576,  1.3017],\n",
            "        [ 0.3098, -0.1689],\n",
            "        [-1.0193,  1.4123],\n",
            "        [-0.7318,  1.1083],\n",
            "        [-0.3464,  0.7193],\n",
            "        [ 0.4363, -0.4156],\n",
            "        [ 0.7087, -0.6585],\n",
            "        [-0.1577,  0.5409],\n",
            "        [ 0.5826, -0.3583],\n",
            "        [ 0.5819, -0.3938],\n",
            "        [ 0.6187, -0.5643],\n",
            "        [-0.6641,  1.0206],\n",
            "        [-1.1873,  1.5439],\n",
            "        [-0.2688,  0.6554],\n",
            "        [ 0.0662,  0.4485],\n",
            "        [ 0.2567,  0.2139],\n",
            "        [ 0.5358, -0.2648],\n",
            "        [ 0.5908, -0.3730],\n",
            "        [ 0.2262,  0.0764],\n",
            "        [ 0.6902, -0.5894],\n",
            "        [-0.4814,  0.8888],\n",
            "        [ 0.2783, -0.2505],\n",
            "        [ 0.5991, -0.3835],\n",
            "        [ 0.1942,  0.1141],\n",
            "        [ 0.5061, -0.3702],\n",
            "        [-0.8312,  1.0383],\n",
            "        [ 0.9661, -1.1217],\n",
            "        [-0.4924,  0.8130]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6573,  1.1441],\n",
            "        [ 0.6034, -0.5364],\n",
            "        [ 0.3216, -0.0798],\n",
            "        [-1.1593,  1.5289],\n",
            "        [-1.0570,  1.4319],\n",
            "        [-1.0025,  1.3056],\n",
            "        [-0.1759,  0.4886],\n",
            "        [ 0.0119,  0.3333],\n",
            "        [-1.1235,  1.5150],\n",
            "        [-0.5513,  0.7758],\n",
            "        [ 0.6606, -0.7558],\n",
            "        [ 0.2640,  0.0367],\n",
            "        [-0.8946,  1.2083],\n",
            "        [-0.5516,  1.0576],\n",
            "        [ 0.6971, -0.5050],\n",
            "        [-0.8050,  1.1672],\n",
            "        [-0.9087,  1.2852],\n",
            "        [-1.0965,  1.4188],\n",
            "        [-0.4522,  0.9021],\n",
            "        [ 0.8831, -0.8359],\n",
            "        [ 0.2852, -0.0027],\n",
            "        [ 0.3574, -0.2076],\n",
            "        [-1.0329,  1.3928],\n",
            "        [-0.7459,  1.2467],\n",
            "        [-0.5057,  1.0133],\n",
            "        [ 0.9604, -1.0747],\n",
            "        [ 0.6183, -0.5285],\n",
            "        [-1.0659,  1.4750],\n",
            "        [ 0.8360, -0.8719],\n",
            "        [ 0.9880, -0.9910],\n",
            "        [ 0.2069,  0.1398],\n",
            "        [-0.4453,  0.8089]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3421, -0.0556],\n",
            "        [ 1.0441, -1.2743],\n",
            "        [-0.7226,  1.1588],\n",
            "        [-1.0883,  1.3868],\n",
            "        [ 0.8964, -0.9443],\n",
            "        [-0.4101,  0.7342],\n",
            "        [-0.9217,  1.3586],\n",
            "        [ 0.3144, -0.2360],\n",
            "        [ 0.4426, -0.4698],\n",
            "        [-0.8219,  1.2935],\n",
            "        [-0.5775,  0.9566],\n",
            "        [ 0.0428,  0.3580],\n",
            "        [-1.0072,  1.3820],\n",
            "        [ 1.1127, -1.3316],\n",
            "        [ 0.3368, -0.1330],\n",
            "        [-0.1851,  0.7102],\n",
            "        [ 0.9216, -0.9207],\n",
            "        [-0.9705,  1.3416],\n",
            "        [ 0.8259, -0.9111],\n",
            "        [ 0.2840,  0.1111],\n",
            "        [ 0.9850, -0.9984],\n",
            "        [-0.7353,  1.2474],\n",
            "        [-0.9884,  1.3425],\n",
            "        [ 0.1602,  0.1742],\n",
            "        [-0.1224,  0.4902],\n",
            "        [ 1.1352, -1.4216],\n",
            "        [-1.0212,  1.3439],\n",
            "        [-0.5532,  0.9687],\n",
            "        [ 0.9263, -1.0876],\n",
            "        [-0.4697,  0.8589],\n",
            "        [ 0.0864,  0.3114],\n",
            "        [-0.3507,  0.6778]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 7.4413e-01, -8.2353e-01],\n",
            "        [ 8.6064e-01, -1.0493e+00],\n",
            "        [-3.3678e-01,  8.1886e-01],\n",
            "        [ 3.3895e-01, -6.7319e-02],\n",
            "        [ 9.4346e-01, -1.0607e+00],\n",
            "        [ 7.6066e-01, -8.2601e-01],\n",
            "        [ 5.1613e-01, -5.0261e-01],\n",
            "        [-1.1745e+00,  1.5444e+00],\n",
            "        [ 1.9394e-01,  1.7991e-01],\n",
            "        [ 5.5426e-04,  4.4902e-01],\n",
            "        [ 3.0258e-01, -5.0073e-03],\n",
            "        [-7.6025e-01,  1.2914e+00],\n",
            "        [ 3.7865e-01, -1.4477e-01],\n",
            "        [-8.9213e-01,  1.3299e+00],\n",
            "        [-5.5061e-01,  9.2040e-01],\n",
            "        [ 3.7405e-01, -1.8171e-01],\n",
            "        [ 3.5151e-01, -1.6964e-01],\n",
            "        [ 4.9764e-01, -1.9578e-01],\n",
            "        [-1.0749e+00,  1.4916e+00],\n",
            "        [-6.2543e-01,  1.0737e+00],\n",
            "        [-9.1304e-01,  1.1814e+00],\n",
            "        [-2.9395e-01,  8.1789e-01],\n",
            "        [ 3.9210e-01, -1.8264e-01],\n",
            "        [ 8.5632e-01, -8.5242e-01],\n",
            "        [-2.5256e-01,  7.3536e-01],\n",
            "        [-1.1113e+00,  1.4728e+00],\n",
            "        [-6.5989e-01,  1.1984e+00],\n",
            "        [-2.0556e-01,  2.6035e-01],\n",
            "        [ 1.2015e+00, -1.4625e+00],\n",
            "        [ 1.5582e-01,  2.0092e-01],\n",
            "        [-1.1354e+00,  1.5240e+00],\n",
            "        [ 8.5391e-02,  3.6304e-01]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0598,  1.3852],\n",
            "        [ 1.0040, -1.2778],\n",
            "        [ 0.9834, -0.9890],\n",
            "        [-0.4902,  0.9668],\n",
            "        [-1.0350,  1.4630],\n",
            "        [-0.9736,  1.3500],\n",
            "        [-1.1995,  1.5690],\n",
            "        [-0.8190,  1.1991],\n",
            "        [-0.9669,  1.3132],\n",
            "        [-0.3300,  0.6636],\n",
            "        [ 0.2184,  0.2878],\n",
            "        [-0.0484,  0.2844],\n",
            "        [-0.9997,  1.3524],\n",
            "        [ 0.2800, -0.0258],\n",
            "        [ 0.1333,  0.1655],\n",
            "        [-0.2884,  0.6482],\n",
            "        [ 0.1671,  0.2068],\n",
            "        [ 0.9649, -0.8163],\n",
            "        [-0.9622,  1.2637],\n",
            "        [ 0.8591, -0.7003],\n",
            "        [-1.0533,  1.4487],\n",
            "        [ 0.4309, -0.4355],\n",
            "        [ 0.2122, -0.1395],\n",
            "        [-0.9545,  1.3803],\n",
            "        [ 0.4001, -0.1675],\n",
            "        [-0.5123,  0.8109],\n",
            "        [-0.4553,  0.9468],\n",
            "        [ 0.8883, -0.7993],\n",
            "        [-0.3341,  0.6266],\n",
            "        [ 0.3333, -0.0257],\n",
            "        [ 0.2661, -0.0781],\n",
            "        [ 0.5058, -0.3265]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9996, -1.0097],\n",
            "        [-0.2435,  0.6381],\n",
            "        [-0.3488,  0.7458],\n",
            "        [ 0.3026, -0.0150],\n",
            "        [ 0.9103, -1.1154],\n",
            "        [-0.8408,  1.2195],\n",
            "        [-0.1884,  0.6709],\n",
            "        [-0.9304,  1.3866],\n",
            "        [-0.3486,  0.7875],\n",
            "        [-0.9999,  1.4515],\n",
            "        [ 0.1504,  0.2412],\n",
            "        [-1.1274,  1.4315],\n",
            "        [ 0.0107,  0.4358],\n",
            "        [-0.0153,  0.3634],\n",
            "        [-0.5376,  0.7341],\n",
            "        [ 0.3661, -0.1399],\n",
            "        [ 0.3487,  0.0218],\n",
            "        [ 0.7054, -0.6637],\n",
            "        [ 0.2964,  0.0951],\n",
            "        [-0.6678,  0.9658],\n",
            "        [-1.0025,  1.3535],\n",
            "        [-0.2269,  0.5353],\n",
            "        [-0.0712,  0.3642],\n",
            "        [-0.5636,  0.8549],\n",
            "        [-0.6914,  1.0834],\n",
            "        [ 0.3529, -0.1439],\n",
            "        [-1.1503,  1.5403],\n",
            "        [-1.1922,  1.5527],\n",
            "        [-1.0321,  1.4685],\n",
            "        [ 0.2292,  0.2788],\n",
            "        [-0.1271,  0.5181],\n",
            "        [ 0.7114, -0.6265]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4906, -0.3652],\n",
            "        [-0.8250,  1.2908],\n",
            "        [ 0.9693, -1.2298],\n",
            "        [-1.1121,  1.4287],\n",
            "        [-1.0941,  1.4668],\n",
            "        [ 0.2198,  0.0062],\n",
            "        [-0.3427,  0.7503],\n",
            "        [-0.0095,  0.3473],\n",
            "        [ 0.0731,  0.4023],\n",
            "        [ 0.8634, -0.9687],\n",
            "        [ 0.5176, -0.2602],\n",
            "        [-0.5321,  0.8561],\n",
            "        [-0.3359,  0.8485],\n",
            "        [-0.0572,  0.4714],\n",
            "        [-0.3920,  0.6957],\n",
            "        [-0.0058,  0.4671],\n",
            "        [ 0.0265,  0.2194],\n",
            "        [-0.3635,  0.8636],\n",
            "        [-1.0757,  1.3700],\n",
            "        [-1.0606,  1.5010],\n",
            "        [-0.5652,  0.9719],\n",
            "        [ 0.1255,  0.3217],\n",
            "        [-1.0139,  1.4232],\n",
            "        [-0.7933,  1.1126],\n",
            "        [ 1.2058, -1.3831],\n",
            "        [-0.4510,  0.6919],\n",
            "        [-0.0337,  0.3593],\n",
            "        [-0.1283,  0.4550],\n",
            "        [ 0.2864,  0.0546],\n",
            "        [ 0.5148, -0.4567],\n",
            "        [-0.7193,  1.2116],\n",
            "        [ 0.0492,  0.2828]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1304,  1.4733],\n",
            "        [ 0.1409,  0.3626],\n",
            "        [-1.1803,  1.5313],\n",
            "        [ 0.3818, -0.1235],\n",
            "        [-0.6066,  0.9897],\n",
            "        [-0.6959,  1.1175],\n",
            "        [-0.1654,  0.6844],\n",
            "        [-0.7299,  1.1749],\n",
            "        [-0.2972,  0.3549],\n",
            "        [ 0.6227, -0.5661],\n",
            "        [ 0.9527, -1.0148],\n",
            "        [ 0.0374,  0.2773],\n",
            "        [ 0.1747,  0.1060],\n",
            "        [ 0.2459, -0.1420],\n",
            "        [-0.8108,  1.3017],\n",
            "        [ 0.0760,  0.2591],\n",
            "        [-0.9146,  1.3053],\n",
            "        [-0.1605,  0.6939],\n",
            "        [ 0.9545, -1.1882],\n",
            "        [-0.8053,  1.0105],\n",
            "        [-0.1890,  0.6767],\n",
            "        [ 0.4391, -0.3041],\n",
            "        [ 0.0282,  0.1762],\n",
            "        [-0.8167,  1.1240],\n",
            "        [ 0.4007, -0.3173],\n",
            "        [ 0.5444, -0.4307],\n",
            "        [ 0.7388, -0.8382],\n",
            "        [-0.5473,  0.9454],\n",
            "        [-0.8082,  1.1681],\n",
            "        [-1.0447,  1.4566],\n",
            "        [ 1.0063, -1.1598],\n",
            "        [ 0.9936, -0.9077]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6434,  1.0241],\n",
            "        [-0.3355,  0.7675],\n",
            "        [-0.8989,  1.4228],\n",
            "        [-0.5039,  1.0218],\n",
            "        [ 1.0151, -1.1440],\n",
            "        [-0.9500,  1.3403],\n",
            "        [-0.2715,  0.6880],\n",
            "        [-0.8253,  1.1337],\n",
            "        [-0.4870,  0.9075],\n",
            "        [-0.2781,  0.6603],\n",
            "        [-0.5011,  1.0192],\n",
            "        [ 0.6509, -0.4448],\n",
            "        [-1.0152,  1.3280],\n",
            "        [-1.0288,  1.4568],\n",
            "        [-0.5750,  1.0009],\n",
            "        [ 1.2455, -1.4155],\n",
            "        [-1.1590,  1.4879],\n",
            "        [-1.0400,  1.3999],\n",
            "        [-0.7807,  1.1013],\n",
            "        [-0.6047,  1.0043],\n",
            "        [-1.0057,  1.3511],\n",
            "        [ 0.5588, -0.4046],\n",
            "        [ 0.2615, -0.0892],\n",
            "        [-0.8249,  1.1995],\n",
            "        [ 0.4312, -0.2555],\n",
            "        [-0.1745,  0.6406],\n",
            "        [-0.2481,  0.7269],\n",
            "        [-1.0044,  1.3852],\n",
            "        [ 0.4173, -0.0429],\n",
            "        [-0.0118,  0.4748],\n",
            "        [-0.2732,  0.6499],\n",
            "        [ 0.1127,  0.3122]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6219,  1.0907],\n",
            "        [-0.3200,  0.7110],\n",
            "        [ 0.8775, -0.9321],\n",
            "        [-1.0199,  1.3845],\n",
            "        [ 0.8248, -1.0031],\n",
            "        [ 0.4234, -0.2567],\n",
            "        [-0.0173,  0.3963],\n",
            "        [ 0.3771, -0.1398],\n",
            "        [-0.5533,  0.7981],\n",
            "        [-0.8324,  1.1813],\n",
            "        [-0.9745,  1.4545],\n",
            "        [ 0.8416, -0.9121],\n",
            "        [-1.1174,  1.4725],\n",
            "        [-0.2876,  0.8177],\n",
            "        [-1.0700,  1.3482],\n",
            "        [ 0.4924, -0.3403],\n",
            "        [ 0.1791,  0.2437],\n",
            "        [-0.8196,  1.2138],\n",
            "        [-1.1091,  1.4524],\n",
            "        [-1.1364,  1.4801],\n",
            "        [ 0.1376,  0.1266],\n",
            "        [ 0.9889, -1.0440],\n",
            "        [-0.6783,  1.0262],\n",
            "        [-0.4778,  0.7785],\n",
            "        [-0.8096,  1.2425],\n",
            "        [-1.0187,  1.4220],\n",
            "        [-0.3568,  0.6703],\n",
            "        [ 0.2060, -0.0328],\n",
            "        [-0.9146,  1.3883],\n",
            "        [ 0.3815, -0.1756],\n",
            "        [-1.1022,  1.4619],\n",
            "        [-0.2563,  0.6778]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7909,  1.2491],\n",
            "        [ 0.0278,  0.2142],\n",
            "        [ 0.1402,  0.0672],\n",
            "        [ 0.0422,  0.3407],\n",
            "        [-0.9387,  1.2931],\n",
            "        [ 0.2025,  0.2544],\n",
            "        [ 0.3108,  0.0458],\n",
            "        [-0.8318,  1.2699],\n",
            "        [-0.2442,  0.5385],\n",
            "        [ 1.0477, -1.1806],\n",
            "        [-1.0836,  1.4830],\n",
            "        [-1.1364,  1.4581],\n",
            "        [ 0.6528, -0.6620],\n",
            "        [ 0.3364, -0.3610],\n",
            "        [-1.0963,  1.5209],\n",
            "        [-0.6635,  0.9425],\n",
            "        [-0.4852,  0.8788],\n",
            "        [ 0.2054,  0.1493],\n",
            "        [ 0.0088,  0.3762],\n",
            "        [ 0.0468,  0.3536],\n",
            "        [-1.0814,  1.4938],\n",
            "        [-1.1666,  1.5220],\n",
            "        [-1.0720,  1.4748],\n",
            "        [-0.1857,  0.5918],\n",
            "        [-0.9144,  1.3530],\n",
            "        [ 0.5142, -0.2807],\n",
            "        [-0.4495,  0.8652],\n",
            "        [-0.0255,  0.3938],\n",
            "        [-0.9393,  1.4326],\n",
            "        [-0.2616,  0.5971],\n",
            "        [ 0.3625, -0.2652],\n",
            "        [ 1.1028, -1.2850]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4521,  0.9055],\n",
            "        [ 0.0838,  0.4092],\n",
            "        [ 0.9879, -1.1754],\n",
            "        [ 0.2272,  0.1195],\n",
            "        [-1.2269,  1.5877],\n",
            "        [ 0.4021, -0.1912],\n",
            "        [-0.6826,  0.8912],\n",
            "        [ 1.0956, -1.1597],\n",
            "        [-0.7942,  1.2225],\n",
            "        [-1.1216,  1.4554],\n",
            "        [-0.5957,  0.8461],\n",
            "        [-0.8686,  1.3141],\n",
            "        [ 0.1681,  0.0209],\n",
            "        [-0.2108,  0.6877],\n",
            "        [-0.9717,  1.2777],\n",
            "        [-0.9460,  1.3831],\n",
            "        [-0.2565,  0.7161],\n",
            "        [-0.6696,  1.0578],\n",
            "        [-0.1504,  0.6460],\n",
            "        [-0.8288,  1.3393],\n",
            "        [ 0.3865, -0.1420],\n",
            "        [-1.0901,  1.5203],\n",
            "        [-1.1737,  1.5558],\n",
            "        [-0.5454,  1.0167],\n",
            "        [-0.6327,  0.8199],\n",
            "        [-0.9791,  1.4721],\n",
            "        [ 0.0404,  0.1633],\n",
            "        [-0.7729,  1.1385],\n",
            "        [-0.6430,  1.0941],\n",
            "        [ 1.0978, -1.2675],\n",
            "        [ 0.0788,  0.4039],\n",
            "        [-0.7935,  1.2844]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0713,  0.0627],\n",
            "        [ 0.1340,  0.0570],\n",
            "        [-1.0275,  1.4094],\n",
            "        [ 0.1785,  0.0671],\n",
            "        [ 0.3568, -0.3123],\n",
            "        [-0.0336,  0.4584],\n",
            "        [ 0.6679, -0.5176],\n",
            "        [ 0.5380, -0.4471],\n",
            "        [ 0.5469, -0.4223],\n",
            "        [ 0.6878, -0.5048],\n",
            "        [-0.3197,  0.7228],\n",
            "        [-0.1823,  0.3546],\n",
            "        [ 0.0927,  0.2843],\n",
            "        [-0.9296,  1.3040],\n",
            "        [ 0.0923,  0.1891],\n",
            "        [-0.6467,  1.0224],\n",
            "        [ 0.2788, -0.0782],\n",
            "        [-0.4066,  0.8994],\n",
            "        [ 0.5801, -0.4696],\n",
            "        [ 0.3161, -0.1259],\n",
            "        [ 0.0161,  0.4541],\n",
            "        [ 0.3775, -0.4239],\n",
            "        [-0.5202,  0.6890],\n",
            "        [ 0.2724,  0.1700],\n",
            "        [ 0.3702, -0.2375],\n",
            "        [-0.3619,  0.8163],\n",
            "        [-0.0222,  0.5107],\n",
            "        [ 0.4683, -0.4008],\n",
            "        [-1.1286,  1.4578],\n",
            "        [-0.1307,  0.6121],\n",
            "        [-0.5719,  1.0122],\n",
            "        [ 0.1270,  0.4167]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9163,  1.3423],\n",
            "        [-1.1456,  1.5233],\n",
            "        [-1.0083,  1.4488],\n",
            "        [ 0.1325,  0.0748],\n",
            "        [ 1.0218, -1.1876],\n",
            "        [ 0.9968, -1.0455],\n",
            "        [ 0.0155,  0.3047],\n",
            "        [-0.3529,  0.6191],\n",
            "        [ 1.1230, -1.3148],\n",
            "        [-0.1491,  0.4060],\n",
            "        [-1.0805,  1.4206],\n",
            "        [ 0.9535, -1.0792],\n",
            "        [-0.7741,  1.1752],\n",
            "        [-0.8485,  1.3226],\n",
            "        [ 0.2449,  0.1504],\n",
            "        [ 0.7321, -0.6862],\n",
            "        [-0.4169,  0.7372],\n",
            "        [-1.0985,  1.4970],\n",
            "        [-1.1600,  1.4944],\n",
            "        [-0.6134,  0.9498],\n",
            "        [-0.1169,  0.4836],\n",
            "        [-0.2182,  0.5644],\n",
            "        [ 0.8118, -0.8895],\n",
            "        [-1.0577,  1.4149],\n",
            "        [ 1.0682, -1.2784],\n",
            "        [-0.8128,  1.2512],\n",
            "        [-0.2862,  0.7959],\n",
            "        [-0.1122,  0.4041],\n",
            "        [-0.8194,  1.3256],\n",
            "        [ 0.7478, -0.7072],\n",
            "        [-1.1084,  1.5321],\n",
            "        [ 0.1985,  0.1168]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7939,  1.2199],\n",
            "        [-0.5598,  0.9124],\n",
            "        [-0.8773,  1.2444],\n",
            "        [ 0.7329, -0.9495],\n",
            "        [ 0.7181, -0.4730],\n",
            "        [-0.5396,  0.7858],\n",
            "        [-0.9668,  1.3762],\n",
            "        [ 0.2301,  0.0934],\n",
            "        [ 0.8798, -0.9242],\n",
            "        [ 0.0434,  0.2277],\n",
            "        [-0.1499,  0.3613],\n",
            "        [-0.5465,  0.8402],\n",
            "        [-0.1789,  0.6155],\n",
            "        [ 0.5956, -0.5008],\n",
            "        [-1.1416,  1.5074],\n",
            "        [-0.2024,  0.7066],\n",
            "        [-0.2778,  0.6070],\n",
            "        [-0.3707,  0.8102],\n",
            "        [ 0.3968, -0.2959],\n",
            "        [-0.9570,  1.3844],\n",
            "        [ 0.5384, -0.4056],\n",
            "        [-1.1025,  1.5228],\n",
            "        [-1.1739,  1.5663],\n",
            "        [-0.9276,  1.3288],\n",
            "        [ 0.0344,  0.4167],\n",
            "        [-0.4200,  0.7947],\n",
            "        [ 0.8588, -0.9397],\n",
            "        [ 0.7096, -0.6651],\n",
            "        [-0.1634,  0.5372],\n",
            "        [ 0.3194, -0.1924],\n",
            "        [-0.6571,  1.0921],\n",
            "        [-0.7406,  1.1553]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0281,  1.4817],\n",
            "        [ 0.6140, -0.4382],\n",
            "        [-0.5611,  0.8251],\n",
            "        [-0.4804,  0.7931],\n",
            "        [-1.0472,  1.4557],\n",
            "        [ 0.1625, -0.0343],\n",
            "        [-0.7396,  1.1740],\n",
            "        [-0.7150,  1.0397],\n",
            "        [-0.8109,  1.1793],\n",
            "        [ 0.8747, -0.9412],\n",
            "        [-0.3946,  0.7225],\n",
            "        [ 0.9325, -0.8970],\n",
            "        [-1.1443,  1.5113],\n",
            "        [-1.1775,  1.5861],\n",
            "        [-0.5350,  0.9787],\n",
            "        [-0.0618,  0.3713],\n",
            "        [-0.9347,  1.4160],\n",
            "        [-0.3271,  0.6336],\n",
            "        [ 0.6658, -0.6108],\n",
            "        [-0.0238,  0.3783],\n",
            "        [-0.9851,  1.3912],\n",
            "        [-0.5709,  0.9534],\n",
            "        [ 1.0997, -1.2760],\n",
            "        [-0.0056,  0.3452],\n",
            "        [-0.0310,  0.3360],\n",
            "        [-0.5899,  0.9601],\n",
            "        [ 0.3045, -0.1449],\n",
            "        [ 0.1224,  0.1017],\n",
            "        [-1.1094,  1.4622],\n",
            "        [ 1.1342, -1.3803],\n",
            "        [ 0.0722,  0.3288],\n",
            "        [-1.0557,  1.4577]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4594,  0.9670],\n",
            "        [-0.9757,  1.3446],\n",
            "        [-1.0880,  1.4524],\n",
            "        [ 0.9437, -1.0635],\n",
            "        [-0.7870,  1.1654],\n",
            "        [-0.2471,  0.5643],\n",
            "        [-1.0802,  1.4569],\n",
            "        [ 0.4138, -0.3396],\n",
            "        [ 0.0129,  0.4238],\n",
            "        [-0.2965,  0.7726],\n",
            "        [ 0.3004, -0.0034],\n",
            "        [ 0.4643, -0.1221],\n",
            "        [-1.1429,  1.4865],\n",
            "        [-1.1138,  1.4077],\n",
            "        [ 1.0412, -0.9763],\n",
            "        [-1.0817,  1.5296],\n",
            "        [ 0.5702, -0.3655],\n",
            "        [-0.3206,  0.7231],\n",
            "        [-0.9169,  1.3485],\n",
            "        [-1.0464,  1.4292],\n",
            "        [ 0.3044, -0.0840],\n",
            "        [ 0.0955,  0.2647],\n",
            "        [-0.0521,  0.4259],\n",
            "        [-0.5217,  1.0100],\n",
            "        [-0.2178,  0.5514],\n",
            "        [ 0.5400, -0.3464],\n",
            "        [ 0.5110, -0.4646],\n",
            "        [-0.7537,  1.0429],\n",
            "        [-0.1462,  0.5403],\n",
            "        [-1.1772,  1.5066],\n",
            "        [ 0.1548,  0.0515],\n",
            "        [ 0.3785,  0.0241]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.4312,  0.8117],\n",
            "        [-0.1646,  0.5253],\n",
            "        [-0.4897,  1.0006],\n",
            "        [-0.9567,  1.4195],\n",
            "        [ 0.3755, -0.3048],\n",
            "        [-0.2642,  0.6216],\n",
            "        [-0.8351,  1.1515],\n",
            "        [-0.9261,  1.2820],\n",
            "        [-0.4396,  0.6198],\n",
            "        [ 0.2172,  0.2142],\n",
            "        [ 0.4114, -0.1069],\n",
            "        [-0.3496,  0.5800],\n",
            "        [ 0.8849, -1.1064],\n",
            "        [-0.1727,  0.5585],\n",
            "        [-0.1894,  0.5890],\n",
            "        [ 0.6269, -0.6345],\n",
            "        [-0.2236,  0.6924],\n",
            "        [-0.9132,  1.2468],\n",
            "        [ 0.0900,  0.1217],\n",
            "        [-0.9988,  1.4558],\n",
            "        [ 0.7440, -0.7398],\n",
            "        [-0.1661,  0.6095],\n",
            "        [ 0.3923, -0.1034],\n",
            "        [-0.7204,  1.2227],\n",
            "        [-0.3991,  0.6189],\n",
            "        [-0.8122,  1.1342],\n",
            "        [-0.8580,  1.3261],\n",
            "        [-1.0874,  1.4979],\n",
            "        [-1.1538,  1.5287],\n",
            "        [ 0.8338, -0.8965],\n",
            "        [ 0.4381, -0.5624],\n",
            "        [ 0.3150, -0.0495]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0177,  0.2553],\n",
            "        [-1.1048,  1.4877],\n",
            "        [-0.2921,  0.6331],\n",
            "        [-1.2023,  1.5210],\n",
            "        [ 0.4053, -0.1135],\n",
            "        [ 0.1891,  0.1444],\n",
            "        [ 0.8517, -0.7151],\n",
            "        [-0.9660,  1.3267],\n",
            "        [-1.1614,  1.5043],\n",
            "        [-0.9018,  1.4168],\n",
            "        [-1.0081,  1.4064],\n",
            "        [ 0.2051,  0.0937],\n",
            "        [-1.1046,  1.4818],\n",
            "        [-0.9847,  1.4111],\n",
            "        [ 0.6158, -0.4596],\n",
            "        [-1.0078,  1.4155],\n",
            "        [-0.4532,  0.8366],\n",
            "        [-0.7844,  1.1295],\n",
            "        [ 0.5385, -0.3428],\n",
            "        [-0.3508,  0.9813],\n",
            "        [ 0.0165,  0.3711],\n",
            "        [-0.2404,  0.5871],\n",
            "        [ 0.8908, -0.9111],\n",
            "        [-0.0242,  0.4382],\n",
            "        [-0.0541,  0.1030],\n",
            "        [ 0.9336, -1.0179],\n",
            "        [-0.4618,  0.6711],\n",
            "        [-0.7701,  1.0751],\n",
            "        [ 0.7905, -0.6801],\n",
            "        [-0.4156,  0.8362],\n",
            "        [-0.6329,  1.0620],\n",
            "        [ 0.8702, -0.7561]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4270, -0.2568],\n",
            "        [-0.4057,  0.9663],\n",
            "        [-0.2293,  0.4888],\n",
            "        [-0.4520,  0.8893],\n",
            "        [-0.1597,  0.6465],\n",
            "        [-0.9065,  1.2902],\n",
            "        [-0.2778,  0.6801],\n",
            "        [-0.5203,  0.6994],\n",
            "        [ 0.0433,  0.3484],\n",
            "        [-0.5730,  0.8631],\n",
            "        [ 0.4164, -0.1506],\n",
            "        [-0.2274,  0.6216],\n",
            "        [ 0.2063,  0.0668],\n",
            "        [-0.5336,  0.8778],\n",
            "        [ 0.2692,  0.0354],\n",
            "        [-0.4067,  0.8559],\n",
            "        [-0.8548,  1.2413],\n",
            "        [-0.3061,  0.6537],\n",
            "        [ 0.8258, -0.8860],\n",
            "        [ 0.7176, -0.6354],\n",
            "        [-0.5900,  0.9750],\n",
            "        [ 0.1260,  0.2599],\n",
            "        [-0.6205,  0.9554],\n",
            "        [-0.8903,  1.3973],\n",
            "        [-0.2566,  0.5898],\n",
            "        [-0.2948,  0.5729],\n",
            "        [ 0.3805,  0.0242],\n",
            "        [-0.6017,  0.9734],\n",
            "        [ 0.3821, -0.1806],\n",
            "        [ 0.4910, -0.4276],\n",
            "        [ 0.3576, -0.2339],\n",
            "        [-0.6412,  1.0425]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.1256,  0.0581],\n",
            "        [ 0.3999, -0.0169],\n",
            "        [-0.0109,  0.3794],\n",
            "        [ 0.0875,  0.3217],\n",
            "        [-1.0780,  1.3376],\n",
            "        [-1.0656,  1.4848],\n",
            "        [ 0.7398, -0.7704],\n",
            "        [-0.3847,  0.6484],\n",
            "        [ 0.5617, -0.6448],\n",
            "        [-0.4791,  0.9687],\n",
            "        [ 0.2691, -0.0720],\n",
            "        [ 0.3747, -0.0843],\n",
            "        [-0.1634,  0.4820],\n",
            "        [-1.1550,  1.5088],\n",
            "        [-0.0220,  0.3731],\n",
            "        [ 0.1367,  0.2225],\n",
            "        [ 0.6378, -0.5222],\n",
            "        [-0.0574,  0.4465],\n",
            "        [ 0.7557, -0.7238],\n",
            "        [-0.7860,  1.2564],\n",
            "        [-0.1324,  0.6302],\n",
            "        [-0.6537,  1.1834],\n",
            "        [-1.0545,  1.5029],\n",
            "        [-0.8337,  1.2432],\n",
            "        [-0.8293,  1.2862],\n",
            "        [-0.1712,  0.6282],\n",
            "        [ 0.7032, -0.6567],\n",
            "        [-0.2298,  0.4487],\n",
            "        [ 0.7881, -0.5846],\n",
            "        [-0.6740,  1.2239],\n",
            "        [ 0.8201, -0.7427],\n",
            "        [-0.4277,  0.8918]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1735,  1.5308],\n",
            "        [ 0.9719, -1.0478],\n",
            "        [ 0.0058,  0.4186],\n",
            "        [-0.8486,  1.2294],\n",
            "        [ 0.7692, -0.7286],\n",
            "        [ 0.4047, -0.2925],\n",
            "        [ 1.0100, -0.9678],\n",
            "        [-1.1168,  1.4587],\n",
            "        [ 0.8480, -0.8210],\n",
            "        [-0.0078,  0.2778],\n",
            "        [-0.3104,  0.4436],\n",
            "        [-1.0720,  1.4418],\n",
            "        [ 0.8483, -0.8219],\n",
            "        [-0.0861,  0.5434],\n",
            "        [-0.5399,  0.7953],\n",
            "        [-0.4336,  0.7795]], device='cuda:0')\n",
            "  Accuracy: 0.64\n",
            "  Development Loss: 0.68\n",
            "  Development took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ======== \n",
            "Training...\n",
            "current time:  19877 days, 12:15:47\n",
            "  Batch    40  of    497.    Elapsed: 0:00:08.\n",
            "current time:  19877 days, 12:15:56\n",
            "  Batch    80  of    497.    Elapsed: 0:00:17.\n",
            "current time:  19877 days, 12:16:04\n",
            "  Batch   120  of    497.    Elapsed: 0:00:26.\n",
            "current time:  19877 days, 12:16:13\n",
            "  Batch   160  of    497.    Elapsed: 0:00:34.\n",
            "current time:  19877 days, 12:16:21\n",
            "  Batch   200  of    497.    Elapsed: 0:00:43.\n",
            "current time:  19877 days, 12:16:30\n",
            "  Batch   240  of    497.    Elapsed: 0:00:51.\n",
            "current time:  19877 days, 12:16:38\n",
            "  Batch   280  of    497.    Elapsed: 0:01:00.\n",
            "current time:  19877 days, 12:16:47\n",
            "  Batch   320  of    497.    Elapsed: 0:01:08.\n",
            "current time:  19877 days, 12:16:55\n",
            "  Batch   360  of    497.    Elapsed: 0:01:17.\n",
            "current time:  19877 days, 12:17:04\n",
            "  Batch   400  of    497.    Elapsed: 0:01:25.\n",
            "current time:  19877 days, 12:17:12\n",
            "  Batch   440  of    497.    Elapsed: 0:01:34.\n",
            "current time:  19877 days, 12:17:21\n",
            "  Batch   480  of    497.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epoch took: 0:01:46\n",
            "\n",
            "Running Development...\n",
            "dev_logits:  tensor([[ 0.9454, -1.0096],\n",
            "        [-0.4562,  0.7154],\n",
            "        [ 0.2492,  0.0095],\n",
            "        [-1.1929,  1.5920],\n",
            "        [-0.4510,  0.7515],\n",
            "        [ 0.6488, -0.5935],\n",
            "        [-0.0444,  0.4551],\n",
            "        [ 0.0238,  0.2065],\n",
            "        [-0.5228,  0.8748],\n",
            "        [-1.0601,  1.4200],\n",
            "        [-0.8896,  1.2061],\n",
            "        [-0.8636,  1.2133],\n",
            "        [-0.5047,  0.7382],\n",
            "        [-0.5724,  0.8145],\n",
            "        [-1.0132,  1.4462],\n",
            "        [-0.1918,  0.4597],\n",
            "        [-0.5293,  0.6796],\n",
            "        [-0.8370,  1.2198],\n",
            "        [ 0.2474, -0.2516],\n",
            "        [-0.4066,  0.7528],\n",
            "        [ 0.2078,  0.1620],\n",
            "        [-1.2316,  1.5782],\n",
            "        [ 1.0129, -1.3251],\n",
            "        [-1.1030,  1.4850],\n",
            "        [ 0.2336,  0.0114],\n",
            "        [-1.0454,  1.4054],\n",
            "        [ 0.5034, -0.2995],\n",
            "        [ 0.7410, -0.7998],\n",
            "        [ 0.5654, -0.5567],\n",
            "        [ 0.0714,  0.0856],\n",
            "        [ 0.9329, -1.1573],\n",
            "        [-0.7210,  1.0617]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1128,  1.5099],\n",
            "        [-1.0523,  1.4078],\n",
            "        [-1.2038,  1.5413],\n",
            "        [ 0.9161, -1.0875],\n",
            "        [ 0.4221, -0.5064],\n",
            "        [-0.1419,  0.2987],\n",
            "        [-1.2184,  1.5819],\n",
            "        [ 1.0643, -1.1480],\n",
            "        [-0.0537,  0.4412],\n",
            "        [-0.9231,  1.3888],\n",
            "        [-1.1246,  1.4876],\n",
            "        [ 0.1140,  0.1466],\n",
            "        [-1.1704,  1.5420],\n",
            "        [ 1.1624, -1.3490],\n",
            "        [-0.2668,  0.4768],\n",
            "        [ 0.6597, -0.4163],\n",
            "        [-1.2539,  1.5908],\n",
            "        [-1.2712,  1.6190],\n",
            "        [-0.0572,  0.3605],\n",
            "        [ 0.1165,  0.2742],\n",
            "        [ 1.1995, -1.3949],\n",
            "        [-0.8744,  1.3000],\n",
            "        [-1.2219,  1.5669],\n",
            "        [-0.6587,  0.8185],\n",
            "        [ 0.0768,  0.0464],\n",
            "        [-0.1912,  0.4950],\n",
            "        [-0.8543,  1.0647],\n",
            "        [ 0.8672, -0.9681],\n",
            "        [-0.9215,  1.3597],\n",
            "        [ 0.9655, -1.0822],\n",
            "        [ 0.0075,  0.4018],\n",
            "        [-0.1999,  0.0947]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0593,  0.3313],\n",
            "        [-0.8715,  1.2707],\n",
            "        [-0.2712,  0.6910],\n",
            "        [-0.6326,  1.1537],\n",
            "        [ 0.9000, -0.9709],\n",
            "        [-1.0533,  1.4303],\n",
            "        [ 0.6856, -0.6479],\n",
            "        [ 0.2149, -0.1898],\n",
            "        [-0.7310,  1.1155],\n",
            "        [ 0.3585, -0.1903],\n",
            "        [ 0.1132,  0.2294],\n",
            "        [-1.0962,  1.4101],\n",
            "        [-0.1942,  0.5616],\n",
            "        [ 0.3231, -0.2715],\n",
            "        [ 0.5843, -0.5748],\n",
            "        [ 0.8987, -1.0514],\n",
            "        [ 0.6122, -0.4004],\n",
            "        [-0.9206,  1.3886],\n",
            "        [ 0.4540, -0.3291],\n",
            "        [ 0.2060,  0.0776],\n",
            "        [-0.9049,  1.3483],\n",
            "        [ 1.1550, -1.5343],\n",
            "        [-1.1969,  1.5274],\n",
            "        [-1.2889,  1.6091],\n",
            "        [ 0.3801, -0.2043],\n",
            "        [ 0.5718, -0.6353],\n",
            "        [ 0.6342, -0.5460],\n",
            "        [-0.3226,  0.5427],\n",
            "        [ 1.2815, -1.5478],\n",
            "        [ 1.1723, -1.3696],\n",
            "        [ 0.3438, -0.3599],\n",
            "        [ 0.5836, -0.4513]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0603,  0.1393],\n",
            "        [-0.5376,  0.7881],\n",
            "        [-1.1763,  1.5841],\n",
            "        [-0.0330,  0.0311],\n",
            "        [-1.2125,  1.5951],\n",
            "        [-1.0983,  1.3719],\n",
            "        [-0.1243,  0.5004],\n",
            "        [-0.8747,  1.2333],\n",
            "        [-0.8790,  1.1623],\n",
            "        [-0.3308,  0.7361],\n",
            "        [-0.4556,  0.8245],\n",
            "        [-0.3717,  0.6143],\n",
            "        [-0.5773,  0.9001],\n",
            "        [-0.1942,  0.6296],\n",
            "        [ 0.5181, -0.5027],\n",
            "        [ 0.4679, -0.3197],\n",
            "        [ 1.2119, -1.4576],\n",
            "        [-0.4268,  0.9199],\n",
            "        [-0.5420,  0.9097],\n",
            "        [-0.5380,  0.6385],\n",
            "        [-0.7204,  1.0216],\n",
            "        [-1.2192,  1.5046],\n",
            "        [ 0.0098,  0.3178],\n",
            "        [ 0.6554, -0.4126],\n",
            "        [-0.0285,  0.0993],\n",
            "        [ 1.0509, -1.1092],\n",
            "        [-0.6892,  0.9079],\n",
            "        [-0.8506,  1.1461],\n",
            "        [-1.0038,  1.4693],\n",
            "        [-1.2252,  1.5845],\n",
            "        [-0.7959,  1.2560],\n",
            "        [-0.4981,  0.5294]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1997,  1.5820],\n",
            "        [ 1.2664, -1.4342],\n",
            "        [-0.0774,  0.4855],\n",
            "        [ 1.1225, -1.3929],\n",
            "        [-1.2734,  1.5771],\n",
            "        [-0.9038,  1.2120],\n",
            "        [-0.5881,  0.8434],\n",
            "        [-1.1628,  1.5358],\n",
            "        [ 0.6336, -0.7146],\n",
            "        [-0.5937,  0.8997],\n",
            "        [-0.2356,  0.4517],\n",
            "        [-0.3116,  0.7623],\n",
            "        [-0.9427,  1.1603],\n",
            "        [-0.2907,  0.5449],\n",
            "        [ 0.4542, -0.3068],\n",
            "        [ 0.1723,  0.0955],\n",
            "        [-1.1620,  1.5321],\n",
            "        [-1.2684,  1.5383],\n",
            "        [-0.4805,  0.8817],\n",
            "        [-0.5667,  0.9544],\n",
            "        [ 1.0209, -1.1714],\n",
            "        [-0.0375,  0.4170],\n",
            "        [ 0.5269, -0.5793],\n",
            "        [ 0.8108, -0.8328],\n",
            "        [-0.2811,  0.7748],\n",
            "        [-0.8077,  1.1113],\n",
            "        [-0.2369,  0.6234],\n",
            "        [-1.0761,  1.4573],\n",
            "        [ 0.3401, -0.0957],\n",
            "        [-1.0492,  1.4594],\n",
            "        [-1.2362,  1.5659],\n",
            "        [ 0.4337, -0.2323]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.2864,  1.6058],\n",
            "        [-1.1034,  1.4687],\n",
            "        [-1.1924,  1.4779],\n",
            "        [-0.9281,  1.4592],\n",
            "        [ 0.6856, -0.5135],\n",
            "        [-1.1921,  1.5643],\n",
            "        [ 0.3875, -0.0754],\n",
            "        [ 1.0255, -1.1419],\n",
            "        [-0.4498,  0.9322],\n",
            "        [-1.2090,  1.5591],\n",
            "        [-1.1943,  1.5340],\n",
            "        [-0.5053,  0.7883],\n",
            "        [ 0.2589,  0.1158],\n",
            "        [ 0.6596, -0.7807],\n",
            "        [ 0.4742, -0.3585],\n",
            "        [ 1.0068, -1.2132],\n",
            "        [-0.2070,  0.3248],\n",
            "        [-1.1652,  1.4601],\n",
            "        [ 1.1797, -1.3933],\n",
            "        [ 1.0332, -1.2024],\n",
            "        [-1.1393,  1.4947],\n",
            "        [-0.2346,  0.4842],\n",
            "        [-1.2537,  1.5946],\n",
            "        [-0.3011,  0.6362],\n",
            "        [-1.1026,  1.4174],\n",
            "        [ 0.9043, -1.0123],\n",
            "        [-0.2604,  0.5290],\n",
            "        [ 0.2977,  0.0419],\n",
            "        [ 0.7612, -0.8820],\n",
            "        [-0.3888,  0.6166],\n",
            "        [-1.1723,  1.5700],\n",
            "        [-1.0854,  1.5465]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.2417,  1.5853],\n",
            "        [ 0.2614,  0.1229],\n",
            "        [-1.1975,  1.6156],\n",
            "        [ 0.1462,  0.1473],\n",
            "        [ 0.8309, -0.7662],\n",
            "        [-0.6053,  0.9246],\n",
            "        [ 0.4252, -0.3539],\n",
            "        [ 0.5699, -0.3000],\n",
            "        [-0.8706,  1.3682],\n",
            "        [-1.2443,  1.5225],\n",
            "        [-1.2165,  1.5572],\n",
            "        [ 0.9855, -0.9760],\n",
            "        [-1.2031,  1.4749],\n",
            "        [-0.7645,  1.0581],\n",
            "        [ 1.1633, -1.3918],\n",
            "        [-0.0797,  0.2679],\n",
            "        [-0.7483,  1.0527],\n",
            "        [-1.2504,  1.5600],\n",
            "        [-1.1997,  1.6058],\n",
            "        [ 0.7512, -0.7597],\n",
            "        [-1.1181,  1.5073],\n",
            "        [-0.1385,  0.3542],\n",
            "        [ 1.3135, -1.6125],\n",
            "        [-0.4846,  0.5034],\n",
            "        [ 0.8107, -0.7589],\n",
            "        [-0.7731,  1.2123],\n",
            "        [ 0.3219, -0.4014],\n",
            "        [-1.0261,  1.4072],\n",
            "        [-1.2171,  1.5757],\n",
            "        [ 0.7009, -0.7942],\n",
            "        [-1.1084,  1.4199],\n",
            "        [ 0.9424, -1.0219]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.3246,  0.5530],\n",
            "        [-0.0271,  0.4619],\n",
            "        [-0.5118,  0.7515],\n",
            "        [-0.3570,  0.8596],\n",
            "        [ 0.9205, -1.0102],\n",
            "        [-1.0778,  1.4751],\n",
            "        [ 0.8677, -0.8643],\n",
            "        [-0.6127,  0.9294],\n",
            "        [-0.0849,  0.2467],\n",
            "        [ 0.6301, -0.6088],\n",
            "        [-1.0479,  1.3894],\n",
            "        [ 0.2323,  0.0628],\n",
            "        [-1.0651,  1.4493],\n",
            "        [ 0.6240, -0.6200],\n",
            "        [ 1.1916, -1.4792],\n",
            "        [-1.2810,  1.6171],\n",
            "        [-0.8779,  1.2870],\n",
            "        [-0.3707,  0.6392],\n",
            "        [ 0.3463,  0.0241],\n",
            "        [-1.1143,  1.5479],\n",
            "        [-1.2170,  1.5109],\n",
            "        [-1.0188,  1.4404],\n",
            "        [ 0.6847, -0.6566],\n",
            "        [ 0.7877, -0.7863],\n",
            "        [ 0.9932, -1.0918],\n",
            "        [-1.0996,  1.4637],\n",
            "        [ 0.4660, -0.3050],\n",
            "        [-1.1795,  1.5548],\n",
            "        [-1.1811,  1.5753],\n",
            "        [ 0.2294,  0.1388],\n",
            "        [ 1.1333, -1.2307],\n",
            "        [-1.0923,  1.4086]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7927,  1.2216],\n",
            "        [ 0.1171, -0.0143],\n",
            "        [ 0.9046, -1.0025],\n",
            "        [-1.2271,  1.6213],\n",
            "        [-1.1310,  1.5690],\n",
            "        [-0.2652,  0.5487],\n",
            "        [ 1.1696, -1.2670],\n",
            "        [-0.4626,  0.8446],\n",
            "        [-0.8750,  1.3653],\n",
            "        [ 0.6246, -0.4363],\n",
            "        [ 0.9927, -1.1173],\n",
            "        [-0.3639,  0.8513],\n",
            "        [ 0.5757, -0.2975],\n",
            "        [-1.1575,  1.5669],\n",
            "        [-0.9914,  1.2941],\n",
            "        [-1.2700,  1.6387],\n",
            "        [-0.1637,  0.6201],\n",
            "        [-0.4962,  0.8873],\n",
            "        [-1.2287,  1.6318],\n",
            "        [-0.4342,  0.6415],\n",
            "        [ 0.0287,  0.2881],\n",
            "        [-0.4335,  0.7531],\n",
            "        [-1.1718,  1.5140],\n",
            "        [-0.0429,  0.3926],\n",
            "        [-0.6363,  0.8941],\n",
            "        [ 0.9571, -1.1729],\n",
            "        [ 1.1010, -1.3689],\n",
            "        [-1.0573,  1.3862],\n",
            "        [-0.2462,  0.6269],\n",
            "        [-1.1655,  1.4148],\n",
            "        [-0.8584,  1.1814],\n",
            "        [-0.9638,  1.3281]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6961,  1.0317],\n",
            "        [-0.7029,  0.9953],\n",
            "        [ 0.0174,  0.3524],\n",
            "        [ 1.0553, -1.2979],\n",
            "        [-1.1852,  1.5414],\n",
            "        [ 0.9762, -1.1639],\n",
            "        [-0.9203,  1.3527],\n",
            "        [-0.7583,  0.9557],\n",
            "        [-0.1821,  0.6497],\n",
            "        [ 1.2583, -1.4069],\n",
            "        [ 1.4013, -1.6202],\n",
            "        [-0.3596,  0.4659],\n",
            "        [-0.3236,  0.8239],\n",
            "        [-1.1169,  1.4980],\n",
            "        [ 0.1622,  0.2281],\n",
            "        [-0.5682,  0.9291],\n",
            "        [-1.0402,  1.3761],\n",
            "        [-0.9310,  1.1228],\n",
            "        [-0.7571,  1.2152],\n",
            "        [-1.2343,  1.6404],\n",
            "        [-0.3664,  0.7561],\n",
            "        [ 0.3651, -0.2876],\n",
            "        [-0.7106,  1.0382],\n",
            "        [-0.5421,  0.7526],\n",
            "        [ 0.6718, -0.7577],\n",
            "        [ 0.4185, -0.0633],\n",
            "        [-0.2410,  0.4456],\n",
            "        [-1.1086,  1.4441],\n",
            "        [-1.2405,  1.6361],\n",
            "        [ 0.3879, -0.3520],\n",
            "        [-0.1580,  0.5545],\n",
            "        [ 1.1024, -1.2091]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.2575,  1.5638],\n",
            "        [-0.5808,  0.8553],\n",
            "        [-1.0642,  1.4076],\n",
            "        [ 1.1124, -1.2245],\n",
            "        [-0.3401,  0.6784],\n",
            "        [ 0.1361,  0.1631],\n",
            "        [ 0.4031,  0.0175],\n",
            "        [-0.8553,  1.1805],\n",
            "        [-1.2528,  1.5712],\n",
            "        [-1.1903,  1.4509],\n",
            "        [ 0.5674, -0.3605],\n",
            "        [ 0.3790, -0.1924],\n",
            "        [-0.9011,  1.2375],\n",
            "        [ 0.3901, -0.1899],\n",
            "        [-1.0119,  1.3452],\n",
            "        [-0.3663,  0.4970],\n",
            "        [ 0.7464, -0.8076],\n",
            "        [-0.9673,  1.3126],\n",
            "        [-0.3555,  0.7651],\n",
            "        [-0.5560,  0.6862],\n",
            "        [-0.7168,  0.9422],\n",
            "        [-0.9016,  1.2182],\n",
            "        [-1.3469,  1.6698],\n",
            "        [-1.0822,  1.5048],\n",
            "        [ 0.2980, -0.1595],\n",
            "        [ 0.8163, -0.9904],\n",
            "        [-0.5566,  1.0525],\n",
            "        [ 0.2439, -0.0527],\n",
            "        [-1.1176,  1.4644],\n",
            "        [ 0.7617, -0.5581],\n",
            "        [-1.0809,  1.3635],\n",
            "        [-0.2112,  0.4286]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1994,  1.5062],\n",
            "        [-0.7513,  1.1959],\n",
            "        [-0.7504,  0.8705],\n",
            "        [-1.2292,  1.5636],\n",
            "        [-0.3987,  0.5329],\n",
            "        [-0.1233,  0.5311],\n",
            "        [ 0.0042,  0.3517],\n",
            "        [-1.0489,  1.4458],\n",
            "        [-1.0823,  1.4462],\n",
            "        [ 0.1493,  0.0347],\n",
            "        [-0.9559,  1.4113],\n",
            "        [ 0.8765, -1.1129],\n",
            "        [ 0.4443, -0.3492],\n",
            "        [ 0.9946, -1.1798],\n",
            "        [-0.4991,  0.8733],\n",
            "        [ 1.2492, -1.4917],\n",
            "        [-0.0157,  0.2497],\n",
            "        [-1.1360,  1.5669],\n",
            "        [-0.9410,  1.2371],\n",
            "        [ 0.7362, -0.6489],\n",
            "        [-0.1287,  0.3835],\n",
            "        [-1.0518,  1.4553],\n",
            "        [-0.0543,  0.0095],\n",
            "        [-0.4663,  0.7907],\n",
            "        [ 0.3114, -0.1056],\n",
            "        [ 1.0275, -1.0963],\n",
            "        [-0.7860,  1.0842],\n",
            "        [ 0.2880,  0.1168],\n",
            "        [ 1.0035, -1.0686],\n",
            "        [-1.1548,  1.5369],\n",
            "        [-1.0192,  1.4537],\n",
            "        [-0.1933,  0.6113]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6078,  1.1764],\n",
            "        [-1.0577,  1.4482],\n",
            "        [ 1.2365, -1.4120],\n",
            "        [-1.0066,  1.3579],\n",
            "        [ 0.1172,  0.1322],\n",
            "        [-0.3151,  0.8043],\n",
            "        [-1.1684,  1.5653],\n",
            "        [ 1.1781, -1.4718],\n",
            "        [ 0.7728, -0.9469],\n",
            "        [-0.1057,  0.5707],\n",
            "        [-1.1413,  1.5237],\n",
            "        [-1.2146,  1.5824],\n",
            "        [ 1.1579, -1.2628],\n",
            "        [-0.6348,  0.9095],\n",
            "        [-1.0780,  1.4762],\n",
            "        [ 0.7956, -0.9559],\n",
            "        [ 0.8032, -0.7720],\n",
            "        [ 0.3969, -0.2521],\n",
            "        [ 0.6514, -0.4837],\n",
            "        [-0.8005,  1.1409],\n",
            "        [-1.2478,  1.6094],\n",
            "        [-1.1985,  1.5318],\n",
            "        [-0.5980,  1.0046],\n",
            "        [-0.8507,  1.3300],\n",
            "        [-0.9407,  1.3065],\n",
            "        [-0.5029,  0.8360],\n",
            "        [-0.4026,  0.8878],\n",
            "        [-0.4479,  0.8530],\n",
            "        [-1.2500,  1.6209],\n",
            "        [-0.3580,  0.4798],\n",
            "        [-1.1768,  1.5728],\n",
            "        [-0.9487,  1.1572]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7411,  1.0710],\n",
            "        [-0.4172,  0.6892],\n",
            "        [ 1.0388, -1.2073],\n",
            "        [-0.7242,  0.9786],\n",
            "        [-0.6362,  0.6834],\n",
            "        [-0.1758,  0.5908],\n",
            "        [-1.1527,  1.4138],\n",
            "        [-0.7033,  1.0066],\n",
            "        [-1.0828,  1.4942],\n",
            "        [-0.0282,  0.2480],\n",
            "        [-0.2530,  0.4179],\n",
            "        [-0.5143,  0.8440],\n",
            "        [-0.6294,  1.0195],\n",
            "        [-0.4167,  0.6931],\n",
            "        [-0.6194,  1.0317],\n",
            "        [-1.0564,  1.3520],\n",
            "        [ 0.9628, -1.0541],\n",
            "        [-0.1474,  0.4541],\n",
            "        [-1.2813,  1.6063],\n",
            "        [-1.1255,  1.4652],\n",
            "        [-1.1220,  1.4014],\n",
            "        [ 0.5627, -0.3503],\n",
            "        [-0.5048,  0.8532],\n",
            "        [-0.9135,  1.1087],\n",
            "        [-0.5634,  0.8183],\n",
            "        [-0.7328,  1.1630],\n",
            "        [ 0.6356, -0.8568],\n",
            "        [ 0.8412, -0.9315],\n",
            "        [ 0.8563, -1.0468],\n",
            "        [-1.2125,  1.6196],\n",
            "        [ 0.0916,  0.2294],\n",
            "        [ 1.1575, -1.2624]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0152,  1.3637],\n",
            "        [-0.2768,  0.7240],\n",
            "        [-0.5460,  0.7430],\n",
            "        [-1.0992,  1.4588],\n",
            "        [ 0.2868, -0.0212],\n",
            "        [ 0.6501, -0.7090],\n",
            "        [-0.5137,  1.0114],\n",
            "        [ 0.8339, -0.9113],\n",
            "        [-0.2490,  0.5102],\n",
            "        [-1.0523,  1.4143],\n",
            "        [-0.8575,  1.3088],\n",
            "        [-0.5804,  0.9593],\n",
            "        [-0.9761,  1.4314],\n",
            "        [ 0.0483, -0.1466],\n",
            "        [ 0.2743, -0.2929],\n",
            "        [ 0.4964, -0.5357],\n",
            "        [-0.4018,  0.8381],\n",
            "        [ 1.0613, -1.2647],\n",
            "        [ 0.5329, -0.3783],\n",
            "        [ 0.5828, -0.5217],\n",
            "        [ 0.1788,  0.2270],\n",
            "        [ 0.6651, -0.6930],\n",
            "        [ 0.2365, -0.0329],\n",
            "        [-0.7647,  1.0749],\n",
            "        [-0.1359,  0.5167],\n",
            "        [ 0.1872,  0.1352],\n",
            "        [-1.0650,  1.4120],\n",
            "        [-1.1561,  1.5046],\n",
            "        [-0.6797,  1.0723],\n",
            "        [ 1.0845, -1.2600],\n",
            "        [-0.5060,  0.7219],\n",
            "        [-0.4533,  0.7571]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0272,  0.2360],\n",
            "        [-1.1469,  1.4970],\n",
            "        [-0.2615,  0.6685],\n",
            "        [ 1.0855, -1.1965],\n",
            "        [-1.0405,  1.3164],\n",
            "        [-1.0213,  1.3146],\n",
            "        [-0.3778,  0.7200],\n",
            "        [-0.3950,  0.7872],\n",
            "        [ 0.4838, -0.4351],\n",
            "        [ 0.2158,  0.1788],\n",
            "        [-1.2384,  1.5946],\n",
            "        [-0.6934,  1.0747],\n",
            "        [-1.2648,  1.6018],\n",
            "        [ 1.0356, -0.9763],\n",
            "        [ 1.3374, -1.5656],\n",
            "        [-0.6290,  0.9693],\n",
            "        [-0.0157, -0.0239],\n",
            "        [-0.3443,  0.6101],\n",
            "        [-0.1594,  0.3952],\n",
            "        [ 0.2395, -0.1303],\n",
            "        [-1.2940,  1.6485],\n",
            "        [ 0.8875, -0.7955],\n",
            "        [ 1.0389, -1.2187],\n",
            "        [-0.8804,  1.1074],\n",
            "        [-1.0629,  1.4255],\n",
            "        [-0.3770,  0.7088],\n",
            "        [ 0.3250, -0.0876],\n",
            "        [-0.8459,  1.3177],\n",
            "        [ 0.6227, -0.6057],\n",
            "        [-0.7194,  1.0960],\n",
            "        [-0.3962,  0.7861],\n",
            "        [-0.3217,  0.6564]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.5841,  1.0434],\n",
            "        [-1.1253,  1.3977],\n",
            "        [ 1.0867, -1.2399],\n",
            "        [-1.2461,  1.5513],\n",
            "        [ 0.0715, -0.2465],\n",
            "        [-0.3503,  0.4850],\n",
            "        [-0.9915,  1.3525],\n",
            "        [-0.6532,  0.9874],\n",
            "        [-1.0860,  1.4397],\n",
            "        [ 0.0097, -0.0380],\n",
            "        [-0.4263,  0.8248],\n",
            "        [ 0.0594,  0.2707],\n",
            "        [-0.9814,  1.3414],\n",
            "        [-0.5517,  1.0283],\n",
            "        [-0.5175,  0.6989],\n",
            "        [-0.0958,  0.6004],\n",
            "        [ 0.6330, -0.4959],\n",
            "        [-0.9482,  1.3741],\n",
            "        [ 0.2835, -0.0395],\n",
            "        [ 0.2413,  0.1341],\n",
            "        [-0.8619,  1.0759],\n",
            "        [ 1.1263, -1.2983],\n",
            "        [-1.2341,  1.5992],\n",
            "        [-0.9475,  1.3160],\n",
            "        [-0.0609,  0.4623],\n",
            "        [-0.9028,  1.4030],\n",
            "        [ 0.0668, -0.1524],\n",
            "        [-0.7129,  1.0942],\n",
            "        [-0.1570,  0.3420],\n",
            "        [-0.5362,  0.7390],\n",
            "        [-1.2716,  1.5876],\n",
            "        [-0.7790,  1.1490]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0269,  1.4961],\n",
            "        [-1.0022,  1.3966],\n",
            "        [ 0.6179, -0.6220],\n",
            "        [ 0.7216, -0.8060],\n",
            "        [ 0.7236, -0.9146],\n",
            "        [-0.6138,  0.7640],\n",
            "        [-0.7933,  1.0508],\n",
            "        [ 0.9877, -1.0549],\n",
            "        [-0.7254,  1.1631],\n",
            "        [-1.2887,  1.6445],\n",
            "        [-0.9291,  1.2131],\n",
            "        [ 0.7393, -0.5937],\n",
            "        [-0.2683,  0.7703],\n",
            "        [ 0.5842, -0.5019],\n",
            "        [-0.0452,  0.3952],\n",
            "        [ 0.8657, -1.0521],\n",
            "        [-1.2487,  1.5616],\n",
            "        [-1.2743,  1.5829],\n",
            "        [-1.0979,  1.5390],\n",
            "        [-1.0030,  1.2994],\n",
            "        [-1.0398,  1.4554],\n",
            "        [-1.2907,  1.6241],\n",
            "        [-0.6619,  1.0214],\n",
            "        [ 0.7619, -0.6575],\n",
            "        [ 0.0100,  0.1563],\n",
            "        [-0.6934,  0.8861],\n",
            "        [ 1.1638, -1.5327],\n",
            "        [-0.2544,  0.7260],\n",
            "        [-0.6710,  1.1081],\n",
            "        [ 1.2208, -1.5578],\n",
            "        [ 0.7482, -0.8226],\n",
            "        [ 0.5326, -0.3686]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6209,  0.9213],\n",
            "        [-0.6705,  1.1573],\n",
            "        [-1.1403,  1.5293],\n",
            "        [-0.8515,  1.2280],\n",
            "        [ 0.0323,  0.2477],\n",
            "        [-0.2079,  0.5672],\n",
            "        [ 0.0318,  0.2781],\n",
            "        [-0.4349,  0.7192],\n",
            "        [-1.1462,  1.5584],\n",
            "        [ 0.1020,  0.1999],\n",
            "        [ 0.5051, -0.3448],\n",
            "        [-0.2796,  0.5487],\n",
            "        [ 0.0252,  0.2737],\n",
            "        [ 0.4325, -0.1585],\n",
            "        [-0.3168,  0.5939],\n",
            "        [ 0.2057, -0.2655],\n",
            "        [-0.5678,  0.7839],\n",
            "        [ 0.4054, -0.2987],\n",
            "        [-0.0063,  0.1426],\n",
            "        [ 0.9054, -1.1388],\n",
            "        [-0.3970,  0.6331],\n",
            "        [-0.4121,  0.7496],\n",
            "        [-0.2537,  0.6344],\n",
            "        [-1.1903,  1.5217],\n",
            "        [-0.3861,  0.6077],\n",
            "        [ 0.8548, -0.9551],\n",
            "        [ 0.8333, -0.9340],\n",
            "        [-0.2677,  0.6004],\n",
            "        [-0.2011,  0.6282],\n",
            "        [-1.0941,  1.4803],\n",
            "        [-1.1730,  1.4978],\n",
            "        [ 1.0731, -1.2337]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.8974,  1.2449],\n",
            "        [-0.6428,  0.9797],\n",
            "        [-0.1891,  0.4748],\n",
            "        [-1.0966,  1.4800],\n",
            "        [-0.9456,  1.2598],\n",
            "        [-0.8881,  1.2646],\n",
            "        [-0.8600,  1.0841],\n",
            "        [ 0.4578, -0.2701],\n",
            "        [-0.0604,  0.2898],\n",
            "        [-0.5031,  0.9135],\n",
            "        [ 0.3930, -0.2944],\n",
            "        [-1.0267,  1.3666],\n",
            "        [ 0.8323, -0.9650],\n",
            "        [ 0.7021, -0.9712],\n",
            "        [-0.6680,  0.9253],\n",
            "        [-1.2508,  1.6011],\n",
            "        [-0.6048,  0.7753],\n",
            "        [ 0.7434, -0.8016],\n",
            "        [-0.9170,  1.1987],\n",
            "        [-0.8826,  1.3419],\n",
            "        [-1.2947,  1.6641],\n",
            "        [-0.9144,  1.0828],\n",
            "        [-1.2897,  1.6723],\n",
            "        [-0.4352,  0.7327],\n",
            "        [-1.1298,  1.4572],\n",
            "        [ 0.2592, -0.0702],\n",
            "        [ 0.5800, -0.7507],\n",
            "        [-0.2847,  0.7551],\n",
            "        [-0.0279,  0.5163],\n",
            "        [-0.1147,  0.4128],\n",
            "        [ 0.6489, -0.8004],\n",
            "        [ 0.0329,  0.3659]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.7625, -0.6531],\n",
            "        [-0.4305,  0.9345],\n",
            "        [-1.2276,  1.5525],\n",
            "        [-0.9914,  1.3017],\n",
            "        [-0.4946,  0.8320],\n",
            "        [-0.2162,  0.6373],\n",
            "        [-1.2138,  1.5707],\n",
            "        [-1.1221,  1.4974],\n",
            "        [ 1.2100, -1.4095],\n",
            "        [-1.1908,  1.5255],\n",
            "        [-0.4231,  0.9017],\n",
            "        [ 0.1202,  0.0137],\n",
            "        [-0.0837,  0.2928],\n",
            "        [ 0.5413, -0.5037],\n",
            "        [-0.2253,  0.6756],\n",
            "        [ 0.4434, -0.2987],\n",
            "        [-1.1728,  1.5231],\n",
            "        [-0.2850,  0.6066],\n",
            "        [ 1.1253, -1.3554],\n",
            "        [ 0.6584, -0.7008],\n",
            "        [-1.1244,  1.5442],\n",
            "        [-1.2459,  1.6027],\n",
            "        [-1.0872,  1.3967],\n",
            "        [ 0.3998, -0.0408],\n",
            "        [-1.0323,  1.4790],\n",
            "        [-1.0393,  1.4349],\n",
            "        [-0.2827,  0.5032],\n",
            "        [ 1.1363, -1.3490],\n",
            "        [-0.2684,  0.7161],\n",
            "        [-1.0214,  1.3542],\n",
            "        [ 1.0727, -1.1310],\n",
            "        [-0.7583,  1.2278]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.1832, -0.2200],\n",
            "        [ 1.1882, -1.3283],\n",
            "        [-0.5004,  0.9608],\n",
            "        [-1.0356,  1.3615],\n",
            "        [ 0.2921, -0.2215],\n",
            "        [-0.8705,  1.1739],\n",
            "        [-0.9654,  1.2751],\n",
            "        [-0.8450,  1.2439],\n",
            "        [ 0.2950, -0.1557],\n",
            "        [-0.9622,  1.2971],\n",
            "        [ 1.1982, -1.3520],\n",
            "        [-0.7501,  1.0757],\n",
            "        [-0.5259,  0.7506],\n",
            "        [-1.2508,  1.5918],\n",
            "        [ 0.0336,  0.0922],\n",
            "        [-0.8284,  1.2298],\n",
            "        [ 0.8861, -0.8512],\n",
            "        [-0.0334,  0.1727],\n",
            "        [-0.0250,  0.4623],\n",
            "        [-0.1334,  0.2956],\n",
            "        [-0.9302,  1.3153],\n",
            "        [ 0.4380, -0.2959],\n",
            "        [ 0.0666,  0.1417],\n",
            "        [-1.2868,  1.5893],\n",
            "        [-0.8467,  1.1594],\n",
            "        [-1.1325,  1.5061],\n",
            "        [-0.6573,  0.7479],\n",
            "        [ 1.0626, -1.3668],\n",
            "        [ 0.3351, -0.2114],\n",
            "        [-1.1421,  1.5422],\n",
            "        [ 0.6912, -0.4566],\n",
            "        [-0.2903,  0.5771]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1913,  1.5529],\n",
            "        [ 0.9375, -1.0478],\n",
            "        [ 0.9650, -1.1544],\n",
            "        [ 1.1681, -1.4145],\n",
            "        [-1.0644,  1.3214],\n",
            "        [ 0.2139,  0.0924],\n",
            "        [-1.1558,  1.4818],\n",
            "        [ 1.0439, -1.2645],\n",
            "        [-1.1977,  1.4736],\n",
            "        [-1.0890,  1.4882],\n",
            "        [-0.2280,  0.3846],\n",
            "        [-1.1009,  1.4320],\n",
            "        [-0.8310,  1.1830],\n",
            "        [ 0.6472, -0.4725],\n",
            "        [ 1.2153, -1.3113],\n",
            "        [ 1.3172, -1.6255],\n",
            "        [-0.4676,  0.7326],\n",
            "        [-1.0995,  1.4095],\n",
            "        [-1.1045,  1.3526],\n",
            "        [ 0.1714,  0.1238],\n",
            "        [-0.9419,  1.3023],\n",
            "        [-1.1285,  1.5063],\n",
            "        [ 0.3810, -0.3362],\n",
            "        [-0.9999,  1.4031],\n",
            "        [-0.8049,  1.1653],\n",
            "        [ 1.2466, -1.5288],\n",
            "        [-1.2441,  1.6132],\n",
            "        [ 1.0857, -1.1345],\n",
            "        [-0.7213,  1.0956],\n",
            "        [-0.6869,  1.0624],\n",
            "        [-1.1440,  1.5007],\n",
            "        [-0.1088,  0.2174]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1822,  1.5565],\n",
            "        [ 0.2003, -0.0557],\n",
            "        [-1.1045,  1.5525],\n",
            "        [ 0.4094, -0.1999],\n",
            "        [-1.1602,  1.5388],\n",
            "        [-0.9778,  1.3745],\n",
            "        [ 0.8467, -0.9680],\n",
            "        [-0.8592,  1.2854],\n",
            "        [-0.2745,  0.5536],\n",
            "        [-1.1862,  1.6120],\n",
            "        [ 0.9569, -0.9908],\n",
            "        [-0.8012,  1.1502],\n",
            "        [-1.2332,  1.6504],\n",
            "        [ 0.4365, -0.3286],\n",
            "        [ 0.2664, -0.0429],\n",
            "        [ 0.4987, -0.6743],\n",
            "        [-0.3350,  0.7638],\n",
            "        [-0.5003,  0.8060],\n",
            "        [ 0.5758, -0.3744],\n",
            "        [-0.9385,  1.4040],\n",
            "        [-1.2312,  1.5811],\n",
            "        [-1.1810,  1.5277],\n",
            "        [-0.4829,  0.9245],\n",
            "        [-1.2763,  1.6243],\n",
            "        [-0.5478,  0.8225],\n",
            "        [-0.0118,  0.3470],\n",
            "        [-0.0902,  0.2535],\n",
            "        [ 1.0406, -1.1902],\n",
            "        [ 0.3548, -0.1307],\n",
            "        [-0.3743,  0.7399],\n",
            "        [ 1.1538, -1.1248],\n",
            "        [-0.1084,  0.3186]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 6.5393e-01, -6.2176e-01],\n",
            "        [-1.1141e+00,  1.4890e+00],\n",
            "        [-1.2320e+00,  1.5846e+00],\n",
            "        [-1.0908e-01,  2.9922e-01],\n",
            "        [-3.8891e-01,  8.6829e-01],\n",
            "        [-6.6558e-02,  2.6504e-01],\n",
            "        [ 4.1200e-01, -8.4421e-02],\n",
            "        [-7.8085e-01,  1.2225e+00],\n",
            "        [-9.3413e-02,  3.9987e-01],\n",
            "        [-1.2072e+00,  1.5683e+00],\n",
            "        [ 9.7697e-01, -1.0239e+00],\n",
            "        [-9.3426e-01,  1.3371e+00],\n",
            "        [ 1.0376e+00, -1.3572e+00],\n",
            "        [-4.8031e-01,  9.0357e-01],\n",
            "        [-9.6786e-01,  1.3720e+00],\n",
            "        [-6.3253e-01,  9.2785e-01],\n",
            "        [-1.1152e+00,  1.4913e+00],\n",
            "        [-8.5098e-01,  1.1962e+00],\n",
            "        [-4.6086e-01,  7.8024e-01],\n",
            "        [ 3.5763e-01, -1.6261e-01],\n",
            "        [-5.0484e-01,  8.1148e-01],\n",
            "        [ 2.3643e-01,  1.2984e-03],\n",
            "        [-1.2195e+00,  1.5504e+00],\n",
            "        [ 1.1690e+00, -1.4362e+00],\n",
            "        [ 1.1272e+00, -1.3181e+00],\n",
            "        [-7.2799e-01,  1.2148e+00],\n",
            "        [-5.8121e-01,  9.4404e-01],\n",
            "        [-1.2179e+00,  1.6185e+00],\n",
            "        [-1.1193e+00,  1.4244e+00],\n",
            "        [-1.0408e+00,  1.4830e+00],\n",
            "        [-1.1786e+00,  1.5254e+00],\n",
            "        [-1.1657e+00,  1.5506e+00]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.2214,  1.5367],\n",
            "        [ 0.3828, -0.1654],\n",
            "        [-1.1851,  1.5634],\n",
            "        [-0.1844,  0.4003],\n",
            "        [-1.1065,  1.5148],\n",
            "        [-0.0620, -0.0150],\n",
            "        [-1.2818,  1.6151],\n",
            "        [ 1.2314, -1.4906],\n",
            "        [-0.8595,  1.2466],\n",
            "        [-1.1575,  1.5794],\n",
            "        [-0.8674,  1.4011],\n",
            "        [-0.5265,  0.7638],\n",
            "        [ 0.9126, -0.9729],\n",
            "        [-0.3677,  0.7506],\n",
            "        [-1.2282,  1.5441],\n",
            "        [-0.8827,  1.1137],\n",
            "        [ 0.0281,  0.4415],\n",
            "        [ 0.9085, -1.2106],\n",
            "        [-1.1489,  1.5775],\n",
            "        [ 0.9773, -1.1585],\n",
            "        [-1.1951,  1.5969],\n",
            "        [ 0.9421, -1.2002],\n",
            "        [ 0.6564, -0.6482],\n",
            "        [-1.1154,  1.5153],\n",
            "        [-0.0249,  0.4090],\n",
            "        [-0.9193,  1.1658],\n",
            "        [-0.2730,  0.7297],\n",
            "        [ 1.2707, -1.5277],\n",
            "        [-0.6385,  0.9019],\n",
            "        [-1.0572,  1.4562],\n",
            "        [ 0.7606, -0.7847],\n",
            "        [ 0.5681, -0.5857]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.0326, -1.2811],\n",
            "        [-1.1490,  1.5493],\n",
            "        [ 0.1271,  0.1283],\n",
            "        [ 0.2182,  0.1638],\n",
            "        [ 1.0348, -0.9444],\n",
            "        [-1.2711,  1.6213],\n",
            "        [-0.8948,  1.0224],\n",
            "        [-0.5357,  0.9148],\n",
            "        [-1.3008,  1.6344],\n",
            "        [ 0.2764, -0.3020],\n",
            "        [-0.1893,  0.3331],\n",
            "        [ 1.1343, -1.3505],\n",
            "        [-0.8330,  1.2904],\n",
            "        [-0.0117,  0.2532],\n",
            "        [ 0.9518, -1.0132],\n",
            "        [ 1.1688, -1.4419],\n",
            "        [-0.3011,  0.5330],\n",
            "        [ 0.3168, -0.4535],\n",
            "        [-0.0094,  0.2806],\n",
            "        [-0.3153,  0.4407],\n",
            "        [ 0.8475, -0.7953],\n",
            "        [-0.5540,  0.6738],\n",
            "        [-0.5041,  0.9197],\n",
            "        [-0.5432,  0.8995],\n",
            "        [ 0.2548, -0.0373],\n",
            "        [ 0.1499,  0.1343],\n",
            "        [-0.2902,  0.6473],\n",
            "        [ 0.8816, -0.9181],\n",
            "        [-1.0333,  1.2766],\n",
            "        [-0.3482,  0.6826],\n",
            "        [ 0.5123, -0.3238],\n",
            "        [-0.6483,  1.1984]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0126,  0.2247],\n",
            "        [-1.2893,  1.6181],\n",
            "        [ 1.2823, -1.3961],\n",
            "        [-0.6737,  1.0241],\n",
            "        [ 0.5765, -0.6311],\n",
            "        [ 0.0839,  0.1916],\n",
            "        [-1.1162,  1.4015],\n",
            "        [ 0.9828, -1.0268],\n",
            "        [-1.2272,  1.6029],\n",
            "        [-0.9495,  1.2794],\n",
            "        [ 0.7401, -0.8249],\n",
            "        [-1.2287,  1.5984],\n",
            "        [-0.1191,  0.3852],\n",
            "        [-0.2818,  0.5538],\n",
            "        [-0.4246,  0.8308],\n",
            "        [-1.1904,  1.6072],\n",
            "        [ 0.5885, -0.3980],\n",
            "        [-0.1080,  0.4680],\n",
            "        [ 1.1168, -1.3121],\n",
            "        [ 0.9710, -0.8623],\n",
            "        [-1.0155,  1.2803],\n",
            "        [-0.0080,  0.2598],\n",
            "        [-1.1438,  1.5440],\n",
            "        [ 0.6041, -0.5316],\n",
            "        [ 0.3896, -0.1884],\n",
            "        [ 0.6659, -0.7056],\n",
            "        [ 1.0421, -1.0826],\n",
            "        [ 1.0188, -1.2918],\n",
            "        [ 0.1865,  0.1172],\n",
            "        [-0.9817,  1.1655],\n",
            "        [ 0.8603, -0.9897],\n",
            "        [-1.0059,  1.3640]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3597, -0.2554],\n",
            "        [-1.2652,  1.6109],\n",
            "        [ 1.2117, -1.3068],\n",
            "        [ 1.2723, -1.5444],\n",
            "        [-1.2350,  1.6102],\n",
            "        [-0.3484,  0.6493],\n",
            "        [-0.4265,  0.5865],\n",
            "        [-1.1388,  1.4602],\n",
            "        [-0.6841,  1.0631],\n",
            "        [-1.1964,  1.5398],\n",
            "        [-0.9499,  1.3351],\n",
            "        [-0.4109,  0.6958],\n",
            "        [-0.1390,  0.4588],\n",
            "        [ 0.0924,  0.1574],\n",
            "        [-0.7236,  1.0668],\n",
            "        [-0.5948,  1.0443],\n",
            "        [ 0.0072,  0.3036],\n",
            "        [ 0.2165,  0.1807],\n",
            "        [-0.7902,  0.9762],\n",
            "        [-0.9005,  1.2052],\n",
            "        [-0.8726,  1.1808],\n",
            "        [ 0.4452, -0.3107],\n",
            "        [-1.2675,  1.6654],\n",
            "        [-1.2142,  1.5829],\n",
            "        [ 0.6265, -0.6354],\n",
            "        [-0.6786,  0.9748],\n",
            "        [ 0.2302, -0.1117],\n",
            "        [-0.0731,  0.2313],\n",
            "        [ 0.7134, -0.4560],\n",
            "        [-1.0731,  1.4286],\n",
            "        [-1.2603,  1.6248],\n",
            "        [-0.8626,  1.2246]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.2922, -1.5712],\n",
            "        [-0.8594,  1.0702],\n",
            "        [ 0.5789, -0.5403],\n",
            "        [ 0.1525,  0.1704],\n",
            "        [-1.1240,  1.4668],\n",
            "        [ 0.1230,  0.0755],\n",
            "        [-0.2177,  0.4807],\n",
            "        [-1.2102,  1.5008],\n",
            "        [ 0.8347, -0.9555],\n",
            "        [ 1.1354, -1.3732],\n",
            "        [-1.1242,  1.5326],\n",
            "        [-0.6009,  0.9697],\n",
            "        [-0.3408,  0.6223],\n",
            "        [-1.2449,  1.5590],\n",
            "        [-0.0958,  0.3187],\n",
            "        [-0.1012,  0.4766],\n",
            "        [-1.2203,  1.5329],\n",
            "        [ 0.8617, -0.8041],\n",
            "        [-0.3086,  0.5061],\n",
            "        [ 1.2050, -1.4347],\n",
            "        [-0.5682,  0.8715],\n",
            "        [-1.1103,  1.4206],\n",
            "        [-1.1214,  1.4675],\n",
            "        [-1.2570,  1.5688],\n",
            "        [ 0.0125,  0.2837],\n",
            "        [-0.2884,  0.6138],\n",
            "        [-0.4318,  0.6034],\n",
            "        [-1.1771,  1.5739],\n",
            "        [ 0.0857,  0.2716],\n",
            "        [-1.0821,  1.4643],\n",
            "        [-1.0844,  1.3771],\n",
            "        [-1.1753,  1.5559]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0450,  1.4848],\n",
            "        [-0.9585,  1.2884],\n",
            "        [ 0.4976, -0.3975],\n",
            "        [ 0.3304,  0.1981],\n",
            "        [-0.2198,  0.6330],\n",
            "        [ 0.6664, -0.4441],\n",
            "        [-0.7889,  1.1900],\n",
            "        [ 1.1449, -1.4387],\n",
            "        [ 0.4592, -0.1281],\n",
            "        [ 0.9723, -1.0477],\n",
            "        [-0.7918,  1.0295],\n",
            "        [-1.1486,  1.4754],\n",
            "        [-0.7885,  1.1536],\n",
            "        [-0.3920,  0.6946],\n",
            "        [-1.3502,  1.6500],\n",
            "        [ 0.3087, -0.2196],\n",
            "        [ 0.9050, -1.1015],\n",
            "        [ 0.3523, -0.3050],\n",
            "        [-0.2669,  0.6078],\n",
            "        [ 0.0374,  0.2758],\n",
            "        [ 0.9671, -0.9962],\n",
            "        [ 1.2967, -1.5790],\n",
            "        [-1.1769,  1.5398],\n",
            "        [-1.1665,  1.5560],\n",
            "        [ 0.3723, -0.1204],\n",
            "        [-0.3484,  0.4823],\n",
            "        [-1.2420,  1.5384],\n",
            "        [-0.2284,  0.3186],\n",
            "        [ 0.0062,  0.3214],\n",
            "        [ 0.5335, -0.4014],\n",
            "        [-1.2388,  1.6301],\n",
            "        [ 0.8222, -0.9220]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.2121, -1.4034],\n",
            "        [-0.6467,  1.0561],\n",
            "        [-0.9385,  1.1892],\n",
            "        [-0.2193,  0.6222],\n",
            "        [ 0.4800, -0.3869],\n",
            "        [-1.1637,  1.5503],\n",
            "        [ 0.3438, -0.0750],\n",
            "        [-1.2035,  1.6165],\n",
            "        [ 0.6254, -0.5971],\n",
            "        [-0.6897,  1.0256],\n",
            "        [ 0.3057, -0.2900],\n",
            "        [-0.8420,  1.1963],\n",
            "        [ 0.7259, -0.6332],\n",
            "        [-0.7684,  1.2031],\n",
            "        [-1.2849,  1.6657],\n",
            "        [-0.7653,  0.7985],\n",
            "        [ 0.7960, -0.7944],\n",
            "        [ 1.0334, -1.2522],\n",
            "        [-0.2396,  0.4075],\n",
            "        [-1.1555,  1.4835],\n",
            "        [-1.2328,  1.4981],\n",
            "        [ 0.7729, -0.6526],\n",
            "        [-0.7841,  1.0875],\n",
            "        [-0.9742,  1.4218],\n",
            "        [ 0.7818, -0.8821],\n",
            "        [-1.2424,  1.5702],\n",
            "        [-0.9430,  1.2624],\n",
            "        [ 1.0255, -0.9701],\n",
            "        [ 0.2622, -0.1998],\n",
            "        [-0.8221,  1.1868],\n",
            "        [ 0.5920, -0.7355],\n",
            "        [ 1.2547, -1.5697]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.7976,  1.2588],\n",
            "        [ 0.0565,  0.1294],\n",
            "        [-1.0407,  1.3572],\n",
            "        [ 0.6330, -0.7482],\n",
            "        [ 0.0632,  0.0966],\n",
            "        [-0.2111,  0.3310],\n",
            "        [-0.3659,  0.6293],\n",
            "        [-0.6105,  1.1418],\n",
            "        [ 0.4252, -0.3461],\n",
            "        [-0.8438,  1.2390],\n",
            "        [-1.1071,  1.5014],\n",
            "        [ 0.5632, -0.3039],\n",
            "        [ 0.0364,  0.3231],\n",
            "        [-0.9943,  1.3986],\n",
            "        [-1.1545,  1.5400],\n",
            "        [-0.0272,  0.4653],\n",
            "        [-0.8824,  1.2923],\n",
            "        [-0.5489,  0.8787],\n",
            "        [-1.0725,  1.4619],\n",
            "        [-1.0497,  1.5180],\n",
            "        [ 0.1757,  0.2178],\n",
            "        [ 0.5447, -0.3622],\n",
            "        [-0.9369,  1.3144],\n",
            "        [ 0.0812,  0.1758],\n",
            "        [ 0.3093,  0.0566],\n",
            "        [-0.6877,  0.8453],\n",
            "        [-1.2286,  1.5921],\n",
            "        [ 0.2801, -0.0734],\n",
            "        [-1.1003,  1.3879],\n",
            "        [ 0.2294, -0.2492],\n",
            "        [ 0.1263,  0.0209],\n",
            "        [-0.5621,  0.9382]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.3287,  1.6720],\n",
            "        [ 0.0188,  0.3557],\n",
            "        [-0.7324,  1.0184],\n",
            "        [-0.9634,  1.4404],\n",
            "        [-0.7748,  1.2035],\n",
            "        [ 1.2423, -1.4648],\n",
            "        [-0.2665,  0.7927],\n",
            "        [ 0.5956, -0.6504],\n",
            "        [ 0.1476, -0.0833],\n",
            "        [ 1.1367, -1.3268],\n",
            "        [-1.1668,  1.4923],\n",
            "        [ 0.9203, -0.8794],\n",
            "        [-0.5011,  0.5844],\n",
            "        [ 0.5287, -0.4456],\n",
            "        [-0.9194,  1.2288],\n",
            "        [ 0.5988, -0.6303],\n",
            "        [-0.5011,  0.8427],\n",
            "        [ 0.9617, -1.0615],\n",
            "        [-0.1919,  0.6023],\n",
            "        [-0.9253,  1.2460],\n",
            "        [ 1.1888, -1.4681],\n",
            "        [ 0.5881, -0.5225],\n",
            "        [-1.1369,  1.5606],\n",
            "        [-1.0263,  1.3666],\n",
            "        [ 0.5581, -0.3594],\n",
            "        [ 1.1477, -1.4708],\n",
            "        [-1.0879,  1.4720],\n",
            "        [-1.2146,  1.5465],\n",
            "        [-1.2008,  1.5155],\n",
            "        [ 0.9407, -1.0778],\n",
            "        [-1.0219,  1.4031],\n",
            "        [-0.2907,  0.6233]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9211,  1.2332],\n",
            "        [ 0.7045, -0.6385],\n",
            "        [-0.3656,  0.8354],\n",
            "        [-1.3004,  1.6227],\n",
            "        [ 0.0601, -0.0068],\n",
            "        [ 1.1968, -1.3233],\n",
            "        [ 0.8121, -1.0206],\n",
            "        [-0.2182,  0.6103],\n",
            "        [ 0.6678, -0.7272],\n",
            "        [-0.9179,  1.2604],\n",
            "        [-0.8547,  1.1333],\n",
            "        [-0.7139,  0.9009],\n",
            "        [-0.4381,  0.6762],\n",
            "        [ 0.2646, -0.0410],\n",
            "        [-1.1948,  1.5289],\n",
            "        [ 0.9433, -1.0601],\n",
            "        [-0.1258,  0.2424],\n",
            "        [-0.1380,  0.5426],\n",
            "        [-1.1595,  1.5028],\n",
            "        [ 0.4485, -0.2021],\n",
            "        [-1.0320,  1.4974],\n",
            "        [-0.9664,  1.3248],\n",
            "        [-0.6545,  1.1017],\n",
            "        [ 0.2937, -0.0939],\n",
            "        [-1.1747,  1.5794],\n",
            "        [-1.0529,  1.3075],\n",
            "        [-0.2522,  0.6022],\n",
            "        [-0.9603,  1.4013],\n",
            "        [-1.2699,  1.6248],\n",
            "        [-1.0862,  1.5194],\n",
            "        [ 0.9096, -0.9428],\n",
            "        [-0.2339,  0.3384]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.0982, -0.0113],\n",
            "        [-0.1471,  0.5809],\n",
            "        [-0.9731,  1.3605],\n",
            "        [-1.2922,  1.6359],\n",
            "        [-0.3122,  0.7769],\n",
            "        [ 0.9021, -0.9161],\n",
            "        [-1.0112,  1.4011],\n",
            "        [-0.9996,  1.3935],\n",
            "        [-0.4381,  0.8922],\n",
            "        [-1.0083,  1.3296],\n",
            "        [ 1.2780, -1.4955],\n",
            "        [-1.3017,  1.5956],\n",
            "        [-0.7765,  1.2033],\n",
            "        [ 1.1939, -1.3542],\n",
            "        [ 1.2583, -1.5388],\n",
            "        [ 0.4442, -0.2406],\n",
            "        [ 1.0733, -1.2774],\n",
            "        [ 0.1503,  0.2945],\n",
            "        [-0.9924,  1.3465],\n",
            "        [-1.2583,  1.5965],\n",
            "        [ 1.2328, -1.5722],\n",
            "        [-0.0620,  0.1948],\n",
            "        [-0.8846,  1.1557],\n",
            "        [-0.0991,  0.4467],\n",
            "        [-0.3347,  0.7487],\n",
            "        [ 1.0439, -1.0463],\n",
            "        [-1.2762,  1.6397],\n",
            "        [ 0.2837,  0.0059],\n",
            "        [-0.9097,  1.3617],\n",
            "        [ 0.8521, -0.9674],\n",
            "        [ 0.7547, -0.7612],\n",
            "        [ 0.8076, -0.8194]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.0392,  1.4404],\n",
            "        [-0.5356,  0.8877],\n",
            "        [ 1.1848, -1.3969],\n",
            "        [-0.2419,  0.5913],\n",
            "        [-0.4473,  0.8980],\n",
            "        [-1.1346,  1.4788],\n",
            "        [ 0.8731, -0.7687],\n",
            "        [ 0.0450,  0.2149],\n",
            "        [-0.9295,  1.2911],\n",
            "        [ 0.7547, -0.6693],\n",
            "        [-1.1990,  1.5042],\n",
            "        [-1.0219,  1.4085],\n",
            "        [ 0.1582,  0.1517],\n",
            "        [ 0.1732,  0.1342],\n",
            "        [-1.0907,  1.4686],\n",
            "        [-0.5193,  0.7773],\n",
            "        [-0.1004,  0.4219],\n",
            "        [ 1.0341, -1.3475],\n",
            "        [-1.1532,  1.5565],\n",
            "        [-0.5267,  0.9154],\n",
            "        [ 0.1041,  0.1607],\n",
            "        [ 0.7937, -0.7347],\n",
            "        [ 0.4972, -0.2116],\n",
            "        [-1.0778,  1.4018],\n",
            "        [-0.4649,  0.7583],\n",
            "        [-1.2758,  1.6005],\n",
            "        [-0.0207,  0.3779],\n",
            "        [-1.1976,  1.5642],\n",
            "        [ 0.8706, -0.8162],\n",
            "        [ 1.0121, -1.0008],\n",
            "        [ 0.7628, -1.0224],\n",
            "        [-1.2150,  1.5704]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.2967, -0.0415],\n",
            "        [-0.0384,  0.3763],\n",
            "        [-0.2879,  0.4079],\n",
            "        [-1.0175,  1.4665],\n",
            "        [-0.6658,  0.9272],\n",
            "        [ 0.5079, -0.5787],\n",
            "        [ 0.8568, -0.8831],\n",
            "        [ 0.2574,  0.1765],\n",
            "        [-0.0202,  0.4338],\n",
            "        [-0.1889,  0.2860],\n",
            "        [ 0.6169, -0.6509],\n",
            "        [ 1.0635, -1.1857],\n",
            "        [ 0.3586, -0.3666],\n",
            "        [-0.6000,  0.9328],\n",
            "        [-1.2161,  1.5329],\n",
            "        [-0.6943,  1.0619],\n",
            "        [-1.2141,  1.5961],\n",
            "        [-0.1082,  0.4529],\n",
            "        [-0.7652,  1.2338],\n",
            "        [-0.7553,  1.0176],\n",
            "        [-0.9952,  1.2625],\n",
            "        [-1.0316,  1.2831],\n",
            "        [-1.1321,  1.4947],\n",
            "        [-0.0454,  0.5014],\n",
            "        [-1.1721,  1.5405],\n",
            "        [ 0.5342, -0.7923],\n",
            "        [-0.6910,  1.0618],\n",
            "        [-1.2568,  1.6185],\n",
            "        [-0.7603,  1.1442],\n",
            "        [-0.3016,  0.6058],\n",
            "        [-0.9698,  1.3586],\n",
            "        [-1.2402,  1.6494]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.1101, -1.1948],\n",
            "        [ 1.0429, -1.3365],\n",
            "        [-1.1351,  1.3599],\n",
            "        [ 0.2491,  0.0196],\n",
            "        [ 0.6001, -0.7267],\n",
            "        [ 0.8916, -0.9147],\n",
            "        [-0.0095,  0.4574],\n",
            "        [ 0.3366, -0.2295],\n",
            "        [-0.6080,  0.8591],\n",
            "        [-0.9939,  1.3108],\n",
            "        [ 1.0764, -1.1721],\n",
            "        [-0.6997,  1.1176],\n",
            "        [ 1.1478, -1.3849],\n",
            "        [-0.6105,  0.7479],\n",
            "        [-0.7712,  1.1296],\n",
            "        [-0.6084,  0.8199],\n",
            "        [-0.9391,  1.3216],\n",
            "        [-1.0595,  1.5103],\n",
            "        [ 0.4613, -0.3278],\n",
            "        [ 0.1463, -0.0521],\n",
            "        [-0.9335,  1.1870],\n",
            "        [-0.5128,  0.7710],\n",
            "        [-0.4220,  0.6881],\n",
            "        [-1.2293,  1.6076],\n",
            "        [-0.1682,  0.5998],\n",
            "        [-1.2331,  1.5670],\n",
            "        [-0.3412,  0.7477],\n",
            "        [-0.3132,  0.6340],\n",
            "        [ 0.3977, -0.2382],\n",
            "        [-0.5619,  1.0355],\n",
            "        [-1.1718,  1.5614],\n",
            "        [-1.1926,  1.6050]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9152, -1.1798],\n",
            "        [-0.4067,  0.6890],\n",
            "        [-1.0596,  1.3917],\n",
            "        [-1.2775,  1.5852],\n",
            "        [-0.2377,  0.3879],\n",
            "        [-0.0929,  0.3606],\n",
            "        [ 0.8417, -0.8660],\n",
            "        [-1.0173,  1.2866],\n",
            "        [-0.1195,  0.3425],\n",
            "        [ 0.7536, -0.9059],\n",
            "        [-1.1567,  1.5719],\n",
            "        [-1.0194,  1.2894],\n",
            "        [-1.1863,  1.5449],\n",
            "        [ 1.2223, -1.2273],\n",
            "        [ 0.3548, -0.0693],\n",
            "        [-0.5254,  0.9030],\n",
            "        [-1.2123,  1.5764],\n",
            "        [ 1.2233, -1.5606],\n",
            "        [-1.1523,  1.4505],\n",
            "        [-0.6469,  1.0263],\n",
            "        [ 0.3948, -0.2200],\n",
            "        [-0.8172,  1.2120],\n",
            "        [-0.6460,  0.8175],\n",
            "        [ 0.9954, -1.1447],\n",
            "        [ 0.4231, -0.1875],\n",
            "        [-0.9459,  1.4016],\n",
            "        [ 1.1369, -1.4722],\n",
            "        [-0.4317,  0.7477],\n",
            "        [ 0.6816, -0.6942],\n",
            "        [ 0.5721, -0.3089],\n",
            "        [ 0.4264, -0.3684],\n",
            "        [ 0.4960, -0.3978]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9196,  1.3240],\n",
            "        [ 0.7508, -0.5988],\n",
            "        [-0.2619,  0.6237],\n",
            "        [-0.0713,  0.5120],\n",
            "        [-0.9434,  1.4337],\n",
            "        [-0.5929,  0.8166],\n",
            "        [-1.0127,  1.3787],\n",
            "        [ 1.1754, -1.3516],\n",
            "        [ 0.9542, -1.2805],\n",
            "        [ 0.5460, -0.5472],\n",
            "        [-0.3087,  0.5882],\n",
            "        [-0.1403,  0.3998],\n",
            "        [ 0.4813, -0.3277],\n",
            "        [-0.3748,  0.6094],\n",
            "        [-1.1075,  1.4936],\n",
            "        [-1.2667,  1.6426],\n",
            "        [ 0.9390, -1.1217],\n",
            "        [-0.9360,  1.3696],\n",
            "        [ 0.3074, -0.2563],\n",
            "        [-0.6522,  1.0632],\n",
            "        [ 1.1713, -1.3308],\n",
            "        [ 0.2288,  0.0394],\n",
            "        [ 0.8629, -1.1017],\n",
            "        [-1.2000,  1.5983],\n",
            "        [ 0.5883, -0.4618],\n",
            "        [ 0.1819,  0.0362],\n",
            "        [ 0.5500, -0.2684],\n",
            "        [-0.6317,  1.0317],\n",
            "        [-0.5920,  0.7381],\n",
            "        [-1.1371,  1.4984],\n",
            "        [ 0.4562, -0.6423],\n",
            "        [-0.9022,  1.3754]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1655,  1.4549],\n",
            "        [ 0.7744, -0.6536],\n",
            "        [-1.0172,  1.4789],\n",
            "        [ 1.2299, -1.5364],\n",
            "        [-1.1011,  1.3949],\n",
            "        [ 1.1037, -1.3319],\n",
            "        [-1.2880,  1.6269],\n",
            "        [ 0.8884, -1.0376],\n",
            "        [-1.0110,  1.3932],\n",
            "        [-0.6373,  1.1124],\n",
            "        [ 0.6969, -0.4630],\n",
            "        [ 1.1621, -1.2906],\n",
            "        [-1.2949,  1.5897],\n",
            "        [ 0.8162, -0.9032],\n",
            "        [ 0.5641, -0.4377],\n",
            "        [-1.1632,  1.5590],\n",
            "        [-1.1847,  1.5666],\n",
            "        [ 0.8148, -0.6257],\n",
            "        [-0.9183,  1.1117],\n",
            "        [-0.8083,  1.0826],\n",
            "        [-1.1514,  1.4992],\n",
            "        [-0.4752,  0.6626],\n",
            "        [ 0.5380, -0.5140],\n",
            "        [-0.7220,  0.9630],\n",
            "        [-0.0397,  0.5365],\n",
            "        [ 0.6050, -0.3966],\n",
            "        [ 0.6635, -0.4912],\n",
            "        [-0.4667,  0.8651],\n",
            "        [-0.7951,  1.2180],\n",
            "        [-1.2112,  1.5883],\n",
            "        [ 0.0975,  0.1564],\n",
            "        [ 1.2389, -1.3759]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.3323, -1.4960],\n",
            "        [ 0.9477, -1.1593],\n",
            "        [ 0.4040, -0.1558],\n",
            "        [-1.0308,  1.3108],\n",
            "        [ 1.0456, -1.1773],\n",
            "        [-1.0681,  1.4573],\n",
            "        [-0.4159,  0.6569],\n",
            "        [-0.2804,  0.4272],\n",
            "        [ 0.0819,  0.2309],\n",
            "        [ 0.9709, -1.1048],\n",
            "        [ 0.2774, -0.0334],\n",
            "        [ 0.7826, -0.8916],\n",
            "        [ 0.5270, -0.2536],\n",
            "        [ 0.0526,  0.4260],\n",
            "        [ 1.2505, -1.5022],\n",
            "        [ 0.9979, -1.2212],\n",
            "        [ 1.2777, -1.5695],\n",
            "        [-0.9475,  1.3943],\n",
            "        [-0.0082,  0.3393],\n",
            "        [-0.0088,  0.4056],\n",
            "        [ 1.0696, -1.1833],\n",
            "        [ 0.3065, -0.0257],\n",
            "        [-1.1611,  1.4816],\n",
            "        [ 0.2841,  0.0197],\n",
            "        [ 1.1606, -1.2869],\n",
            "        [-1.1637,  1.5561],\n",
            "        [ 0.2054,  0.1592],\n",
            "        [-0.7186,  0.9801],\n",
            "        [-1.1520,  1.4661],\n",
            "        [-1.2479,  1.6224],\n",
            "        [ 0.6296, -0.7060],\n",
            "        [ 0.5917, -0.4061]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 1.0435, -1.2167],\n",
            "        [-0.9467,  1.3862],\n",
            "        [ 0.3343, -0.0987],\n",
            "        [ 1.2623, -1.5156],\n",
            "        [ 0.5854, -0.5526],\n",
            "        [ 0.1031,  0.1348],\n",
            "        [-1.2085,  1.6153],\n",
            "        [-1.0958,  1.4720],\n",
            "        [ 0.5424, -0.5752],\n",
            "        [-0.9715,  1.2293],\n",
            "        [-0.0236,  0.1352],\n",
            "        [-0.7349,  1.0398],\n",
            "        [ 0.1942,  0.1139],\n",
            "        [ 0.3429, -0.1604],\n",
            "        [ 0.0586,  0.3333],\n",
            "        [ 0.1304,  0.3112],\n",
            "        [-0.9365,  1.2896],\n",
            "        [-0.6761,  1.0770],\n",
            "        [-0.5185,  0.8149],\n",
            "        [ 0.6205, -0.5299],\n",
            "        [-0.8402,  1.3312],\n",
            "        [-0.8263,  1.1551],\n",
            "        [ 1.0773, -1.2745],\n",
            "        [-1.1839,  1.4804],\n",
            "        [-0.1504,  0.4213],\n",
            "        [-1.1178,  1.4772],\n",
            "        [-0.8581,  1.2478],\n",
            "        [-0.8546,  1.1703],\n",
            "        [-1.2648,  1.5854],\n",
            "        [-0.4922,  0.9567],\n",
            "        [ 0.8685, -1.1040],\n",
            "        [-1.0316,  1.3798]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.5071, -0.2792],\n",
            "        [-0.6649,  1.1054],\n",
            "        [-1.2022,  1.5426],\n",
            "        [-0.1688,  0.4972],\n",
            "        [-0.0943,  0.2638],\n",
            "        [-1.2945,  1.6215],\n",
            "        [-1.2154,  1.5996],\n",
            "        [-1.1503,  1.4514],\n",
            "        [-1.0970,  1.4540],\n",
            "        [-1.0823,  1.4601],\n",
            "        [-1.1945,  1.4615],\n",
            "        [-0.2051,  0.6541],\n",
            "        [-0.1627,  0.2826],\n",
            "        [ 0.1419, -0.0084],\n",
            "        [-1.0839,  1.4193],\n",
            "        [-0.4972,  0.6380],\n",
            "        [-1.1948,  1.5795],\n",
            "        [-0.7124,  1.1883],\n",
            "        [ 1.1257, -1.3995],\n",
            "        [ 0.7586, -0.7875],\n",
            "        [-0.7925,  1.1739],\n",
            "        [-0.1855,  0.5345],\n",
            "        [ 0.8719, -0.9799],\n",
            "        [-1.0418,  1.4596],\n",
            "        [-0.1011,  0.1700],\n",
            "        [ 0.0833,  0.0966],\n",
            "        [-0.6855,  1.0712],\n",
            "        [-1.1486,  1.5309],\n",
            "        [ 0.9486, -1.1157],\n",
            "        [ 1.0914, -1.3388],\n",
            "        [ 0.0355,  0.2859],\n",
            "        [ 0.8721, -0.9589]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.7116, -0.4447],\n",
            "        [-0.4885,  0.6267],\n",
            "        [ 1.0852, -1.1118],\n",
            "        [-1.0746,  1.3878],\n",
            "        [-1.2010,  1.4827],\n",
            "        [-0.8421,  1.2222],\n",
            "        [ 1.1144, -1.2121],\n",
            "        [-1.1194,  1.4734],\n",
            "        [-1.1041,  1.3267],\n",
            "        [-0.8001,  1.0949],\n",
            "        [-1.1842,  1.6159],\n",
            "        [ 0.3083, -0.0991],\n",
            "        [ 0.7752, -0.7139],\n",
            "        [-0.2386,  0.6456],\n",
            "        [ 0.9345, -1.0389],\n",
            "        [ 0.3549, -0.2259],\n",
            "        [-1.0668,  1.3473],\n",
            "        [ 0.2187, -0.1271],\n",
            "        [-0.4163,  0.7663],\n",
            "        [-0.8602,  1.2029],\n",
            "        [-1.1084,  1.4978],\n",
            "        [-0.6212,  0.9717],\n",
            "        [-0.2791,  0.5968],\n",
            "        [ 0.7252, -0.7842],\n",
            "        [ 0.9416, -1.1400],\n",
            "        [-0.3364,  0.5840],\n",
            "        [-1.0647,  1.4839],\n",
            "        [-0.1855,  0.3835],\n",
            "        [-0.1906,  0.5481],\n",
            "        [ 0.5384, -0.4771],\n",
            "        [-0.1748,  0.5705],\n",
            "        [-0.3289,  0.7987]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9416,  1.2279],\n",
            "        [ 0.5723, -0.3734],\n",
            "        [ 1.0026, -1.3332],\n",
            "        [-1.0264,  1.4191],\n",
            "        [ 1.1612, -1.2465],\n",
            "        [-0.3080,  0.5883],\n",
            "        [-0.9234,  1.1873],\n",
            "        [-1.1563,  1.5163],\n",
            "        [ 1.1507, -1.4267],\n",
            "        [ 1.1497, -1.3879],\n",
            "        [ 1.1864, -1.4206],\n",
            "        [ 0.7104, -0.5862],\n",
            "        [-1.1535,  1.4635],\n",
            "        [-0.5280,  0.8021],\n",
            "        [-1.1887,  1.4902],\n",
            "        [-0.5641,  0.8769],\n",
            "        [-0.0823,  0.5500],\n",
            "        [-0.6210,  0.8657],\n",
            "        [-0.0638,  0.4851],\n",
            "        [-1.1939,  1.4869],\n",
            "        [-1.2674,  1.5661],\n",
            "        [-0.6824,  0.9994],\n",
            "        [-1.1461,  1.4617],\n",
            "        [ 0.3602, -0.2264],\n",
            "        [-0.4729,  0.9213],\n",
            "        [-0.3731,  0.8836],\n",
            "        [ 1.3686, -1.5863],\n",
            "        [-0.4495,  0.7800],\n",
            "        [-1.2126,  1.5387],\n",
            "        [-0.0058,  0.2129],\n",
            "        [ 0.4901, -0.6433],\n",
            "        [ 0.6085, -0.5917]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.8438e-01,  5.6247e-01],\n",
            "        [-3.4765e-01,  7.7825e-01],\n",
            "        [ 5.5849e-02,  3.5021e-01],\n",
            "        [ 9.7986e-02,  2.8690e-01],\n",
            "        [-8.3448e-01,  1.0690e+00],\n",
            "        [-1.1822e+00,  1.3986e+00],\n",
            "        [-9.5623e-01,  1.2836e+00],\n",
            "        [-1.2449e+00,  1.5885e+00],\n",
            "        [-1.2130e+00,  1.5659e+00],\n",
            "        [-1.1412e+00,  1.4594e+00],\n",
            "        [ 5.6903e-02,  2.8047e-01],\n",
            "        [ 4.0817e-04,  3.0154e-01],\n",
            "        [-4.8850e-01,  8.2255e-01],\n",
            "        [-1.2256e+00,  1.5648e+00],\n",
            "        [ 4.5176e-01, -6.3537e-01],\n",
            "        [-1.1478e+00,  1.5032e+00],\n",
            "        [-6.8311e-01,  1.0219e+00],\n",
            "        [-8.5671e-01,  1.2216e+00],\n",
            "        [-1.2263e+00,  1.5874e+00],\n",
            "        [-1.0522e+00,  1.3961e+00],\n",
            "        [ 6.0566e-01, -6.1557e-01],\n",
            "        [-1.0883e+00,  1.4886e+00],\n",
            "        [-1.0747e+00,  1.4813e+00],\n",
            "        [ 9.5131e-01, -1.0785e+00],\n",
            "        [ 6.9289e-01, -6.6201e-01],\n",
            "        [ 6.2758e-01, -8.0206e-01],\n",
            "        [ 8.4721e-01, -8.7526e-01],\n",
            "        [ 3.5993e-01, -2.3150e-01],\n",
            "        [-1.2031e+00,  1.5346e+00],\n",
            "        [ 7.7134e-01, -7.4992e-01],\n",
            "        [-3.2489e-01,  5.8414e-01],\n",
            "        [-1.1956e+00,  1.5081e+00]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.5025, -0.4372],\n",
            "        [-0.9702,  1.4549],\n",
            "        [-0.9934,  1.2473],\n",
            "        [-1.1285,  1.5157],\n",
            "        [ 0.3552, -0.0541],\n",
            "        [ 1.0984, -1.2723],\n",
            "        [-0.7547,  1.2384],\n",
            "        [-0.7064,  1.0195],\n",
            "        [-0.8795,  1.2117],\n",
            "        [-1.0939,  1.3765],\n",
            "        [ 0.9651, -1.1004],\n",
            "        [-1.1339,  1.5297],\n",
            "        [-1.1896,  1.5922],\n",
            "        [-0.1478,  0.1680],\n",
            "        [ 1.1137, -1.3303],\n",
            "        [ 0.2783, -0.0144],\n",
            "        [ 0.0938,  0.1518],\n",
            "        [-0.5806,  1.0677],\n",
            "        [-1.1452,  1.4851],\n",
            "        [-1.2504,  1.5877],\n",
            "        [-0.8195,  1.2845],\n",
            "        [-0.0142,  0.2615],\n",
            "        [-1.0338,  1.3679],\n",
            "        [ 0.5222, -0.2357],\n",
            "        [-0.5812,  1.0650],\n",
            "        [-1.1591,  1.4976],\n",
            "        [-1.1894,  1.5796],\n",
            "        [-0.5587,  0.9459],\n",
            "        [-0.9345,  1.1601],\n",
            "        [ 1.2194, -1.4251],\n",
            "        [-1.0435,  1.3934],\n",
            "        [-1.0598,  1.4638]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.9358, -0.8402],\n",
            "        [-1.2217,  1.5481],\n",
            "        [ 1.1481, -1.3129],\n",
            "        [-0.7562,  1.1183],\n",
            "        [ 0.5190, -0.4572],\n",
            "        [ 0.7851, -0.7517],\n",
            "        [ 0.6288, -0.7624],\n",
            "        [ 0.2967,  0.1054],\n",
            "        [ 0.1241,  0.0155],\n",
            "        [-0.5084,  0.9228],\n",
            "        [-1.2595,  1.5913],\n",
            "        [ 0.0892,  0.0269],\n",
            "        [ 0.7262, -0.8922],\n",
            "        [ 0.5926, -0.6568],\n",
            "        [-0.4388,  0.4925],\n",
            "        [-0.7485,  1.3539],\n",
            "        [ 0.2407, -0.0016],\n",
            "        [ 1.1209, -1.3687],\n",
            "        [ 0.6557, -0.6805],\n",
            "        [ 0.9831, -1.2653],\n",
            "        [ 0.4959, -0.4159],\n",
            "        [ 0.5892, -0.4893],\n",
            "        [ 0.2575, -0.1418],\n",
            "        [-1.2740,  1.5974],\n",
            "        [ 1.0368, -1.3406],\n",
            "        [ 0.0170,  0.3969],\n",
            "        [ 0.5259, -0.4745],\n",
            "        [-1.1712,  1.5548],\n",
            "        [ 0.1582,  0.0965],\n",
            "        [-0.2646,  0.4998],\n",
            "        [-1.1490,  1.5654],\n",
            "        [-1.1967,  1.5837]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9993,  1.3766],\n",
            "        [-0.9078,  1.3428],\n",
            "        [ 0.2580, -0.1312],\n",
            "        [ 0.0463,  0.2922],\n",
            "        [ 0.2877, -0.1129],\n",
            "        [ 0.7848, -0.9349],\n",
            "        [ 0.4195, -0.2535],\n",
            "        [ 0.2178,  0.2932],\n",
            "        [-0.5484,  1.0011],\n",
            "        [-0.8209,  1.2210],\n",
            "        [-0.7669,  1.0735],\n",
            "        [ 0.4896, -0.2564],\n",
            "        [-1.2261,  1.5220],\n",
            "        [-0.3733,  0.8501],\n",
            "        [ 0.6953, -0.7136],\n",
            "        [-0.4449,  0.8395],\n",
            "        [-0.4639,  0.6346],\n",
            "        [-0.4017,  0.5204],\n",
            "        [ 0.5024, -0.2379],\n",
            "        [-0.1769,  0.4796],\n",
            "        [-1.2715,  1.6582],\n",
            "        [-0.0238,  0.4756],\n",
            "        [ 0.4406, -0.5160],\n",
            "        [-1.2794,  1.6453],\n",
            "        [ 0.8289, -0.8944],\n",
            "        [-1.0813,  1.3621],\n",
            "        [ 0.4558, -0.3103],\n",
            "        [ 0.8885, -0.9748],\n",
            "        [-1.2163,  1.5912],\n",
            "        [-0.3380,  0.8377],\n",
            "        [ 0.9608, -1.0444],\n",
            "        [-0.5762,  0.9166]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.3523,  0.6521],\n",
            "        [ 0.1479,  0.1140],\n",
            "        [-0.6424,  1.0530],\n",
            "        [-1.1106,  1.5473],\n",
            "        [ 1.3557, -1.6146],\n",
            "        [-0.4731,  0.7761],\n",
            "        [ 1.3156, -1.5321],\n",
            "        [-0.8803,  1.0937],\n",
            "        [ 0.6098, -0.5900],\n",
            "        [-0.6401,  1.1099],\n",
            "        [-0.6314,  1.0531],\n",
            "        [-0.8631,  1.1488],\n",
            "        [ 0.6499, -0.6779],\n",
            "        [-0.9141,  1.3409],\n",
            "        [ 0.4119, -0.3218],\n",
            "        [-0.0544,  0.5309],\n",
            "        [ 0.0958,  0.0439],\n",
            "        [ 0.5572, -0.5613],\n",
            "        [ 0.7739, -0.9452],\n",
            "        [-0.6781,  1.1441],\n",
            "        [-0.5686,  0.9722],\n",
            "        [-1.2001,  1.5026],\n",
            "        [ 0.6023, -0.3795],\n",
            "        [-1.1397,  1.5221],\n",
            "        [ 0.8066, -1.0473],\n",
            "        [ 0.4040, -0.1954],\n",
            "        [-1.1329,  1.5861],\n",
            "        [-0.9718,  1.3873],\n",
            "        [ 0.7692, -0.8368],\n",
            "        [-1.1692,  1.4479],\n",
            "        [ 0.2085, -0.1407],\n",
            "        [ 1.1314, -1.3042]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4259, -0.1959],\n",
            "        [ 0.2790, -0.1696],\n",
            "        [-1.1130,  1.4119],\n",
            "        [-0.1082,  0.2314],\n",
            "        [ 0.0958,  0.3801],\n",
            "        [-0.6281,  1.1280],\n",
            "        [-0.5455,  0.6986],\n",
            "        [-1.0966,  1.4887],\n",
            "        [ 0.0340,  0.2421],\n",
            "        [ 1.0406, -1.2198],\n",
            "        [-0.6376,  0.7593],\n",
            "        [ 1.0731, -1.3623],\n",
            "        [-0.6876,  1.1112],\n",
            "        [-0.4241,  0.5432],\n",
            "        [ 1.0844, -1.2870],\n",
            "        [ 0.3784, -0.3912],\n",
            "        [-1.0285,  1.3786],\n",
            "        [-1.2169,  1.5914],\n",
            "        [-1.0787,  1.4043],\n",
            "        [ 0.9370, -0.8908],\n",
            "        [ 0.4148, -0.3417],\n",
            "        [ 0.4353, -0.3468],\n",
            "        [ 0.1718,  0.1547],\n",
            "        [-0.9048,  1.2345],\n",
            "        [-1.0934,  1.3839],\n",
            "        [ 0.3811, -0.1848],\n",
            "        [-0.9828,  1.4117],\n",
            "        [ 0.0928,  0.0783],\n",
            "        [ 0.2881, -0.0971],\n",
            "        [ 0.3271, -0.1185],\n",
            "        [-0.9342,  1.2269],\n",
            "        [-0.1355,  0.2949]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.1510,  1.4377],\n",
            "        [ 0.0745, -0.0852],\n",
            "        [-1.2723,  1.6116],\n",
            "        [-1.2001,  1.5859],\n",
            "        [ 1.1025, -1.1795],\n",
            "        [-0.9455,  1.2003],\n",
            "        [-1.0938,  1.4476],\n",
            "        [-0.5085,  0.8026],\n",
            "        [-0.8537,  1.3009],\n",
            "        [ 0.6566, -0.7457],\n",
            "        [ 0.1441, -0.0384],\n",
            "        [ 0.8512, -0.9632],\n",
            "        [-0.1411,  0.3113],\n",
            "        [ 1.1250, -1.2461],\n",
            "        [ 0.0575,  0.0452],\n",
            "        [ 0.9316, -1.1324],\n",
            "        [ 0.9482, -1.0683],\n",
            "        [-1.2567,  1.5567],\n",
            "        [-1.2074,  1.5342],\n",
            "        [ 0.9959, -1.0150],\n",
            "        [ 0.7638, -0.8396],\n",
            "        [-0.7605,  1.1538],\n",
            "        [-0.9427,  1.3195],\n",
            "        [ 1.0836, -1.2524],\n",
            "        [ 1.3405, -1.5818],\n",
            "        [-1.1175,  1.4732],\n",
            "        [ 0.0944,  0.1137],\n",
            "        [ 0.0364, -0.0417],\n",
            "        [-0.4159,  0.6194],\n",
            "        [-1.1154,  1.5288],\n",
            "        [ 0.2062,  0.0697],\n",
            "        [ 0.6173, -0.5517]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.3732,  0.6998],\n",
            "        [-0.3201,  0.5974],\n",
            "        [-0.5237,  0.7098],\n",
            "        [-1.0103,  1.4114],\n",
            "        [-0.6083,  1.0398],\n",
            "        [ 0.6428, -0.5678],\n",
            "        [-0.6210,  1.0641],\n",
            "        [ 0.4125, -0.2607],\n",
            "        [ 0.3556, -0.1185],\n",
            "        [-1.0878,  1.5592],\n",
            "        [-0.7257,  1.2051],\n",
            "        [-1.1703,  1.4531],\n",
            "        [-0.3744,  0.6704],\n",
            "        [-1.0568,  1.4815],\n",
            "        [-0.7321,  1.0252],\n",
            "        [-1.2363,  1.5689],\n",
            "        [ 0.7384, -0.8669],\n",
            "        [-0.0506,  0.3158],\n",
            "        [ 0.7161, -0.5541],\n",
            "        [-1.1953,  1.6025],\n",
            "        [-0.3011,  0.5465],\n",
            "        [-0.4254,  0.6832],\n",
            "        [ 0.4749, -0.6205],\n",
            "        [-1.1281,  1.4511],\n",
            "        [-0.9091,  1.3129],\n",
            "        [-1.1920,  1.5267],\n",
            "        [ 0.2266,  0.1471],\n",
            "        [ 0.4794, -0.5179],\n",
            "        [-0.0694,  0.1627],\n",
            "        [-0.8922,  1.2803],\n",
            "        [-0.8524,  1.2710],\n",
            "        [ 0.7446, -0.7690]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 8.4421e-01, -8.5564e-01],\n",
            "        [-6.1127e-01,  9.8954e-01],\n",
            "        [-1.2128e+00,  1.5778e+00],\n",
            "        [-1.1397e+00,  1.4505e+00],\n",
            "        [ 6.3770e-01, -5.6673e-01],\n",
            "        [-1.0713e+00,  1.4318e+00],\n",
            "        [-1.2363e+00,  1.5896e+00],\n",
            "        [-8.2468e-03,  4.9994e-01],\n",
            "        [ 2.4673e-01, -3.5372e-01],\n",
            "        [-7.2506e-01,  1.0172e+00],\n",
            "        [-1.3116e+00,  1.6634e+00],\n",
            "        [-1.5435e-01,  4.0770e-01],\n",
            "        [ 1.0083e+00, -1.1615e+00],\n",
            "        [ 1.3276e-01,  8.6898e-02],\n",
            "        [-9.0887e-01,  1.3557e+00],\n",
            "        [-1.1697e-01,  3.8191e-01],\n",
            "        [ 2.2057e-01, -1.2425e-03],\n",
            "        [-1.2121e+00,  1.6105e+00],\n",
            "        [-4.8344e-01,  7.4085e-01],\n",
            "        [ 5.0575e-01, -2.7057e-01],\n",
            "        [-7.9967e-01,  1.0006e+00],\n",
            "        [-1.1165e+00,  1.4570e+00],\n",
            "        [ 2.9286e-01, -1.6188e-01],\n",
            "        [ 1.5037e-01,  8.9140e-02],\n",
            "        [-2.3702e-01,  4.3513e-01],\n",
            "        [-5.8226e-01,  8.0296e-01],\n",
            "        [-1.0793e+00,  1.4337e+00],\n",
            "        [-1.5595e-01,  5.1053e-02],\n",
            "        [ 1.1914e+00, -1.3885e+00],\n",
            "        [ 8.8709e-01, -9.8970e-01],\n",
            "        [-1.0999e+00,  1.4822e+00],\n",
            "        [-3.1088e-01,  4.4613e-01]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.6751,  0.8208],\n",
            "        [-0.4334,  0.4809],\n",
            "        [ 0.9850, -1.1468],\n",
            "        [ 0.9740, -1.2147],\n",
            "        [-0.7147,  1.1990],\n",
            "        [-0.9754,  1.3797],\n",
            "        [-0.5459,  0.9890],\n",
            "        [ 0.9390, -1.1217],\n",
            "        [ 0.0772,  0.0705],\n",
            "        [-1.2816,  1.6290],\n",
            "        [ 0.2061, -0.0542],\n",
            "        [ 0.3195,  0.0373],\n",
            "        [-1.2238,  1.5839],\n",
            "        [-0.0349,  0.3560],\n",
            "        [-0.4180,  0.6510],\n",
            "        [ 0.6151, -0.4593],\n",
            "        [-0.8546,  1.3000],\n",
            "        [-0.8420,  1.3644],\n",
            "        [ 0.3008, -0.1859],\n",
            "        [-0.2370,  0.4831],\n",
            "        [ 1.1023, -1.3047],\n",
            "        [-0.2017,  0.4179],\n",
            "        [-1.1487,  1.4667],\n",
            "        [-0.5476,  0.6482],\n",
            "        [-0.7360,  1.0967],\n",
            "        [ 0.6332, -0.6343],\n",
            "        [-0.4598,  0.6668],\n",
            "        [-1.1219,  1.4116],\n",
            "        [-0.3247,  0.5277],\n",
            "        [-0.8319,  1.1582],\n",
            "        [-0.9217,  1.2910],\n",
            "        [-0.6604,  0.8652]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.9409,  1.3263],\n",
            "        [-0.4070,  0.8431],\n",
            "        [ 0.9945, -1.1952],\n",
            "        [-0.8561,  1.3031],\n",
            "        [ 0.6827, -0.6627],\n",
            "        [-0.4328,  0.6640],\n",
            "        [-0.7621,  1.0152],\n",
            "        [-0.7670,  1.2330],\n",
            "        [ 1.0765, -1.1881],\n",
            "        [-0.5450,  0.9781],\n",
            "        [-1.1743,  1.5466],\n",
            "        [-1.0739,  1.3939],\n",
            "        [ 0.2162,  0.1388],\n",
            "        [ 0.8293, -0.8055],\n",
            "        [-1.2267,  1.5503],\n",
            "        [ 0.8172, -0.8864],\n",
            "        [-1.1104,  1.4763],\n",
            "        [-0.4962,  1.0387],\n",
            "        [ 0.6695, -0.5900],\n",
            "        [ 0.7036, -0.7828],\n",
            "        [-0.1000,  0.4159],\n",
            "        [-0.4003,  0.7111],\n",
            "        [-0.9102,  1.2573],\n",
            "        [ 1.2485, -1.4103],\n",
            "        [ 0.6233, -0.6641],\n",
            "        [-0.8942,  1.2785],\n",
            "        [ 0.8405, -0.9181],\n",
            "        [ 0.4426, -0.4976],\n",
            "        [-0.0861,  0.3667],\n",
            "        [ 0.7856, -1.0104],\n",
            "        [-0.9641,  1.2345],\n",
            "        [-0.4991,  0.8578]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.4739, -0.4770],\n",
            "        [-0.4910,  0.8977],\n",
            "        [-1.0033,  1.3047],\n",
            "        [-0.0906,  0.2563],\n",
            "        [ 0.1009, -0.1251],\n",
            "        [-1.1094,  1.5496],\n",
            "        [-1.1477,  1.5370],\n",
            "        [ 1.0529, -1.2217],\n",
            "        [-0.4044,  0.6688],\n",
            "        [-1.0105,  1.4635],\n",
            "        [-0.6908,  0.9702],\n",
            "        [ 0.6389, -0.7255],\n",
            "        [-0.0663,  0.4672],\n",
            "        [ 1.3472, -1.6254],\n",
            "        [-0.2872,  0.6767],\n",
            "        [ 0.6077, -0.6369],\n",
            "        [ 0.7506, -0.7140],\n",
            "        [ 0.8697, -1.0202],\n",
            "        [-0.6394,  0.9258],\n",
            "        [-1.1550,  1.4817],\n",
            "        [ 0.4837, -0.2214],\n",
            "        [ 0.5527, -0.6612],\n",
            "        [ 0.0778, -0.0820],\n",
            "        [-1.1986,  1.5864],\n",
            "        [-0.5589,  0.9791],\n",
            "        [ 0.8182, -0.9333],\n",
            "        [-0.5730,  0.8334],\n",
            "        [-0.4800,  0.6886],\n",
            "        [ 0.8472, -0.9196],\n",
            "        [-0.3565,  0.8236],\n",
            "        [-0.0960,  0.1812],\n",
            "        [-0.1422,  0.5147]], device='cuda:0')\n",
            "dev_logits:  tensor([[ 0.3220, -0.1910],\n",
            "        [-0.1862,  0.5993],\n",
            "        [-0.9345,  1.1679],\n",
            "        [-0.6912,  0.9431],\n",
            "        [-0.4780,  0.7225],\n",
            "        [-1.2530,  1.4960],\n",
            "        [ 0.1768,  0.1533],\n",
            "        [-0.9101,  1.1819],\n",
            "        [ 1.1136, -1.3039],\n",
            "        [-0.6771,  1.1096],\n",
            "        [ 1.1117, -1.3037],\n",
            "        [ 0.3139, -0.1037],\n",
            "        [-0.7650,  1.1711],\n",
            "        [ 0.6040, -0.5729],\n",
            "        [-0.3593,  0.4010],\n",
            "        [-0.5057,  0.8024],\n",
            "        [ 1.0299, -1.2330],\n",
            "        [ 0.0995,  0.0806],\n",
            "        [ 0.0307,  0.3665],\n",
            "        [-0.6098,  0.8722],\n",
            "        [-0.9809,  1.2899],\n",
            "        [-1.2165,  1.5502],\n",
            "        [-0.8785,  1.2600],\n",
            "        [ 1.3007, -1.5876],\n",
            "        [ 1.2470, -1.3965],\n",
            "        [-0.4817,  0.9330],\n",
            "        [-0.8678,  1.3098],\n",
            "        [-1.3520,  1.6468],\n",
            "        [-0.9379,  1.3787],\n",
            "        [-0.3198,  0.5958],\n",
            "        [ 0.9100, -1.1402],\n",
            "        [-0.7614,  1.1778]], device='cuda:0')\n",
            "dev_logits:  tensor([[-0.0610,  0.3905],\n",
            "        [ 0.5596, -0.5410],\n",
            "        [-1.2337,  1.5565],\n",
            "        [ 0.6729, -0.5710],\n",
            "        [ 1.0086, -1.1951],\n",
            "        [-1.1863,  1.5469],\n",
            "        [-1.0486,  1.3159],\n",
            "        [ 0.6850, -0.6298],\n",
            "        [-0.0771,  0.1370],\n",
            "        [-0.5170,  0.9807],\n",
            "        [-1.2493,  1.6108],\n",
            "        [-0.8395,  1.0609],\n",
            "        [-0.9836,  1.3529],\n",
            "        [-1.0992,  1.4959],\n",
            "        [-0.5715,  0.8153],\n",
            "        [-0.4201,  0.7281],\n",
            "        [-0.2610,  0.6230],\n",
            "        [-1.1327,  1.5442],\n",
            "        [ 0.1592,  0.3111],\n",
            "        [ 0.9163, -1.1551],\n",
            "        [ 0.3129,  0.0171],\n",
            "        [ 0.6891, -0.6661],\n",
            "        [ 0.7020, -0.6444],\n",
            "        [-0.9672,  1.2816],\n",
            "        [-0.3492,  0.5504],\n",
            "        [-1.0567,  1.3854],\n",
            "        [ 1.1755, -1.3056],\n",
            "        [ 0.8717, -0.9247],\n",
            "        [ 1.1767, -1.4244],\n",
            "        [-1.2252,  1.5945],\n",
            "        [ 0.5348, -0.5367],\n",
            "        [-0.2816,  0.5902]], device='cuda:0')\n",
            "dev_logits:  tensor([[-2.1706e-01,  6.2565e-01],\n",
            "        [-1.2509e+00,  1.6601e+00],\n",
            "        [-3.5541e-02,  7.0787e-02],\n",
            "        [-7.9941e-02,  4.1276e-01],\n",
            "        [ 6.9613e-01, -5.4086e-01],\n",
            "        [ 9.6562e-01, -1.0923e+00],\n",
            "        [ 1.0147e+00, -1.0975e+00],\n",
            "        [-5.4061e-01,  6.5165e-01],\n",
            "        [-1.0284e+00,  1.4159e+00],\n",
            "        [-3.6933e-01,  7.1536e-01],\n",
            "        [-5.5748e-01,  8.9870e-01],\n",
            "        [-7.8943e-01,  1.1836e+00],\n",
            "        [ 8.2977e-04,  3.7028e-01],\n",
            "        [ 6.9845e-01, -9.9825e-01],\n",
            "        [-1.0285e+00,  1.3850e+00],\n",
            "        [-1.1515e+00,  1.4071e+00],\n",
            "        [-1.0777e+00,  1.4428e+00],\n",
            "        [ 2.8869e-01,  9.1392e-03],\n",
            "        [-1.1277e+00,  1.5551e+00],\n",
            "        [-1.0578e+00,  1.4425e+00],\n",
            "        [-1.1965e+00,  1.5350e+00],\n",
            "        [-8.2683e-01,  1.3152e+00],\n",
            "        [ 1.1096e+00, -1.0904e+00],\n",
            "        [ 8.9437e-01, -8.2652e-01],\n",
            "        [-1.1782e-01,  4.9160e-01],\n",
            "        [ 5.8495e-01, -9.1434e-01],\n",
            "        [-6.3287e-01,  8.9154e-01],\n",
            "        [ 6.4299e-02,  4.4928e-02],\n",
            "        [ 5.4161e-01, -4.7907e-01],\n",
            "        [ 9.2065e-01, -1.1017e+00],\n",
            "        [-6.0176e-01,  8.0995e-01],\n",
            "        [-1.2780e+00,  1.6502e+00]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.2207,  1.5734],\n",
            "        [-0.3931,  0.8560],\n",
            "        [ 0.4528, -0.2863],\n",
            "        [ 0.2103, -0.2262],\n",
            "        [-1.2571,  1.5821],\n",
            "        [-1.1873,  1.5451],\n",
            "        [ 0.7083, -0.8136],\n",
            "        [-1.2061,  1.5593],\n",
            "        [ 0.8159, -0.6627],\n",
            "        [ 0.4515, -0.2472],\n",
            "        [-0.3875,  0.4398],\n",
            "        [ 0.7793, -0.7117],\n",
            "        [-0.9392,  1.1114],\n",
            "        [-1.0342,  1.5299],\n",
            "        [ 0.0247,  0.1560],\n",
            "        [ 0.7697, -0.7990],\n",
            "        [-0.6563,  0.8384],\n",
            "        [ 0.0565,  0.2881],\n",
            "        [-0.6246,  1.1286],\n",
            "        [ 1.0214, -1.2232],\n",
            "        [ 0.6249, -0.5043],\n",
            "        [ 1.0868, -1.1325],\n",
            "        [-0.6655,  0.8916],\n",
            "        [-0.3016,  0.6162],\n",
            "        [ 0.7290, -0.8149],\n",
            "        [-1.0210,  1.3812],\n",
            "        [ 1.2749, -1.5574],\n",
            "        [-1.0079,  1.4137],\n",
            "        [-0.6687,  1.1430],\n",
            "        [-1.0756,  1.5449],\n",
            "        [-1.0361,  1.2372],\n",
            "        [-0.8925,  1.1528]], device='cuda:0')\n",
            "dev_logits:  tensor([[-1.2659,  1.5867],\n",
            "        [-1.1721,  1.4620],\n",
            "        [-1.1998,  1.5277],\n",
            "        [ 1.2167, -1.4299],\n",
            "        [ 1.1907, -1.4562],\n",
            "        [-0.8438,  1.1785],\n",
            "        [-0.2284,  0.5419],\n",
            "        [-0.1015,  0.3012],\n",
            "        [-1.2661,  1.6028],\n",
            "        [ 0.4633, -0.2648],\n",
            "        [-0.0173, -0.0209],\n",
            "        [ 0.7313, -0.9687],\n",
            "        [-1.1528,  1.4951],\n",
            "        [ 0.4721, -0.1501],\n",
            "        [ 0.5776, -0.4447],\n",
            "        [-0.7192,  1.1150]], device='cuda:0')\n",
            "  Accuracy: 0.65\n",
            "  Development Loss: 0.72\n",
            "  Development took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:22 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybJX8-lt-88x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a0dbab37-62df-49b7-b9e3-2577939e55a4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display floats with two decimal places (regardless of the above codes)\n",
        "pd.set_option('display.precision', 3)\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Dev. Loss  Dev. Accur. Training Time Development Time\n",
              "epoch                                                                      \n",
              "1              0.633      0.651        0.614       0:01:46          0:00:05\n",
              "2              0.605      0.644        0.644       0:01:47          0:00:04\n",
              "3              0.520      0.684        0.640       0:01:46          0:00:04\n",
              "4              0.461      0.724        0.646       0:01:46          0:00:04"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-923a1156-a4b8-4b26-a91d-529177a1a054\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Dev. Loss</th>\n",
              "      <th>Dev. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Development Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.633</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0:01:46</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.605</td>\n",
              "      <td>0.644</td>\n",
              "      <td>0.644</td>\n",
              "      <td>0:01:47</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.520</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0:01:46</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.461</td>\n",
              "      <td>0.724</td>\n",
              "      <td>0.646</td>\n",
              "      <td>0:01:46</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-923a1156-a4b8-4b26-a91d-529177a1a054')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-923a1156-a4b8-4b26-a91d-529177a1a054 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-923a1156-a4b8-4b26-a91d-529177a1a054');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-318a87ae-ba5d-43c7-bd87-70a2a0f5c2bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-318a87ae-ba5d-43c7-bd87-70a2a0f5c2bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-318a87ae-ba5d-43c7-bd87-70a2a0f5c2bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_stats",
              "summary": "{\n  \"name\": \"df_stats\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07898418067681992,\n        \"min\": 0.46073750566908533,\n        \"max\": 0.6330924162442535,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6052140701464724,\n          0.46073750566908533,\n          0.6330924162442535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dev. Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.036658716988360256,\n        \"min\": 0.64415840851143,\n        \"max\": 0.7240697061643004,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.64415840851143,\n          0.7240697061643004,\n          0.6505706943571568\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dev. Accur.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014879898760598172,\n        \"min\": 0.61376953125,\n        \"max\": 0.64599609375,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6435546875,\n          0.64599609375,\n          0.61376953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0:01:47\",\n          \"0:01:46\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Development Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0:00:04\",\n          \"0:00:05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training Complete!\\nTotal training took {format_time(time.time()-total_t0):} (h:mm:ss)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUof_9NIIvQy",
        "outputId": "e1e50e46-113a-43fa-b869-be5f9b886e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Complete!\n",
            "Total training took 0:36:42 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdhAzaKIA2Rd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "675ab3ac-1e54-4510-e569-a38cbc14b9c1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# seaborn 사용하여 plot 생성\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# plot 사이즈 & 폰트 사이즈 지정\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Dev. Loss'], 'g-o', label=\"Development\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Development Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKP-Nb6yD9GV"
      },
      "source": [
        "### Test 데이터 검증\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_jOYx9qDrwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bddb5e9-bfdc-4e91-f0c6-42f5a8501c0d"
      },
      "source": [
        "# # Test 데이터 셋 array화\n",
        "# dataset_dev = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Grammar_Detection/NIKL_CoLA_dev.tsv\", delimiter = '\\t', header = None, names = ['sentence_source_dev', 'label_dev', 'lable_notes_dev', 'sentence_dev'])\n",
        "# print(dataset_dev)\n",
        "\n",
        "# # 문장 개수 확인\n",
        "# print('Number of test sentences: {:,}\\n'.format(dataset_dev.shape[0]))\n",
        "\n",
        "# # Create sentence and lists\n",
        "# sentences_dev = dataset_dev.sentence_dev.values\n",
        "# sentences_dev = sentences_dev[1:]\n",
        "# labels_dev = dataset_dev.label_dev.values\n",
        "# labels_dev = labels_dev[1:]\n",
        "# labels_dev = labels_dev.astype(np.int64) # 라벨 정수화\n",
        "# print(sentences_dev)\n",
        "\n",
        "\n",
        "# # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "# input_ids_dev = []\n",
        "# attention_masks_dev = []\n",
        "\n",
        "# # For every sentence...\n",
        "# for sent in sentences_dev:\n",
        "#     # `encode_plus` will:\n",
        "#     #   (1) Tokenize the sentence.\n",
        "#     #   (2) Prepend the `[CLS]` token to the start.\n",
        "#     #   (3) Append the `[SEP]` token to the end.\n",
        "#     #   (4) Map tokens to their IDs.\n",
        "#     #   (5) Pad or truncate the sentence to `max_length`\n",
        "#     #   (6) Create attention masks for [PAD] tokens.\n",
        "#     encoded_dict = tokenizer.encode_plus(\n",
        "#                         sent,                      # Sentence to encode.\n",
        "#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "#                         max_length = 64,           # Pad & truncate all sentences.\n",
        "#                         padding = 'max_length',\n",
        "#                         truncation = True,\n",
        "#                         return_attention_mask = True,   # Construct attn. masks.\n",
        "#                         return_tensors = 'pt',     # Return pytorch tensors.\n",
        "#                    )\n",
        "\n",
        "#     # Add the encoded sentence to the list.\n",
        "#     input_ids_dev.append(encoded_dict['input_ids'])\n",
        "\n",
        "#     # And its attention mask (simply differentiates padding from non-padding).\n",
        "#     attention_masks_dev.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# # Convert the lists into tensors.\n",
        "# input_ids_dev = torch.cat(input_ids_dev, dim=0)\n",
        "# attention_masks_dev = torch.cat(attention_masks_dev, dim=0)\n",
        "# labels_dev = torch.Tensor(labels_dev)\n",
        "\n",
        "# print('Dev_Original: ', sentences_dev[0]) # 1차원\n",
        "# print('Dev_Token IDs: {}, \\nDev_input_ids_shape: {}, \\nDev_input_ids_dim: {}'.format(input_ids_dev[0], input_ids_dev.shape, input_ids_dev.ndim))\n",
        "# print('Dev_labels: {}, \\nDev_labels_shape: {}, \\nDev_labels_dim: {}'.format(labels_dev, labels_dev.shape, labels_dev.ndim))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sentence_source_dev            label_dev    lable_notes_dev  \\\n",
            "0                 source  acceptability_label  source_annotation   \n",
            "1                 T00002                    0                  *   \n",
            "2                 T00029                    1                NaN   \n",
            "3                 T00033                    0                  *   \n",
            "4                 T00036                    0                  *   \n",
            "...                  ...                  ...                ...   \n",
            "2028              T09986                    1                NaN   \n",
            "2029              T09990                    1                NaN   \n",
            "2030              T09994                    0                  *   \n",
            "2031              T09997                    1                NaN   \n",
            "2032              T10000                    0                  *   \n",
            "\n",
            "                              sentence_dev  \n",
            "0                                 sentence  \n",
            "1                            실없는 사람이 까불한다.  \n",
            "2                순희에게는 아무리 좋은 옷도 어울리지 않는다.  \n",
            "3                        사람은 언제나 젊는 수는 없다.  \n",
            "4     나는 등산이 힘들다는 진실을 모르고 산에 따라갔다가 고생만 했다.  \n",
            "...                                    ...  \n",
            "2028                             날씨가 풀리었다.  \n",
            "2029                      순이가 영수한테 팔이 잡혔다.  \n",
            "2030                    밤새 그 술을 다 먹었는 것이다.  \n",
            "2031               학교에서 철수는 놀았고, 순이는 공부했다.  \n",
            "2032                 그의 부주의에 말미암아 사건이 터졌다.  \n",
            "\n",
            "[2033 rows x 4 columns]\n",
            "Number of test sentences: 2,033\n",
            "\n",
            "['실없는 사람이 까불한다.' '순희에게는 아무리 좋은 옷도 어울리지 않는다.' '사람은 언제나 젊는 수는 없다.' ...\n",
            " '밤새 그 술을 다 먹었는 것이다.' '학교에서 철수는 놀았고, 순이는 공부했다.' '그의 부주의에 말미암아 사건이 터졌다.']\n",
            "Dev_Original:  실없는 사람이 까불한다.\n",
            "Dev_Token IDs: tensor([   2, 3036, 6882, 2589,  517, 5591, 6424, 7831,   54,    3,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1]), \n",
            "Dev_input_ids_shape: torch.Size([2032, 64]), \n",
            "Dev_input_ids_dim: 2\n",
            "Dev_labels: tensor([0., 1., 0.,  ..., 0., 1., 0.]), \n",
            "Dev_labels_shape: torch.Size([2032]), \n",
            "Dev_labels_dim: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeRLralHkqOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8ae7d9-da5b-4d0e-e636-3d6b5f755f1a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} dev sentences...'.format(len(input_ids_dev)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  dev_logits = outputs[0]\n",
        "  # print(\"dev_logits: \", dev_logits)\n",
        "  # dev_preds = torch.argmax(torch.nn.functional.log_softmax(dev_logits,dim=1), dim=1)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  dev_logits = dev_logits.to('cpu').numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy().astype(np.int64)\n",
        "  dev_logits = dev_logits.tolist()\n",
        "  label_ids = label_ids.tolist()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(dev_logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "print(\"Predictions: \", predictions)\n",
        "print(\"True_labels: \", true_labels)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,032 dev sentences...\n",
            "Predictions:  [[[-0.5440900921821594, 0.7604565620422363], [-0.6366633772850037, 0.883903443813324], [0.9504691362380981, -0.8344037532806396], [-0.8265974521636963, 0.9448611736297607], [-0.5388743281364441, 0.7245370149612427], [0.906873345375061, -0.691264271736145], [-0.03731789067387581, 0.3464967906475067], [-0.4156523048877716, 0.6740354895591736], [-0.6725124716758728, 0.8856978416442871], [0.8152270913124084, -0.8461727499961853], [0.039695896208286285, 0.09380380809307098], [-1.1282413005828857, 1.0753147602081299], [-0.640638530254364, 0.8436546921730042], [-0.4983147978782654, 0.5973384976387024], [-0.2673923969268799, 0.4611343741416931], [0.845350980758667, -0.6441733837127686], [0.2587580978870392, 0.013214417733252048], [0.48228734731674194, -0.3857894241809845], [-0.15357869863510132, 0.32100576162338257], [-0.08528336137533188, 0.15245434641838074], [0.27799245715141296, 0.13311707973480225], [0.9178853034973145, -0.6604626774787903], [0.15196719765663147, 0.12687884271144867], [0.43209120631217957, -0.20357608795166016], [-0.560158371925354, 0.806786298751831], [0.3066714406013489, -0.16162416338920593], [-0.473632276058197, 0.7014603018760681], [-0.4277993440628052, 0.6297873258590698], [0.34631308913230896, -0.2975274324417114], [-0.9840128421783447, 0.8547818064689636], [-1.0516828298568726, 1.079056739807129], [0.9256165027618408, -0.8577197194099426]], [[0.9923861026763916, -0.8015137910842896], [-0.7135761976242065, 0.9584362506866455], [-0.6942639350891113, 0.8473489284515381], [-0.6738757491111755, 0.7751575708389282], [-0.8063123822212219, 0.9900689125061035], [-0.22803758084774017, 0.5188574194908142], [0.2665196657180786, -0.10735074430704117], [0.5758488178253174, -0.5589287281036377], [-0.08843182027339935, 0.24567976593971252], [-0.04521670565009117, 0.3689069151878357], [-0.020640121772885323, 0.03125961124897003], [-0.2983754873275757, 0.3613196909427643], [-0.5818466544151306, 0.7290335297584534], [0.6799868941307068, -0.3645533323287964], [0.09631427377462387, 0.14401665329933167], [0.5195565223693848, -0.26875799894332886], [-0.07790882140398026, 0.25260257720947266], [0.9185310006141663, -0.8534088134765625], [0.867634117603302, -0.7508019208908081], [-0.8338456749916077, 0.9251871109008789], [0.4934490919113159, -0.25546813011169434], [0.6821221709251404, -0.5629751086235046], [-1.0446763038635254, 1.1453607082366943], [0.9662392139434814, -0.8724552392959595], [-0.9824398756027222, 0.9505742192268372], [-1.0712238550186157, 1.0489071607589722], [-0.7148199081420898, 0.8848488926887512], [-0.18711712956428528, 0.4165797829627991], [-0.28210726380348206, 0.5164773464202881], [-0.4453302025794983, 0.6150250434875488], [-0.9265776872634888, 1.0118365287780762], [-0.19152040779590607, 0.30487164855003357]], [[0.14295953512191772, 0.10523873567581177], [-0.7713683247566223, 0.8693787455558777], [0.01815454103052616, 0.2658226788043976], [-0.46047985553741455, 0.6918138861656189], [-0.502471923828125, 0.7396768927574158], [0.7280952334403992, -0.5369008779525757], [0.6607030630111694, -0.4617462754249573], [0.2779879868030548, -0.16549064218997955], [-0.8552318811416626, 0.9295988082885742], [-1.057819128036499, 0.947079062461853], [-0.49317264556884766, 0.7195528745651245], [-0.8358964323997498, 0.8834695219993591], [0.7596861124038696, -0.5939494371414185], [-0.7115239500999451, 0.807265043258667], [-0.17544257640838623, 0.3740421235561371], [-0.25122183561325073, 0.5424134135246277], [-0.39082038402557373, 0.6465872526168823], [-0.9701409935951233, 1.080401062965393], [0.11551941931247711, 0.09370698779821396], [0.4139849543571472, -0.14893147349357605], [0.2619837820529938, -0.031642455607652664], [-0.5525091290473938, 0.796583890914917], [-1.079677700996399, 1.0594451427459717], [0.4882509112358093, -0.3095964193344116], [-0.31359443068504333, 0.440647691488266], [-0.603087306022644, 0.809704065322876], [0.36312100291252136, -0.19889572262763977], [-0.9249717593193054, 0.8083029985427856], [-0.16450540721416473, 0.48536115884780884], [0.9053236246109009, -0.8337474465370178], [-0.205024853348732, 0.40380406379699707], [0.9469200968742371, -0.9094624519348145]], [[0.8994646072387695, -0.9170271158218384], [-0.6895142197608948, 0.7715346813201904], [0.8986701965332031, -0.7151367664337158], [-0.2894172668457031, 0.5719497203826904], [-0.7297326326370239, 0.8637973070144653], [-0.9330407381057739, 1.0509496927261353], [0.18998490273952484, 0.059850022196769714], [0.410792738199234, -0.4122063219547272], [-0.9982976317405701, 0.8272385597229004], [-0.37605997920036316, 0.6206943988800049], [-0.36520469188690186, 0.6470986008644104], [0.8639690279960632, -0.7142254114151001], [0.09824962913990021, 0.12925003468990326], [-0.6213464736938477, 0.749428927898407], [-0.04112878069281578, 0.2966914772987366], [-0.6649792790412903, 0.721308171749115], [-0.9970440864562988, 0.9994363784790039], [-1.057045817375183, 0.9853651523590088], [0.40685781836509705, -0.38066229224205017], [-1.0642002820968628, 0.9513244032859802], [-0.21849776804447174, 0.4543980062007904], [-1.0241320133209229, 1.0350475311279297], [-0.8801442980766296, 0.8686737418174744], [0.8977781534194946, -0.6513999700546265], [-1.0376337766647339, 0.9883580207824707], [1.0027910470962524, -0.876106321811676], [0.9024989008903503, -0.7127035856246948], [0.5366854071617126, -0.20561009645462036], [0.7689781188964844, -0.6872609853744507], [-0.9478050470352173, 0.9393414258956909], [-0.2709924578666687, 0.45224469900131226], [-0.44565656781196594, 0.6902217864990234]], [[-0.5293204188346863, 0.7633237242698669], [-1.1205898523330688, 1.0244646072387695], [-1.117991328239441, 1.040431022644043], [-0.09520336985588074, 0.2139609009027481], [1.0350425243377686, -0.9222737550735474], [-1.1439359188079834, 1.081497311592102], [0.20306789875030518, 0.007711087353527546], [-1.0704777240753174, 1.0113959312438965], [-0.6457403302192688, 0.7444243431091309], [-0.9261274337768555, 0.9714868664741516], [-0.18067166209220886, 0.3783439099788666], [0.3543693423271179, -0.05971919745206833], [-0.3285388946533203, 0.540158212184906], [-0.5959117412567139, 0.7458446025848389], [-0.36116084456443787, 0.5278785228729248], [-1.070249080657959, 1.0404311418533325], [-0.8148585557937622, 0.8966125249862671], [-0.766677975654602, 0.7638355493545532], [-0.2547760009765625, 0.35893020033836365], [-0.3298044204711914, 0.4931321144104004], [-0.38378801941871643, 0.5388233661651611], [-0.6731621623039246, 0.8119847774505615], [-0.8766490817070007, 0.9804131984710693], [0.9712861180305481, -0.9490222930908203], [-0.9529510736465454, 1.0812774896621704], [-0.919062077999115, 1.0312514305114746], [-0.058638036251068115, 0.35984161496162415], [-0.2028350681066513, 0.4898919463157654], [0.6519742608070374, -0.4327162504196167], [-0.9819976091384888, 1.0165764093399048], [-1.0560102462768555, 1.061842679977417], [-0.896350085735321, 0.9118602871894836]], [[0.24423938989639282, 0.009930268861353397], [0.7869442701339722, -0.5683426260948181], [-0.38698625564575195, 0.6293765306472778], [-0.6563121676445007, 0.8434232473373413], [-0.6141452193260193, 0.8029770851135254], [-0.3492920994758606, 0.6310681104660034], [0.6106551885604858, -0.2817111313343048], [0.9044248461723328, -0.7258998155593872], [-0.5640735030174255, 0.6844696402549744], [0.3531511425971985, -0.07158519327640533], [-1.1258478164672852, 1.1033138036727905], [0.7675761580467224, -0.6375181674957275], [0.6689505577087402, -0.659987211227417], [-0.036702610552310944, 0.23255766928195953], [-0.9572944641113281, 1.0894521474838257], [-0.2225840985774994, 0.4986070394515991], [0.7884445190429688, -0.7232903242111206], [-0.4465460181236267, 0.582595705986023], [0.8696852326393127, -0.7384878396987915], [-0.09895628690719604, 0.4668065905570984], [-0.2798600196838379, 0.5047805309295654], [0.10285275429487228, 0.11201244592666626], [-1.0075538158416748, 0.9726586937904358], [-1.0851595401763916, 0.9647916555404663], [0.03537297621369362, 0.23140573501586914], [-1.0921205282211304, 1.0084394216537476], [0.08083271235227585, 0.18993400037288666], [-0.035580337047576904, 0.30346086621284485], [-0.46793341636657715, 0.6900732517242432], [-1.0154846906661987, 1.0345724821090698], [-0.1009884625673294, 0.28442081809043884], [0.09912918508052826, 0.06695935875177383]], [[0.7483450770378113, -0.6062843799591064], [-0.7943017482757568, 0.8492482304573059], [-0.9443506002426147, 0.9300956130027771], [-1.0538736581802368, 0.9867838621139526], [-0.5922935605049133, 0.7787685394287109], [-0.33742815256118774, 0.495647132396698], [-0.5158477425575256, 0.6487523913383484], [0.26809632778167725, -0.053261905908584595], [-0.9656887054443359, 0.8796265721321106], [-0.9726406335830688, 0.9660053849220276], [-1.1265367269515991, 1.0509727001190186], [-0.18458177149295807, 0.4582119286060333], [-0.444387823343277, 0.6578844785690308], [0.6890134811401367, -0.5307297706604004], [0.11117643117904663, 0.13291822373867035], [-0.9824128150939941, 0.9640846252441406], [-0.07186920195817947, 0.2696201801300049], [-1.0954642295837402, 1.0354397296905518], [-0.5874238014221191, 0.7062114477157593], [-0.17259187996387482, 0.4016845226287842], [-0.3258156180381775, 0.6181007027626038], [0.2865476608276367, 0.016682857647538185], [-0.1223432794213295, 0.37589266896247864], [0.2622239589691162, -0.05097850784659386], [-1.1465617418289185, 1.0593236684799194], [-1.0201084613800049, 0.9491387009620667], [-1.0791945457458496, 0.9539837837219238], [0.5252948999404907, -0.32190024852752686], [-0.8282204866409302, 0.8979278802871704], [-0.7837641835212708, 0.9215307831764221], [0.8897686004638672, -0.7108700275421143], [0.9285568594932556, -0.8483492136001587]], [[-0.9876258969306946, 1.0458487272262573], [-0.9616694450378418, 1.0770018100738525], [-1.104406714439392, 1.0313302278518677], [0.884782612323761, -0.7496054172515869], [0.25791263580322266, -0.1458166241645813], [0.5082690715789795, -0.28993871808052063], [0.18688273429870605, 0.10829837620258331], [-0.20024830102920532, 0.42508816719055176], [-0.24665291607379913, 0.4505903124809265], [-0.7087154984474182, 0.8796728849411011], [-0.4758918881416321, 0.6589568853378296], [-0.35653847455978394, 0.5943179130554199], [0.9328427910804749, -0.824398398399353], [0.30639055371284485, -0.23685362935066223], [0.6609204411506653, -0.6524519920349121], [-0.546039342880249, 0.7466827630996704], [-0.7967324256896973, 1.0199697017669678], [0.582400918006897, -0.30281364917755127], [-0.45609429478645325, 0.7192381620407104], [-1.0583890676498413, 1.1209036111831665], [-0.6447275280952454, 0.847296416759491], [1.0768977403640747, -0.9987431764602661], [-0.734026312828064, 0.8384276032447815], [-0.4344538450241089, 0.6848441362380981], [-1.0604374408721924, 0.9916263818740845], [-0.28832995891571045, 0.3581409156322479], [-0.03998219594359398, 0.31109708547592163], [-0.2521814703941345, 0.3883748948574066], [-0.2846808433532715, 0.3697906732559204], [0.10002157092094421, 0.2668278217315674], [0.682569146156311, -0.4738808870315552], [-0.1090945452451706, 0.4445483088493347]], [[-0.7970432043075562, 0.9591415524482727], [0.4795488715171814, -0.14020749926567078], [-1.016722321510315, 1.0716019868850708], [0.5471881031990051, -0.32606345415115356], [-0.5001806616783142, 0.671688973903656], [-0.9524232149124146, 0.9751061201095581], [0.35464340448379517, 0.0011251207906752825], [-0.1696513295173645, 0.3157682418823242], [0.07921682298183441, 0.0025076766032725573], [-1.0519744157791138, 0.9999642968177795], [-1.1342459917068481, 1.0115669965744019], [-1.0484243631362915, 1.112303376197815], [0.14486554265022278, 0.2648238241672516], [-0.19441014528274536, 0.3375266194343567], [0.2876788377761841, -0.008061363361775875], [-0.09374243766069412, 0.4200306832790375], [0.37568867206573486, -0.20544815063476562], [-0.4634696841239929, 0.6246984601020813], [0.7226860523223877, -0.46858400106430054], [-0.07382085174322128, 0.22168020904064178], [-0.28774917125701904, 0.4917747974395752], [-1.0179725885391235, 0.998853862285614], [-0.5488262176513672, 0.7928386926651001], [-0.5372852087020874, 0.759002685546875], [-1.0106220245361328, 1.0689194202423096], [-0.9847592711448669, 1.0785654783248901], [0.8979328870773315, -0.764759361743927], [-0.724765956401825, 0.9160047173500061], [0.2314148098230362, 0.060809552669525146], [0.17555376887321472, 0.14772796630859375], [-0.407970666885376, 0.5578993558883667], [1.1073635816574097, -1.0591531991958618]], [[-1.0311542749404907, 1.042617917060852], [-0.8393581509590149, 0.8863387107849121], [-0.14626654982566833, 0.48736459016799927], [0.7201233506202698, -0.43593624234199524], [0.10397834330797195, 0.17489098012447357], [0.07254581153392792, 0.24716076254844666], [-0.10970811545848846, 0.3168424963951111], [-1.1172524690628052, 1.1007909774780273], [-0.05034879595041275, 0.4097573459148407], [0.578250527381897, -0.35774290561676025], [-0.3106253743171692, 0.4208049476146698], [0.4286668598651886, -0.31630629301071167], [-0.8582535982131958, 0.9964813590049744], [0.0032438188791275024, 0.31307950615882874], [-0.22026856243610382, 0.5157946348190308], [0.12241623550653458, 0.1588829606771469], [-0.31359434127807617, 0.659975528717041], [0.9805207848548889, -0.9835085868835449], [-0.8441908359527588, 0.9740481972694397], [-0.4144577085971832, 0.6429541110992432], [-0.6125595569610596, 0.8013921976089478], [-0.7557045817375183, 0.7909418344497681], [-0.7463791370391846, 0.7714007496833801], [-0.8287344574928284, 0.9699685573577881], [-0.1631942242383957, 0.4559325575828552], [0.987045407295227, -0.9859631061553955], [0.46211302280426025, -0.15229232609272003], [0.8355157375335693, -0.651874303817749], [0.47929519414901733, -0.2124919444322586], [0.4883604347705841, -0.2989198565483093], [-0.2467321753501892, 0.5442653298377991], [-0.07679583877325058, 0.38858067989349365]], [[-0.36084115505218506, 0.670121431350708], [-0.3393673896789551, 0.6537014842033386], [-0.47401830554008484, 0.754672110080719], [-0.08555034548044205, 0.4542084336280823], [-0.04899192228913307, 0.43927136063575745], [0.9872043132781982, -0.8185441493988037], [0.46980729699134827, -0.2996232509613037], [-0.35450464487075806, 0.5528870224952698], [-0.8363064527511597, 0.8734207153320312], [-0.8748738765716553, 1.0234514474868774], [0.10125169903039932, 0.21875184774398804], [-0.81892991065979, 0.9619803428649902], [0.20582391321659088, 0.12014933675527573], [-0.6761429309844971, 0.9019553661346436], [0.7879921197891235, -0.774182915687561], [-0.8246356844902039, 0.8580950498580933], [-0.18016046285629272, 0.48783066868782043], [-0.2094181925058365, 0.43996477127075195], [-0.6124758124351501, 0.8037027716636658], [-0.7398146390914917, 0.7944642901420593], [-0.3426027297973633, 0.6502026319503784], [0.7758587002754211, -0.6245071887969971], [-1.1138062477111816, 1.0961923599243164], [-0.8012179136276245, 0.9141957759857178], [0.303627610206604, -0.13107529282569885], [-0.7982105016708374, 0.8702925443649292], [-1.053938627243042, 0.9393273591995239], [0.748242199420929, -0.5407145023345947], [-0.3222440183162689, 0.5378496646881104], [0.5285178422927856, -0.21784943342208862], [-1.0108075141906738, 0.9592784643173218], [-0.6732181906700134, 0.8301312923431396]], [[-1.1591429710388184, 0.9547112584114075], [0.9050939083099365, -0.7531378269195557], [-0.8136547207832336, 0.9116525650024414], [0.046723876148462296, 0.2742408514022827], [-0.021031023934483528, 0.27259188890457153], [0.706821084022522, -0.4155341386795044], [0.08320356160402298, 0.2020513415336609], [-0.11905141919851303, 0.35080042481422424], [-0.5780825614929199, 0.8752022981643677], [-0.4695247411727905, 0.6690894365310669], [-0.47056952118873596, 0.60692298412323], [-0.4559803009033203, 0.7051768898963928], [-0.8858789205551147, 1.036946415901184], [-0.40618693828582764, 0.5604742765426636], [0.7697224020957947, -0.5879255533218384], [0.1514270007610321, 0.33613312244415283], [-0.5395421981811523, 0.6528223752975464], [0.16717149317264557, 0.20923763513565063], [0.9157675504684448, -0.6974736452102661], [0.8695928454399109, -0.7041661739349365], [1.0134143829345703, -0.8826998472213745], [0.4959731996059418, -0.48733723163604736], [-0.32133057713508606, 0.6327259540557861], [0.9255284070968628, -0.8534929752349854], [-0.8374413251876831, 0.8859269618988037], [-0.899911642074585, 0.867878794670105], [-0.48980602622032166, 0.6973143815994263], [-0.8896108865737915, 0.9821605086326599], [-0.9985687136650085, 1.0228124856948853], [-0.04209568351507187, 0.18874740600585938], [-1.1045416593551636, 1.0794512033462524], [0.7360144853591919, -0.5426951050758362]], [[0.2952629327774048, -0.06489820033311844], [0.7164282202720642, -0.49586522579193115], [-0.9069066047668457, 1.020104169845581], [1.118427038192749, -1.0920988321304321], [-0.8874450922012329, 0.9050753116607666], [0.9590077996253967, -0.7331775426864624], [-0.5272141098976135, 0.781442403793335], [-0.49060195684432983, 0.6614831686019897], [-0.2019404023885727, 0.4049682915210724], [-1.1054960489273071, 1.0334413051605225], [-0.42905551195144653, 0.6846272349357605], [0.41475149989128113, -0.34734249114990234], [-1.0995973348617554, 1.1228052377700806], [-0.8246703743934631, 0.7615851163864136], [-0.9858956933021545, 1.0311154127120972], [-0.19190044701099396, 0.3735470175743103], [-0.49042314291000366, 0.7236918210983276], [0.9099814891815186, -0.6713764667510986], [-0.5830740928649902, 0.7109686732292175], [0.8526581525802612, -0.7810729742050171], [-0.31382322311401367, 0.48062580823898315], [0.7541620135307312, -0.47684839367866516], [-0.1054646447300911, 0.29165002703666687], [-0.9360325932502747, 1.0468047857284546], [-0.27493974566459656, 0.5264149308204651], [-0.449213445186615, 0.6594147682189941], [-0.5710113644599915, 0.7341538667678833], [-0.529553234577179, 0.815268874168396], [0.17964929342269897, 0.1362832486629486], [0.43608659505844116, -0.14484699070453644], [0.2798405587673187, 0.0355168841779232], [1.041033387184143, -0.8598018884658813]], [[0.43726322054862976, -0.27708950638771057], [-1.1104129552841187, 1.0518100261688232], [-0.7476543188095093, 0.8054961562156677], [-0.2706637382507324, 0.5579342842102051], [-0.6767489910125732, 0.8884403109550476], [-0.9625256061553955, 1.0686579942703247], [0.2775503993034363, -0.01571963168680668], [-0.4346625506877899, 0.6544512510299683], [0.6881765127182007, -0.4884907007217407], [-1.1528562307357788, 1.0678774118423462], [0.1328020691871643, 0.000908638583496213], [-0.5809937119483948, 0.7936656475067139], [-0.7134880423545837, 0.8936308026313782], [-1.0656355619430542, 1.0440161228179932], [-1.0624037981033325, 1.113551378250122], [-0.21290692687034607, 0.37729209661483765], [-0.393152117729187, 0.67039954662323], [0.8248689770698547, -0.7513105869293213], [-0.4073086977005005, 0.465114951133728], [0.5332340002059937, -0.2303161472082138], [-0.22122657299041748, 0.463401198387146], [0.2341960072517395, -0.05365852266550064], [0.8149939775466919, -0.7304322123527527], [-0.30349230766296387, 0.39654672145843506], [0.5993114113807678, -0.3263564109802246], [-0.30945509672164917, 0.5518172979354858], [-0.27512967586517334, 0.5356675982475281], [-0.8364930152893066, 0.9056660532951355], [-1.004654049873352, 0.919599175453186], [0.25622203946113586, -0.0911756381392479], [0.9360249638557434, -0.792827844619751], [0.3520447611808777, -0.0856688991189003]], [[1.0949150323867798, -0.9774969816207886], [0.8287390470504761, -0.6640876531600952], [0.08395995944738388, 0.19829748570919037], [-0.6953083276748657, 0.9350192546844482], [-0.3437604606151581, 0.5997962355613708], [-1.0107964277267456, 0.9798118472099304], [-0.9703987240791321, 1.0007928609848022], [-0.04531657323241234, 0.4295750856399536], [0.3212059438228607, -0.10909295827150345], [-1.0720105171203613, 1.055122971534729], [0.891933023929596, -0.7920248508453369], [-1.0647696256637573, 1.082079529762268], [-0.23778018355369568, 0.4286560118198395], [-0.2902352213859558, 0.5089753866195679], [-0.4776214063167572, 0.5993432998657227], [-0.38035285472869873, 0.6064078211784363], [-0.3580487072467804, 0.5488483905792236], [0.51540207862854, -0.44142746925354004], [-0.8587892055511475, 1.0260047912597656], [-0.02375088445842266, 0.3930726647377014], [0.8782874345779419, -0.7279645204544067], [-0.7908914089202881, 0.9799518585205078], [-1.1034317016601562, 0.986542820930481], [0.6823469400405884, -0.47697481513023376], [0.8804605007171631, -0.7953231334686279], [-1.0720127820968628, 1.0496350526809692], [0.2153792828321457, -0.03533947467803955], [-0.9116448163986206, 0.8754260540008545], [-0.283409059047699, 0.37422508001327515], [-1.0271196365356445, 1.1019504070281982], [-0.7980436682701111, 0.9765636920928955], [0.004323361441493034, 0.3636591136455536]], [[0.5932290554046631, -0.4792662262916565], [0.6226397752761841, -0.4510278105735779], [0.5224023461341858, -0.3331925868988037], [-0.6524626612663269, 0.700661301612854], [-0.5638430118560791, 0.7987303137779236], [-0.025986189022660255, 0.22418497502803802], [-0.8533263206481934, 0.9238213300704956], [-0.7071977853775024, 0.7899578213691711], [-1.0782212018966675, 1.0712037086486816], [0.06804763525724411, 0.2812099754810333], [-0.5898133516311646, 0.7440481781959534], [-0.8129515051841736, 0.8996989727020264], [-0.28590887784957886, 0.30777591466903687], [0.9983095526695251, -0.9447119235992432], [-0.8880780935287476, 1.0382097959518433], [-0.8216009736061096, 1.0477429628372192], [0.9180727601051331, -0.8283714056015015], [0.9384945631027222, -0.8002176284790039], [-0.2529844343662262, 0.4501345753669739], [-0.9490491151809692, 0.9861202836036682], [0.6000047922134399, -0.43859636783599854], [-0.29126840829849243, 0.5511478185653687], [-1.0850858688354492, 1.0625282526016235], [-0.8462886214256287, 1.0052934885025024], [-0.30745232105255127, 0.58076012134552], [0.4706009030342102, -0.2504003643989563], [-0.3825426995754242, 0.5190775990486145], [-0.37088853120803833, 0.5018159747123718], [1.1237995624542236, -0.9973236918449402], [-0.15921050310134888, 0.43994569778442383], [0.5311609506607056, -0.1461116373538971], [-0.8567724227905273, 0.938819169998169]], [[-0.7885823845863342, 0.9595770835876465], [0.8116332292556763, -0.6268887519836426], [-0.8537890911102295, 0.8278465270996094], [0.16732420027256012, -0.00839961227029562], [-0.2541213929653168, 0.3516477346420288], [0.9692134261131287, -0.8853336572647095], [-0.9134940505027771, 0.9768517017364502], [-0.3910006880760193, 0.6337487697601318], [1.0203239917755127, -0.8813818097114563], [-0.7048563361167908, 0.8018210530281067], [-1.0890774726867676, 1.1274152994155884], [-0.8991031646728516, 0.8967761397361755], [-0.7546180486679077, 1.0082424879074097], [0.642417311668396, -0.43805330991744995], [-0.6205852627754211, 0.6800087094306946], [-0.30188870429992676, 0.4281476140022278], [0.06201125308871269, 0.15053638815879822], [-0.12585827708244324, 0.45633411407470703], [0.32742804288864136, -0.04706081375479698], [-0.27719104290008545, 0.5225658416748047], [-0.6112223863601685, 0.4835963845252991], [-0.7623124122619629, 0.837798535823822], [-1.0154163837432861, 0.9993710517883301], [0.7241244316101074, -0.5168906450271606], [0.40046364068984985, -0.21285679936408997], [-0.823846697807312, 0.9543218612670898], [-0.9150605797767639, 0.9361129999160767], [-0.9917610287666321, 0.9508224725723267], [0.5672642588615417, -0.2851001024246216], [-0.3512495756149292, 0.48596131801605225], [0.13470406830310822, 0.22422057390213013], [1.0747175216674805, -0.9521148800849915]], [[-0.23812510073184967, 0.6016460657119751], [-0.6549400687217712, 0.8412504196166992], [0.14446809887886047, -0.0648818090558052], [0.10111257433891296, 0.09583494812250137], [0.168733149766922, -0.011339309625327587], [-0.19877633452415466, 0.4626252055168152], [-0.5659320950508118, 0.7668468952178955], [-0.19850534200668335, 0.44235411286354065], [-1.0154627561569214, 1.0128810405731201], [-0.7921673655509949, 0.8811689019203186], [-1.0411875247955322, 1.0815984010696411], [-1.1642478704452515, 1.0772422552108765], [-0.8328884840011597, 1.0181728601455688], [-0.03127642348408699, 0.2199062705039978], [-1.031680941581726, 1.0520809888839722], [0.9342058897018433, -0.843769907951355], [0.22785328328609467, 0.02937168814241886], [-0.749754786491394, 0.7946763038635254], [-0.47834205627441406, 0.6604068279266357], [0.046686407178640366, 0.1691170036792755], [-0.045800674706697464, 0.2665669322013855], [0.9499573111534119, -0.8332796096801758], [-1.0827014446258545, 1.0404709577560425], [0.9722152948379517, -0.8068142533302307], [-0.41074737906455994, 0.6974076628684998], [-0.820816159248352, 0.9886374473571777], [-0.23124855756759644, 0.31573954224586487], [-0.9490197896957397, 0.8403895497322083], [-0.2574599087238312, 0.42611777782440186], [-0.23941737413406372, 0.4383697807788849], [-0.06780412048101425, 0.29172012209892273], [0.9494748711585999, -0.7842063903808594]], [[-0.15711632370948792, 0.47788912057876587], [-0.5940585732460022, 0.7436681389808655], [-0.4265996217727661, 0.6172958612442017], [-0.24805134534835815, 0.4822918474674225], [0.9602764248847961, -0.8102970719337463], [-0.9539258480072021, 1.006024718284607], [-1.0900896787643433, 0.9721252918243408], [-0.7841771841049194, 0.8096815347671509], [-1.0130822658538818, 1.0812268257141113], [-0.9084864258766174, 0.8242405652999878], [-0.25523167848587036, 0.48838120698928833], [-0.41825738549232483, 0.6723136901855469], [-0.9355723261833191, 1.0001118183135986], [0.9544179439544678, -0.809424638748169], [0.7968602180480957, -0.5626869797706604], [-0.2417452335357666, 0.42442795634269714], [-0.3608900308609009, 0.610395073890686], [0.3920079469680786, -0.22910895943641663], [-0.43146929144859314, 0.633171558380127], [-0.915095329284668, 0.9934171438217163], [-0.34942761063575745, 0.4833853244781494], [0.8395136594772339, -0.6575881242752075], [-1.0577303171157837, 1.0580388307571411], [-0.27205055952072144, 0.4052300453186035], [-0.4742668867111206, 0.6569339036941528], [-1.084186315536499, 1.0943602323532104], [-0.27550044655799866, 0.27094578742980957], [-1.0739350318908691, 1.0633368492126465], [-0.3585736155509949, 0.6019729375839233], [-0.9573237299919128, 1.0237393379211426], [-0.16416870057582855, 0.5057029128074646], [-0.7152428030967712, 0.9046811461448669]], [[0.03256182372570038, 0.21956267952919006], [-0.43431976437568665, 0.6388742923736572], [-1.048258900642395, 1.0713495016098022], [1.0745583772659302, -0.9943491220474243], [1.0066529512405396, -0.95450359582901], [0.20758238434791565, -0.019624853506684303], [-0.7937161922454834, 0.894361138343811], [-0.8233819603919983, 0.938072144985199], [0.2656797766685486, -0.10079588741064072], [-0.5271320939064026, 0.7391753792762756], [-0.7920722365379333, 0.8922519683837891], [0.004664318636059761, 0.14017638564109802], [-0.6293594241142273, 0.812177300453186], [-0.7355248332023621, 0.7555219531059265], [-0.0024848971515893936, 0.03219833970069885], [-0.9983382225036621, 0.8371608853340149], [-0.9089613556861877, 1.0716739892959595], [-0.9625333547592163, 1.0571658611297607], [-0.9055438041687012, 1.0093563795089722], [-0.9056819081306458, 1.0361799001693726], [0.13735094666481018, -0.045326195657253265], [-0.8471964597702026, 0.9565032720565796], [-0.3043745458126068, 0.4885833263397217], [-0.11846975982189178, 0.30086955428123474], [-1.0306892395019531, 1.041244387626648], [0.36972856521606445, -0.15706224739551544], [-0.9394834637641907, 0.8853572607040405], [-0.186872661113739, 0.45570939779281616], [-0.6896451115608215, 0.6848413348197937], [1.1139287948608398, -1.129830002784729], [-1.0850087404251099, 1.0926727056503296], [-0.05664774402976036, 0.25842031836509705]], [[0.689252495765686, -0.5348310470581055], [0.5436407923698425, -0.4520706236362457], [-0.7514791488647461, 0.904006838798523], [0.36360639333724976, -0.2081068754196167], [0.4138434827327728, -0.3061102628707886], [-0.42546650767326355, 0.6341683268547058], [-0.34739285707473755, 0.5878697633743286], [-0.3336034417152405, 0.46528103947639465], [-0.9877022504806519, 1.1173884868621826], [-0.19333966076374054, 0.5502865314483643], [-1.0327563285827637, 1.0567467212677002], [-0.449298620223999, 0.6894727945327759], [-0.031828951090574265, 0.44067680835723877], [-0.6796679496765137, 0.8110959529876709], [0.5844493508338928, -0.4847984313964844], [-1.102785587310791, 0.9936826825141907], [-0.6939079761505127, 0.8816582560539246], [-0.354960560798645, 0.5630350708961487], [-0.47091343998908997, 0.682309627532959], [-1.0766122341156006, 1.0678281784057617], [-0.10770941525697708, 0.29669368267059326], [-0.7270686626434326, 0.8958799839019775], [-0.28442931175231934, 0.47157764434814453], [-0.9308599829673767, 0.9796513319015503], [-0.46243101358413696, 0.7058271765708923], [-1.0182477235794067, 1.0273605585098267], [0.32738572359085083, -0.1323154866695404], [0.695213794708252, -0.5739578008651733], [-0.11901009827852249, 0.3470562696456909], [-0.9161355495452881, 1.021663784980774], [0.559679388999939, -0.42942875623703003], [0.14147402346134186, 0.12343695014715195]], [[-0.7003099918365479, 0.8496474027633667], [0.11705400049686432, 0.02441379614174366], [0.7650871276855469, -0.7026528716087341], [0.9249586462974548, -0.7083989977836609], [-0.8990986347198486, 0.9947579503059387], [-0.7747007608413696, 0.9705568552017212], [-0.9101184606552124, 1.006425380706787], [-0.06755278259515762, 0.3107200264930725], [-0.26458632946014404, 0.3779413402080536], [0.9948519468307495, -0.9160120487213135], [-0.03184421360492706, 0.1862374097108841], [0.4152359068393707, -0.2470536231994629], [0.589756965637207, -0.2977738082408905], [-0.2791101634502411, 0.5071583986282349], [0.2596116364002228, -0.062328118830919266], [0.5912782549858093, -0.3405625820159912], [-0.8928254842758179, 0.9647234082221985], [0.7265089750289917, -0.44192612171173096], [-0.5350211262702942, 0.7607129216194153], [1.0455061197280884, -0.9671001434326172], [-0.7335556745529175, 0.681106686592102], [-1.0486807823181152, 1.0609042644500732], [0.6031574010848999, -0.41101735830307007], [-0.9078537821769714, 1.0082584619522095], [0.3813588321208954, -0.1876356154680252], [0.13324332237243652, 0.04020851105451584], [-0.11403212696313858, 0.3017303943634033], [-0.8068960905075073, 0.9196432828903198], [0.6430017948150635, -0.4837314486503601], [1.002991795539856, -0.8572255373001099], [-0.49778494238853455, 0.7051167488098145], [-0.8318331837654114, 0.8929017186164856]], [[-0.42217618227005005, 0.6131446361541748], [-0.41139841079711914, 0.6395717859268188], [0.8564798831939697, -0.6545290350914001], [0.35652559995651245, -0.17105701565742493], [-0.7748501300811768, 0.8735335469245911], [-0.26973363757133484, 0.5284548997879028], [-0.9496119022369385, 1.0542523860931396], [-1.0530544519424438, 1.0595920085906982], [-0.6269247531890869, 0.809897780418396], [-0.15013758838176727, 0.4642070233821869], [-0.7449240684509277, 0.9692181944847107], [-0.672900378704071, 0.9236837029457092], [0.19505584239959717, 0.04639263451099396], [-1.0663715600967407, 1.0879160165786743], [-1.0277196168899536, 1.0125141143798828], [0.439363956451416, -0.4049519896507263], [0.7401357889175415, -0.5439773797988892], [-0.48829084634780884, 0.6660301685333252], [-0.8242373466491699, 0.9807788133621216], [-0.6714242100715637, 0.8438947200775146], [0.9448188543319702, -0.8295575976371765], [-0.4214745759963989, 0.5246481895446777], [0.37760937213897705, -0.12198444455862045], [0.30036425590515137, -0.05249609053134918], [0.033098362386226654, 0.16666799783706665], [-1.1063876152038574, 1.0647839307785034], [0.9312676191329956, -0.7496339082717896], [-0.316706120967865, 0.5607894659042358], [-1.1007107496261597, 1.0104937553405762], [0.3690587282180786, -0.08993875235319138], [-0.39055439829826355, 0.6264691352844238], [-0.8739742040634155, 0.953615665435791]], [[-0.6221845149993896, 0.7427374124526978], [-0.26273825764656067, 0.3281846046447754], [1.0903090238571167, -0.9429272413253784], [-0.32481664419174194, 0.6310668587684631], [0.057971302419900894, 0.07311657071113586], [0.03593735024333, 0.1772886961698532], [-0.16938452422618866, 0.3821154832839966], [0.14952214062213898, 0.20001071691513062], [-0.6857351660728455, 0.820829451084137], [-0.3896228075027466, 0.65614253282547], [-1.0744295120239258, 1.0265129804611206], [0.36612528562545776, -0.1950812190771103], [0.47482961416244507, -0.2885860204696655], [-0.7764054536819458, 0.9743270874023438], [0.9125350713729858, -0.7152901291847229], [-0.5070023536682129, 0.7891104221343994], [0.12437569350004196, 0.045967262238264084], [0.7021533250808716, -0.4658443331718445], [0.47005248069763184, -0.3253815174102783], [-0.1794845014810562, 0.4188472032546997], [0.5493252277374268, -0.37188470363616943], [0.36241427063941956, -0.15388190746307373], [0.8493548035621643, -0.7609487771987915], [0.8454643487930298, -0.8374267816543579], [0.8592603206634521, -0.8182955980300903], [-0.9260228872299194, 0.9518622756004333], [0.3365476131439209, -0.0770549327135086], [-0.39493417739868164, 0.6538118124008179], [0.9874151945114136, -0.9162586331367493], [-1.0453566312789917, 1.0483680963516235], [-0.8266432881355286, 0.9099780321121216], [0.7566235065460205, -0.42661571502685547]], [[0.28301194310188293, 0.08816978335380554], [-0.42710158228874207, 0.7161917686462402], [0.9583191871643066, -0.7729960680007935], [0.2717806100845337, -0.03461439162492752], [-0.8075565099716187, 0.8211143016815186], [0.2093304693698883, 0.05649372190237045], [-0.7593530416488647, 0.9131301641464233], [0.7916104793548584, -0.680816113948822], [-1.1469873189926147, 1.0285422801971436], [-0.32835671305656433, 0.5137408375740051], [-0.2123214602470398, 0.5853909850120544], [-0.14057430624961853, 0.4278159737586975], [-0.9295896887779236, 0.908437192440033], [0.14253799617290497, 0.09912963956594467], [-0.6735988855361938, 0.9498165845870972], [-1.0977307558059692, 1.0430351495742798], [0.5449530482292175, -0.22041884064674377], [-0.7882501482963562, 1.0320384502410889], [0.9386938214302063, -0.718391478061676], [-0.797491192817688, 0.9258584380149841], [0.013544822111725807, 0.2822635769844055], [-0.7013733386993408, 0.8561941981315613], [0.7596507668495178, -0.6437265872955322], [1.0947924852371216, -1.0068303346633911], [-0.8089742064476013, 0.8327020406723022], [0.03475299850106239, 0.24139049649238586], [-0.42714741826057434, 0.5908621549606323], [-0.16717559099197388, 0.567891001701355], [-0.050556764006614685, 0.3561643958091736], [0.601432740688324, -0.49417194724082947], [0.4358399510383606, -0.20805558562278748], [-0.9217435717582703, 0.9930610656738281]], [[-0.9771589040756226, 1.0379979610443115], [-0.7960523962974548, 1.0150985717773438], [-0.1528867781162262, 0.2721858024597168], [-0.47757190465927124, 0.5524430274963379], [-0.8871251940727234, 1.0770684480667114], [-0.5948977470397949, 0.8132508397102356], [0.8815435171127319, -0.5987523198127747], [-0.26430442929267883, 0.6279592514038086], [0.04440028965473175, 0.18182875216007233], [0.40428465604782104, -0.01284762192517519], [-0.2873236835002899, 0.5427055358886719], [-0.6656309366226196, 0.842475175857544], [-0.7041264176368713, 0.8581655025482178], [-0.5864073634147644, 0.786695122718811], [0.6809003949165344, -0.41558709740638733], [-1.066372275352478, 1.0504510402679443], [0.010509755462408066, 0.25035667419433594], [0.46616658568382263, -0.20599740743637085], [-0.6433089375495911, 0.8317028284072876], [-0.1829458326101303, 0.49963638186454773], [0.004772478714585304, 0.312828928232193], [-0.7062950134277344, 0.7986253499984741], [1.0591486692428589, -0.9987411499023438], [0.282231867313385, -0.09585482627153397], [1.0014171600341797, -0.863645613193512], [-0.6219637393951416, 0.7824397683143616], [-0.15204499661922455, 0.37775951623916626], [0.8006823062896729, -0.6284220218658447], [0.7452327013015747, -0.6236714124679565], [0.38216501474380493, -0.10655797272920609], [0.463334858417511, -0.2174357771873474], [0.4188953638076782, -0.19924312829971313]], [[0.2185489684343338, -0.16785965859889984], [0.7106065154075623, -0.6636354923248291], [0.6489320993423462, -0.3822271525859833], [-0.9173049926757812, 0.9298239350318909], [-0.31761714816093445, 0.5366880893707275], [0.2619088292121887, 0.00739999208599329], [0.3773578405380249, -0.17198452353477478], [-0.22449979186058044, 0.4716743230819702], [0.8617760539054871, -0.6611583232879639], [0.6351197361946106, -0.3665553033351898], [-0.809951663017273, 0.9670818448066711], [-0.4641752243041992, 0.6297979354858398], [-0.31503087282180786, 0.5189598202705383], [-0.5026240348815918, 0.5291408896446228], [-0.5354851484298706, 0.7662057280540466], [0.22877100110054016, 0.01645529828965664], [-0.18909317255020142, 0.5134117007255554], [0.8698943257331848, -0.786063015460968], [-0.5213386416435242, 0.7301585078239441], [-0.31465521454811096, 0.6064143776893616], [0.7841368317604065, -0.766991138458252], [-0.9358558654785156, 0.9430415630340576], [0.8864181041717529, -0.7313592433929443], [-0.5933215022087097, 0.6152243614196777], [0.9337894916534424, -0.943153977394104], [-0.23880518972873688, 0.4234735071659088], [0.2029091715812683, 0.1324736773967743], [1.001155972480774, -0.8868406414985657], [-0.09348908811807632, 0.4028741121292114], [-0.34659528732299805, 0.6536611318588257], [0.8185601830482483, -0.6301820278167725], [-0.3503192663192749, 0.62494957447052]], [[-0.7196990251541138, 0.788447380065918], [0.9970889091491699, -0.9204453229904175], [-0.49687543511390686, 0.6212013959884644], [-0.9315892457962036, 1.0174225568771362], [0.5866926312446594, -0.3569357991218567], [0.25345706939697266, -0.019844895228743553], [0.05401059612631798, 0.1254732757806778], [-0.22301062941551208, 0.38738107681274414], [0.34785887598991394, -0.010536796413362026], [0.17958873510360718, 0.1492527425289154], [-0.9428045749664307, 0.9879205226898193], [-0.08696650713682175, 0.37650471925735474], [1.0411103963851929, -1.0019060373306274], [0.9909766912460327, -0.9014146327972412], [-0.8490961790084839, 0.7811423540115356], [-0.11169129610061646, 0.22879061102867126], [0.7599536180496216, -0.5906704068183899], [-0.6840740442276001, 0.8401745557785034], [0.5265975594520569, -0.4593963623046875], [-1.0427099466323853, 0.9320954084396362], [-0.64243084192276, 0.867464005947113], [-0.5924618244171143, 0.8359501361846924], [0.0029418356716632843, 0.2535540461540222], [-0.592877984046936, 0.8163453340530396], [0.8203433752059937, -0.6270323991775513], [0.7825809717178345, -0.6286901235580444], [-0.790254533290863, 0.9252859354019165], [0.033077795058488846, 0.06150176003575325], [-0.9373847246170044, 1.0303261280059814], [0.032430801540613174, 0.3065531849861145], [-0.6465468406677246, 0.731839656829834], [-0.743711531162262, 0.8805871605873108]], [[0.13695938885211945, 0.032551512122154236], [-0.19028544425964355, 0.32800930738449097], [0.007498549297451973, 0.23618054389953613], [0.7579598426818848, -0.6320044994354248], [0.7756761908531189, -0.6942970752716064], [-0.7582882046699524, 0.9153555631637573], [-0.3047209680080414, 0.539501965045929], [-0.5310103297233582, 0.7822214961051941], [-0.4327300488948822, 0.572645902633667], [-1.0295792818069458, 1.0627624988555908], [0.8822513818740845, -0.6647399663925171], [-1.0647186040878296, 1.0119580030441284], [0.9825952053070068, -0.8454210758209229], [-0.40487831830978394, 0.6052945852279663], [-0.3390349745750427, 0.4571983814239502], [-0.7762006521224976, 0.8058667778968811], [0.8475990295410156, -0.5947396159172058], [-0.5999802350997925, 0.8045732975006104], [-0.08298864215612411, 0.30737704038619995], [0.0004138777730986476, 0.14640891551971436], [-0.18269675970077515, 0.4225645065307617], [-0.6232447624206543, 0.8245798945426941], [-0.05363520607352257, 0.3290955126285553], [1.0654630661010742, -1.0100082159042358], [0.559650182723999, -0.36966684460639954], [0.9776358604431152, -0.9405502080917358], [0.4497426152229309, -0.27778494358062744], [0.2898414731025696, -0.1886831521987915], [-0.8530529737472534, 0.8847025632858276], [-0.4936707317829132, 0.6160480976104736], [0.5842509269714355, -0.5121254920959473], [-0.13862404227256775, 0.29493656754493713]], [[-0.9801380634307861, 1.0190255641937256], [0.05489953234791756, 0.2933489978313446], [-0.29823803901672363, 0.5234553217887878], [0.0949292778968811, 0.02470213919878006], [-0.2026847004890442, 0.3681212365627289], [0.966303825378418, -0.9190571308135986], [1.0060416460037231, -0.9593048095703125], [-0.10243885219097137, 0.23894546926021576], [0.2581753134727478, 0.039650626480579376], [-0.37592384219169617, 0.5186028480529785], [-0.3214852511882782, 0.6614985466003418], [-1.102807879447937, 1.0493887662887573], [-0.583899974822998, 0.7574456334114075], [0.3737773299217224, -0.18202590942382812], [-0.6126939058303833, 0.7559887170791626], [0.32019326090812683, -0.07118477672338486], [-0.6074935793876648, 0.79202800989151], [-0.6520695686340332, 0.7443954944610596], [-0.9581255316734314, 1.073421835899353], [-0.9165326356887817, 0.92120361328125], [-1.0406657457351685, 1.1010955572128296], [0.5731266736984253, -0.41764289140701294], [-0.6864544153213501, 0.8985071182250977], [-0.9699389934539795, 1.0379513502120972], [-0.9515957832336426, 1.0315653085708618], [-0.770051121711731, 0.7387017607688904], [0.6599862575531006, -0.47957339882850647], [0.4547653794288635, -0.40424931049346924], [-0.8093298673629761, 1.003043293952942], [-0.8504315614700317, 1.0247715711593628], [-0.05668947473168373, 0.12666760385036469], [-0.9193373918533325, 0.7892004251480103]], [[-0.19945433735847473, 0.5208860635757446], [-0.6732861399650574, 0.7258889675140381], [-0.3057771325111389, 0.49362170696258545], [-0.5561912059783936, 0.7146614789962769], [-0.3561285436153412, 0.5422000288963318], [-0.5036688446998596, 0.7322730422019958], [0.18136292695999146, 0.08081284165382385], [-0.3276692032814026, 0.5080858469009399], [-0.41882050037384033, 0.6018373966217041], [-0.822284460067749, 1.0604244470596313], [0.5819675326347351, -0.43782052397727966], [-1.1056970357894897, 1.1224544048309326], [-0.7744728326797485, 0.8565638065338135], [-0.03886955603957176, 0.21105259656906128], [-0.5916987657546997, 0.76414555311203], [0.3123469650745392, -0.21760454773902893], [0.2829950153827667, -0.005318823270499706], [-0.6317756772041321, 0.8232669830322266], [0.22625786066055298, 0.04382714629173279], [0.025998765602707863, 0.16021187603473663], [-0.9483126401901245, 1.0001369714736938], [0.9434952735900879, -0.8413048982620239], [-0.12675827741622925, 0.3394533395767212], [-0.6411965489387512, 0.8781698346138], [0.6388795375823975, -0.4634711444377899], [0.30018073320388794, -0.02947680465877056], [0.8546730279922485, -0.677929162979126], [-1.0654304027557373, 1.0079158544540405], [0.4128856956958771, -0.11429627984762192], [-0.2839723229408264, 0.5729601979255676], [-0.6289713382720947, 0.8536339998245239], [-0.2096584439277649, 0.4003996253013611]], [[0.2843306064605713, -0.05435321480035782], [-0.27759024500846863, 0.43450698256492615], [-0.4773769974708557, 0.6417519450187683], [-1.0471158027648926, 1.1570453643798828], [-0.4825337827205658, 0.722690761089325], [0.35766392946243286, -0.10390253365039825], [-0.3530293107032776, 0.6467993259429932], [0.8123199939727783, -0.7440729141235352], [0.8583614826202393, -0.7963447570800781], [-0.05122844874858856, 0.2790241837501526], [-0.29074782133102417, 0.5265320539474487], [-0.43721330165863037, 0.5873724222183228], [-1.0266683101654053, 1.1136842966079712], [-0.7423744201660156, 0.9904260635375977], [-0.4912627041339874, 0.6270673274993896], [0.0638013631105423, 0.21669456362724304], [-0.600567102432251, 0.832517683506012], [0.8203430771827698, -0.5874616503715515], [0.1570080816745758, 0.19543302059173584], [0.6281603574752808, -0.5336666107177734], [-0.7114296555519104, 0.8439964652061462], [0.02410959079861641, 0.20291924476623535], [-0.3661678433418274, 0.5202813148498535], [0.5685743689537048, -0.2947678864002228], [0.495202898979187, -0.24574634432792664], [-0.4149808883666992, 0.6368181705474854], [-0.42298001050949097, 0.623948335647583], [0.800739049911499, -0.8045319318771362], [-0.037376780062913895, 0.35049915313720703], [-0.22897276282310486, 0.5279471278190613], [-0.002591421827673912, 0.2464577704668045], [-0.4072542190551758, 0.5037178993225098]], [[0.1660599559545517, 0.09515973925590515], [0.5552672743797302, -0.34767425060272217], [0.4822704493999481, -0.4243982136249542], [-0.2022710144519806, 0.3517961800098419], [-0.5927212238311768, 0.8750146627426147], [-0.6458677053451538, 0.9027576446533203], [-0.04931206256151199, 0.3061102032661438], [-0.46059203147888184, 0.7044252157211304], [-0.2743706703186035, 0.4811577796936035], [-0.30568626523017883, 0.5331563949584961], [0.27581480145454407, 0.07551472634077072], [-0.2157410979270935, 0.46017777919769287], [0.9721790552139282, -0.8050427436828613], [-0.8804870843887329, 1.0002552270889282], [-0.9479882717132568, 1.0712755918502808], [-0.3877190351486206, 0.6071014404296875], [-0.8541924953460693, 1.0474989414215088], [0.8200317621231079, -0.7219159603118896], [-0.08813789486885071, 0.34915316104888916], [-0.49235931038856506, 0.709376335144043], [-0.424485445022583, 0.6371106505393982], [0.032608237117528915, 0.2176627516746521], [0.6102128028869629, -0.41991645097732544], [-1.0241750478744507, 1.028457522392273], [-0.6882587671279907, 0.8575005531311035], [1.1257632970809937, -1.0246922969818115], [-0.8883538246154785, 1.0052201747894287], [0.2819306254386902, -0.2207619994878769], [-0.9698191285133362, 1.0549741983413696], [-0.9886044263839722, 1.0440047979354858], [1.0127174854278564, -0.9925596714019775], [-0.7989867329597473, 0.8147936463356018]], [[-0.4814121127128601, 0.732337236404419], [0.8080782890319824, -0.696570873260498], [-0.7447011470794678, 1.0109244585037231], [0.6928238272666931, -0.4642714858055115], [-0.6646497845649719, 0.7654762268066406], [-0.41773760318756104, 0.6241649389266968], [0.3645138442516327, -0.12523841857910156], [-0.7635262608528137, 0.8476022481918335], [-0.9739725589752197, 1.0449093580245972], [-0.14768855273723602, 0.46997693181037903], [-1.0412373542785645, 1.068359375], [0.6038728356361389, -0.4265155494213104], [0.9291937351226807, -0.7735229730606079], [0.6930456757545471, -0.39215487241744995], [-0.08500868827104568, 0.3283396363258362], [-1.0270296335220337, 1.0826247930526733], [-0.6376084089279175, 0.8074651956558228], [-0.12147852033376694, 0.36097317934036255], [-0.38874197006225586, 0.6222822666168213], [0.2886500060558319, 0.028544006869196892], [0.022659434005618095, 0.2251402586698532], [-0.21188552677631378, 0.3549060821533203], [-0.24061857163906097, 0.4814405143260956], [-0.4371354579925537, 0.6626671552658081], [-0.4098391532897949, 0.6749989986419678], [-0.06838440895080566, 0.4100845754146576], [0.24814215302467346, 0.11173765361309052], [-0.344809353351593, 0.48322010040283203], [-0.9345048666000366, 0.8968064188957214], [-0.06524938344955444, 0.32472801208496094], [0.6220301389694214, -0.5597134232521057], [-0.8215803503990173, 0.9406914710998535]], [[0.00016163465625140816, 0.26039502024650574], [0.9798297882080078, -0.9068623781204224], [-0.40620169043540955, 0.5138987302780151], [-0.9782412648200989, 0.921427845954895], [0.13189107179641724, 0.09718263149261475], [-0.4647659957408905, 0.6210449934005737], [-0.5657724738121033, 0.7934092283248901], [-0.2199653834104538, 0.32216957211494446], [-0.8032719492912292, 0.9100848436355591], [0.29008275270462036, 0.006101951934397221], [-0.7933842539787292, 0.861207127571106], [0.5267655849456787, -0.2949381470680237], [0.15520429611206055, 0.0728914886713028], [-0.09150095283985138, 0.4557390809059143], [-0.186447411775589, 0.45810073614120483], [-0.34660840034484863, 0.4172692894935608], [-0.5604995489120483, 0.6778209209442139], [0.3879210650920868, -0.2924237847328186], [-1.0639057159423828, 1.0775814056396484], [0.6237859725952148, -0.41866517066955566], [-0.7550743818283081, 0.9251707792282104], [-0.7636280655860901, 0.867752194404602], [0.5424415469169617, -0.3262895941734314], [-0.40964609384536743, 0.6383545398712158], [0.727573573589325, -0.4244796633720398], [0.4758882522583008, -0.3157790005207062], [0.6992343068122864, -0.5179365277290344], [-0.3428376317024231, 0.6625892519950867], [0.3552100360393524, -0.022736622020602226], [-0.18193617463111877, 0.519534707069397], [1.094480276107788, -0.9225896596908569], [-0.08932748436927795, 0.14223220944404602]], [[-0.7276890277862549, 0.8268409967422485], [-0.025533372536301613, 0.33932626247406006], [-0.4787658154964447, 0.652165949344635], [-0.19305871427059174, 0.5221457481384277], [-0.6448403596878052, 0.8738458156585693], [-0.3497037887573242, 0.6048283576965332], [-1.0685254335403442, 1.0753064155578613], [0.8266134262084961, -0.6898413896560669], [0.8508318662643433, -0.7163156867027283], [-0.7661288976669312, 0.8337910771369934], [-0.9875779747962952, 1.0931340456008911], [-1.0028246641159058, 1.1241580247879028], [-0.5894964337348938, 0.7623460292816162], [-0.8032894134521484, 0.8379104137420654], [-0.24734798073768616, 0.4280688166618347], [0.3585794270038605, -0.158610999584198], [0.8730849623680115, -0.6741839051246643], [0.7972638607025146, -0.6256263852119446], [0.6074642539024353, -0.3032470643520355], [-0.17748112976551056, 0.3350137770175934], [0.4415855407714844, -0.32407647371292114], [0.9757295250892639, -0.943753719329834], [-0.5855308175086975, 0.6959187984466553], [-0.22501321136951447, 0.5128977298736572], [-1.0095257759094238, 1.1425470113754272], [-1.0485447645187378, 1.042477011680603], [-0.42016786336898804, 0.6643517017364502], [-1.0631747245788574, 1.1053698062896729], [0.9062288403511047, -0.6510411500930786], [-1.115533471107483, 1.088605284690857], [-0.804212212562561, 0.9791207313537598], [0.595675528049469, -0.6140413284301758]], [[-0.7512096166610718, 0.95477294921875], [-0.7432196736335754, 0.9420037865638733], [-0.2898659110069275, 0.5124929547309875], [0.7471259832382202, -0.7493278980255127], [0.5996876955032349, -0.47059160470962524], [0.721729040145874, -0.5195924043655396], [-0.6027534604072571, 0.7153215408325195], [-0.9780788421630859, 1.0200810432434082], [-0.07999047636985779, 0.3021995425224304], [-1.1106029748916626, 1.1075985431671143], [0.004773683845996857, 0.34707385301589966], [1.0368247032165527, -0.921407163143158], [-0.875348687171936, 0.9991524815559387], [-1.1085261106491089, 1.1170308589935303], [0.8209607601165771, -0.6573591232299805], [-0.26571011543273926, 0.500324010848999], [0.17187142372131348, 0.18328021466732025], [-0.8961780071258545, 0.8580431938171387], [-0.4822579324245453, 0.6908496022224426], [-0.9850271940231323, 1.032281756401062], [0.9151391386985779, -0.8136792182922363], [-1.003631830215454, 1.0689326524734497], [-0.9338181614875793, 1.0340958833694458], [0.12087629735469818, 0.09096840023994446], [-1.0613844394683838, 1.0931059122085571], [0.3290609121322632, -0.0560033805668354], [0.9128191471099854, -0.802047848701477], [0.08104653656482697, 0.24594464898109436], [-1.1014209985733032, 1.0928548574447632], [-0.8509063720703125, 1.002508282661438], [-0.398767352104187, 0.6906181573867798], [0.15255478024482727, 0.013857134617865086]], [[-0.20775434374809265, 0.39158087968826294], [0.29723644256591797, -0.04972250014543533], [-0.3774520754814148, 0.6217156648635864], [0.8644754886627197, -0.7924033403396606], [0.9672526121139526, -0.7953667640686035], [-0.23517301678657532, 0.4715662896633148], [-0.2221190631389618, 0.43409401178359985], [-0.20031151175498962, 0.4313424527645111], [-0.4480232298374176, 0.6998996138572693], [0.9496728181838989, -0.8053176999092102], [0.9858425259590149, -0.8295604586601257], [0.797207236289978, -0.6439210772514343], [0.08745275437831879, 0.14850622415542603], [-0.3612418472766876, 0.605600118637085], [-0.7840685844421387, 0.921747088432312], [0.7496177554130554, -0.6546899080276489], [-0.3730950951576233, 0.6193714737892151], [-1.0920382738113403, 1.1237925291061401], [-1.09046471118927, 1.131439208984375], [-1.0325623750686646, 1.019769310951233], [0.726405918598175, -0.514473557472229], [-1.001865267753601, 0.8683023452758789], [-0.39329904317855835, 0.677697479724884], [0.9912416338920593, -0.906101644039154], [0.6947736144065857, -0.48629820346832275], [-0.05617162212729454, 0.2722015976905823], [-1.104502558708191, 1.0677680969238281], [-0.37598294019699097, 0.6051859855651855], [-0.04930044338107109, 0.28419461846351624], [1.1110038757324219, -1.047739863395691], [1.0242198705673218, -0.8694522976875305], [-0.07049490511417389, 0.3872683048248291]], [[-0.5863249897956848, 0.828025221824646], [-0.9328354597091675, 1.021427869796753], [0.29891347885131836, -0.039163023233413696], [-0.15270915627479553, 0.3639717400074005], [0.9341122508049011, -0.8265193700790405], [-1.097481369972229, 1.1104992628097534], [-1.0608488321304321, 1.1285148859024048], [-1.0981476306915283, 1.1477407217025757], [-0.9113421440124512, 1.0081381797790527], [-0.7720515727996826, 0.7925426959991455], [1.0421820878982544, -0.9797273874282837], [-0.6165319681167603, 0.6939540505409241], [-0.8239222168922424, 1.0209141969680786], [-0.2513936460018158, 0.5162234306335449], [-0.23169860243797302, 0.26891690492630005], [-0.677460789680481, 0.6362037062644958], [-0.8175598382949829, 0.9311110973358154], [0.1066463515162468, 0.1925150752067566], [0.5152410268783569, -0.3770408630371094], [-1.0352421998977661, 1.115250825881958], [0.09832516312599182, 0.19209033250808716], [0.8664489984512329, -0.7538072466850281], [-0.889708399772644, 1.0314044952392578], [-0.9763890504837036, 1.0433567762374878], [-0.7557082176208496, 0.833055853843689], [-0.3915456235408783, 0.5544801950454712], [-0.4771720767021179, 0.6967535018920898], [-0.46168506145477295, 0.7996695637702942], [-0.9962389469146729, 0.9127236604690552], [0.18481120467185974, 0.019203314557671547], [0.28100675344467163, -0.05178999528288841], [0.5230876207351685, -0.3158971071243286]], [[0.6252381801605225, -0.576953649520874], [0.5771585702896118, -0.5135976076126099], [-0.5648239254951477, 0.5555373430252075], [0.1542709618806839, -0.019180281087756157], [-0.028523875400424004, 0.2701725959777832], [-0.2994791865348816, 0.549811065196991], [0.850986897945404, -0.8153330087661743], [-1.0147895812988281, 1.0597249269485474], [-0.09979861229658127, 0.30942073464393616], [0.11231762915849686, 0.16244465112686157], [0.8652948141098022, -0.585553765296936], [-0.3870285749435425, 0.6971822381019592], [0.09993089735507965, 0.24705658853054047], [-0.4019240140914917, 0.6220136880874634], [1.0804760456085205, -1.021270990371704], [-0.7418724298477173, 0.8173452019691467], [-0.4190656542778015, 0.6218432784080505], [0.7483258247375488, -0.5365434885025024], [-0.19239921867847443, 0.48363029956817627], [0.9763662815093994, -0.9355736374855042], [-0.1005096435546875, 0.3335082232952118], [-0.967564582824707, 0.9961794018745422], [-0.2449498027563095, 0.5304247736930847], [-0.35156476497650146, 0.6220777034759521], [-0.3431871831417084, 0.561518669128418], [0.6178207397460938, -0.5666835904121399], [0.37085604667663574, -0.18604780733585358], [-0.38529932498931885, 0.5863952040672302], [-0.21796265244483948, 0.27640485763549805], [0.4210796058177948, -0.2127077579498291], [0.8919786214828491, -0.8876067399978638], [0.7794932723045349, -0.36299192905426025]], [[-0.06850672513246536, 0.3162369132041931], [0.5545423030853271, -0.30805060267448425], [-0.9636938571929932, 0.9713032245635986], [-1.0329116582870483, 1.0391627550125122], [-1.1216120719909668, 1.0372200012207031], [-1.1312239170074463, 0.9262752532958984], [-0.708293080329895, 0.9382269382476807], [0.2597120404243469, 0.04644003510475159], [-0.4335823059082031, 0.6436319351196289], [0.16687998175621033, 0.004092835821211338], [-0.8074201941490173, 0.9643721580505371], [0.48472923040390015, -0.481548935174942], [0.8035812377929688, -0.6366269588470459], [0.7064580917358398, -0.5863927006721497], [-0.39398783445358276, 0.6530478596687317], [0.3143075704574585, -0.09274549037218094], [0.06583840399980545, 0.18462082743644714], [0.6248472929000854, -0.3926895260810852], [-0.4351885914802551, 0.7143146991729736], [-0.43653786182403564, 0.7900835275650024], [-0.04824470356106758, -0.0068839555606245995], [-0.40213608741760254, 0.6116213202476501], [-1.019595742225647, 1.015381097793579], [-0.4090346693992615, 0.5916575193405151], [-0.26637282967567444, 0.5076260566711426], [-0.8352274894714355, 1.0586100816726685], [-1.1054631471633911, 1.0764477252960205], [-1.1380795240402222, 1.0085272789001465], [-0.8807267546653748, 0.9720301628112793], [-0.7861194014549255, 0.953624963760376], [0.6671303510665894, -0.4627705216407776], [-0.9237124919891357, 0.9552891850471497]], [[0.4234827756881714, -0.10911282151937485], [0.537889301776886, -0.18772318959236145], [0.14581698179244995, 0.11376076191663742], [-0.5293592214584351, 0.6620241403579712], [-0.8674430847167969, 0.9725818634033203], [-0.400992751121521, 0.7262417674064636], [0.37650489807128906, -0.30534815788269043], [-0.9585675001144409, 0.9465113878250122], [0.06204172596335411, 0.12521043419837952], [0.16200891137123108, 0.05957012623548508], [0.31111639738082886, -0.12086339294910431], [-1.0378633737564087, 1.050123691558838], [-0.7958883047103882, 1.0141332149505615], [-0.08692266792058945, 0.3670092225074768], [-0.6272347569465637, 0.7056088447570801], [-0.5926421880722046, 0.8630096912384033], [-0.7151336669921875, 0.8830733299255371], [0.951369047164917, -0.968137264251709], [0.40367117524147034, -0.3663991689682007], [-0.925534725189209, 1.0417258739471436], [0.5772602558135986, -0.3052210807800293], [-0.7964383959770203, 0.923253059387207], [0.9661142826080322, -0.8107496500015259], [-1.099584937095642, 1.11680269241333], [0.6764973402023315, -0.4756311774253845], [0.21386373043060303, 0.061046402901411057], [-1.0830471515655518, 1.149155616760254], [0.27877652645111084, -0.10515420138835907], [-0.1945071816444397, 0.4477139711380005], [-0.31769537925720215, 0.5165969133377075], [0.4738248586654663, -0.13931939005851746], [-1.1493459939956665, 1.1043261289596558]], [[-0.40643510222435, 0.6359460949897766], [-0.6019679307937622, 0.6712161302566528], [-1.0613986253738403, 0.9415141940116882], [0.7608970403671265, -0.4857119619846344], [0.464905321598053, -0.34392112493515015], [0.061021145433187485, 0.2179793417453766], [-0.44454967975616455, 0.7434201836585999], [0.12813392281532288, 0.18431831896305084], [-0.8349289894104004, 1.075874924659729], [-0.8051824569702148, 0.9807270765304565], [0.1020820364356041, 0.28686442971229553], [0.9908078908920288, -0.7740644216537476], [0.1732456237077713, 0.13733625411987305], [0.8030022978782654, -0.6292968988418579], [1.004771113395691, -0.8602083921432495], [-1.06333589553833, 1.0707987546920776], [0.4323613941669464, -0.18292957544326782], [-1.123490810394287, 1.1799672842025757], [-0.21100467443466187, 0.41387850046157837], [0.49873071908950806, -0.1174892708659172], [0.8763783574104309, -0.7944239377975464], [-0.7244019508361816, 0.7980035543441772], [-1.0531162023544312, 1.1050142049789429], [-1.0954569578170776, 1.1411306858062744], [0.887819766998291, -0.6794050931930542], [-0.8106710910797119, 0.922698974609375], [-1.0981652736663818, 1.0337566137313843], [0.7961463928222656, -0.6357460618019104], [0.290937215089798, -0.05729009956121445], [0.7838296294212341, -0.7110328674316406], [1.0286320447921753, -0.9254806041717529], [-0.161323681473732, 0.449770450592041]], [[-0.47868573665618896, 0.6167134642601013], [0.4098243713378906, -0.1934417337179184], [0.13732539117336273, 0.17397943139076233], [-0.7909839153289795, 0.7831223011016846], [-0.10684970021247864, 0.3538498878479004], [-1.031279444694519, 1.0774736404418945], [-0.3897436559200287, 0.5070516467094421], [-0.3294162452220917, 0.6062555313110352], [-1.0747917890548706, 0.9641586542129517], [-0.5466887354850769, 0.7829057574272156], [-0.22218415141105652, 0.5461316108703613], [-0.013515420258045197, 0.2029927372932434], [0.1679985225200653, 0.06661151349544525], [0.790229320526123, -0.727117657661438], [0.7788560390472412, -0.6544394493103027], [-0.9993224740028381, 1.0484099388122559], [1.0827417373657227, -0.9830713272094727], [-1.1394106149673462, 1.159485936164856], [0.891244113445282, -0.7679252028465271], [0.49982327222824097, -0.2604129910469055], [1.0355867147445679, -0.8954108953475952], [0.3255560100078583, -0.14305433630943298], [-0.02845442295074463, 0.23902373015880585], [-0.5566986799240112, 0.8332331776618958], [0.09556517750024796, 0.20652617514133453], [1.0533143281936646, -0.8846243619918823], [1.0510669946670532, -0.9169834852218628], [0.3254251480102539, -0.2078038901090622], [0.9567651152610779, -0.8664112687110901], [-0.9434735774993896, 1.0631332397460938], [-0.7552317380905151, 0.9124006628990173], [-0.3589518368244171, 0.6726440191268921]], [[0.18222220242023468, 0.18672840297222137], [0.7672073841094971, -0.492172509431839], [-0.4859592914581299, 0.6462033987045288], [0.79164719581604, -0.5800659656524658], [0.15415546298027039, -0.03545725345611572], [-0.6600885391235352, 0.8193174600601196], [0.6515549421310425, -0.45417898893356323], [0.7724353075027466, -0.44303908944129944], [-0.8362941741943359, 1.0001075267791748], [0.8160694241523743, -0.5931699872016907], [-0.23177173733711243, 0.3084784150123596], [0.6110785007476807, -0.3564712107181549], [0.9603686332702637, -0.8297090530395508], [0.9579201340675354, -0.8371419906616211], [-1.0512558221817017, 1.112371802330017], [0.39285963773727417, -0.2700917720794678], [-0.33209022879600525, 0.48326122760772705], [-0.22987724840641022, 0.46532317996025085], [-0.5561844706535339, 0.668218731880188], [0.5360078811645508, -0.295512318611145], [1.0360231399536133, -0.877967357635498], [0.825996458530426, -0.7210116386413574], [-0.45592767000198364, 0.6908811330795288], [0.93049156665802, -0.7570469379425049], [-0.2335463911294937, 0.5079891681671143], [0.6733700633049011, -0.4001363515853882], [-0.2577938735485077, 0.4920235872268677], [0.14449505507946014, 0.15786613523960114], [-0.6543234586715698, 0.8402443528175354], [-0.4983682930469513, 0.7333104610443115], [0.7575287222862244, -0.4663655757904053], [-0.5632057785987854, 0.7642106413841248]], [[0.6915551424026489, -0.572041392326355], [0.3059132993221283, -0.09157199412584305], [-0.6839058995246887, 0.9514681100845337], [0.7050533890724182, -0.4070889949798584], [-0.16437837481498718, 0.39396241307258606], [0.378637433052063, -0.1766812801361084], [0.8137640357017517, -0.6167614459991455], [-0.683460533618927, 0.8551374077796936], [-0.6870082020759583, 0.7760146856307983], [0.4615389108657837, -0.17183926701545715], [-0.2590269446372986, 0.4706740081310272], [-0.3597368597984314, 0.5215485692024231], [-1.1455790996551514, 1.0975676774978638], [1.0867128372192383, -0.914655864238739], [0.4278593361377716, -0.13649532198905945], [0.8214815855026245, -0.7697382569313049], [0.3445143699645996, -0.13067510724067688], [-0.142706960439682, 0.2914240062236786], [0.09176655113697052, 0.14714214205741882], [-0.8932046890258789, 1.0597294569015503], [-0.42991894483566284, 0.71343994140625], [0.6501784324645996, -0.42012083530426025], [-0.2526273727416992, 0.5433887839317322], [-0.2853652536869049, 0.5386158227920532], [-0.45403677225112915, 0.7250400185585022], [1.078371524810791, -0.8675517439842224], [-0.5561548471450806, 0.7178015112876892], [-0.8506515026092529, 0.9546457529067993], [0.5504330992698669, -0.4227603077888489], [-0.9059426784515381, 0.8452496528625488], [-0.33120399713516235, 0.6315404176712036], [-0.07323165982961655, 0.3701939880847931]], [[-0.939065158367157, 1.0577236413955688], [0.8026622533798218, -0.565588116645813], [0.1627122461795807, 0.19521641731262207], [-0.018146205693483353, 0.12401671707630157], [0.5783842206001282, -0.42484259605407715], [-1.043816328048706, 1.0653153657913208], [-0.40856584906578064, 0.4422374367713928], [-0.7583680152893066, 0.9467308521270752], [-0.689691424369812, 0.7892731428146362], [0.9359849691390991, -0.8268928527832031], [-0.32755333185195923, 0.595624566078186], [-0.6390082836151123, 0.8663955926895142], [0.5365970134735107, -0.29296910762786865], [-0.37856143712997437, 0.6438460350036621], [0.4493747651576996, -0.31067508459091187], [0.7447478771209717, -0.5467987060546875], [1.1004722118377686, -1.040000081062317], [0.842647135257721, -0.8007864356040955], [-1.0877225399017334, 1.0060583353042603], [-0.16684696078300476, 0.3894194960594177], [0.8920603394508362, -0.6725749373435974], [-0.849115788936615, 0.7406294941902161], [1.0006532669067383, -0.9964467287063599], [-0.4477035403251648, 0.6111831665039062], [0.4957278370857239, -0.31663215160369873], [0.21052327752113342, 0.15024606883525848], [-0.5746338963508606, 0.8736169934272766], [0.5125747323036194, -0.18464696407318115], [-0.7193834185600281, 0.8739622831344604], [0.8929190039634705, -0.7449910044670105], [-1.026937484741211, 1.0134159326553345], [-0.41973406076431274, 0.6826152801513672]], [[0.3743883967399597, -0.08092017471790314], [0.9452372789382935, -0.839924693107605], [-0.15878932178020477, 0.37851160764694214], [-0.8628604412078857, 1.0375556945800781], [-0.2864324748516083, 0.24586288630962372], [0.4911162555217743, -0.3279902935028076], [-1.0232664346694946, 0.9573953151702881], [-0.9104782938957214, 1.0096911191940308], [-0.008424336090683937, 0.26460498571395874], [0.3337230086326599, -0.015506262890994549], [0.20804254710674286, 0.10076198726892471], [0.3488513231277466, -0.08142390847206116], [-1.1012014150619507, 1.0998032093048096], [-0.1326970010995865, 0.40315622091293335], [0.5189748406410217, -0.32359275221824646], [0.7294967174530029, -0.49000295996665955], [-0.8098039627075195, 0.9082622528076172], [0.08298826217651367, 0.19035710394382477], [-0.27887970209121704, 0.5294573903083801], [0.004722911864519119, 0.2569851577281952], [-0.600044846534729, 0.8514955639839172], [-0.5302655100822449, 0.6477981805801392], [0.7796074748039246, -0.676807165145874], [-0.496446430683136, 0.6310380101203918], [-0.16160880029201508, 0.4071946442127228], [-0.47323867678642273, 0.6493579149246216], [-0.23203015327453613, 0.4967924654483795], [0.2206926941871643, 0.03427654504776001], [-0.9771590232849121, 0.8106367588043213], [0.7584816217422485, -0.6110256910324097], [-1.025264859199524, 1.074234962463379], [-0.29009220004081726, 0.4868033528327942]], [[0.7922770977020264, -0.7303289175033569], [-0.17744114995002747, 0.26023566722869873], [0.015111913904547691, 0.2807941734790802], [1.0732096433639526, -1.0597467422485352], [-0.6966933608055115, 0.929871678352356], [-1.0305255651474, 0.9462887644767761], [0.9921693205833435, -0.8557778000831604], [-0.9696308374404907, 1.0773321390151978], [-0.8975374698638916, 1.0003777742385864], [-0.17189501225948334, 0.12297683209180832], [0.24516473710536957, 0.009772197343409061], [0.17320957779884338, 0.08190358430147171], [0.13795597851276398, -0.03978411480784416], [-1.0252065658569336, 1.01304292678833], [-0.7223993539810181, 0.7950329780578613], [-0.8220099210739136, 0.9560737609863281], [-0.9334155321121216, 1.0466841459274292], [-1.004109263420105, 1.0528926849365234], [-0.0043943170458078384, 0.2680816054344177], [-0.7192433476448059, 0.827608585357666], [-0.7439634203910828, 0.8618423342704773], [0.07317262887954712, 0.29321786761283875], [0.9776132106781006, -0.7853813171386719], [0.5491561889648438, -0.27009379863739014], [-1.058272123336792, 1.1658719778060913], [0.16765892505645752, 0.231651172041893], [-0.7352893352508545, 0.8770062327384949], [-0.7174279689788818, 0.8177198171615601], [-0.554215669631958, 0.7379893660545349], [-0.1825261414051056, 0.37387657165527344], [-0.1998196542263031, 0.49081361293792725], [0.19637823104858398, -0.009790961630642414]], [[0.008827971294522285, 0.1730835735797882], [-0.2710151970386505, 0.3564452826976776], [0.25408506393432617, -0.025675473734736443], [0.5866175889968872, -0.2853742241859436], [-0.837040901184082, 0.946863055229187], [-0.2511167526245117, 0.48542600870132446], [-0.6799147725105286, 0.8740606307983398], [0.6381735801696777, -0.39104801416397095], [-0.8722641468048096, 0.9230272769927979], [-1.0358092784881592, 1.0259373188018799], [-0.859910786151886, 0.8797080516815186], [0.11863382160663605, 0.1065998300909996], [-0.32965826988220215, 0.5178356170654297], [-0.8971245288848877, 0.9632717967033386], [-0.9097267389297485, 1.0012108087539673], [-1.0905481576919556, 1.0357939004898071], [-0.19708558917045593, 0.4699927270412445], [-0.9102374315261841, 1.034794569015503], [-0.10010475665330887, 0.3393346667289734], [-0.3276655077934265, 0.4498797655105591], [0.8645399808883667, -0.7383224368095398], [-0.9748254418373108, 0.930963933467865], [-0.2915240228176117, 0.4959048628807068], [-0.769202709197998, 0.889157772064209], [1.0520485639572144, -0.9834428429603577], [-0.046574316918849945, 0.33796998858451843], [-0.7858886122703552, 0.8255236148834229], [0.05170563608407974, 0.09621662646532059], [0.9937561750411987, -0.8802358508110046], [0.7836873531341553, -0.695767879486084], [-0.3504824936389923, 0.6467485427856445], [0.447401762008667, -0.22558802366256714]], [[0.5024291276931763, -0.2798979580402374], [-0.4564853012561798, 0.674198567867279], [-0.9029630422592163, 0.904358983039856], [0.8894373178482056, -0.7973896861076355], [0.17566142976284027, 0.025855394080281258], [-0.4941057562828064, 0.7022358179092407], [-0.23838256299495697, 0.4978235363960266], [-0.1349664181470871, 0.49434536695480347], [-0.5107457637786865, 0.7421489953994751], [-0.6140987277030945, 0.7961373329162598], [-0.09522957354784012, 0.24067533016204834], [0.1523231565952301, 0.11151130497455597], [-0.9658198356628418, 1.0618261098861694], [0.35488641262054443, -0.21952128410339355], [-0.5129782557487488, 0.7252962589263916], [0.002850763499736786, 0.20138566195964813], [-0.9849773645401001, 1.031907558441162], [-1.0151972770690918, 1.0481306314468384], [-0.8831223845481873, 0.9111339449882507], [-1.0284911394119263, 1.0076379776000977], [0.41567036509513855, -0.2983333468437195], [-0.9249148368835449, 1.0650794506072998], [-0.4837411046028137, 0.7522746324539185], [-1.086164116859436, 1.0810978412628174], [-0.5193765163421631, 0.6105669736862183], [0.721546471118927, -0.46411120891571045], [0.9364171028137207, -0.8593332767486572], [-1.0773091316223145, 1.1117955446243286], [0.09197582304477692, -0.013315952382981777], [0.6523417234420776, -0.46960896253585815], [-0.4056118428707123, 0.6384825706481934], [0.6196308135986328, -0.44168925285339355]], [[-0.9548847675323486, 0.9631812572479248], [-0.060225047171115875, 0.2896582782268524], [-0.22532901167869568, 0.43767544627189636], [0.6067990660667419, -0.44172871112823486], [0.3143536448478699, -0.07981763780117035], [-0.9847955703735352, 1.0337289571762085], [0.49283626675605774, -0.2154580056667328], [-0.7869068384170532, 0.8791854381561279], [0.25349247455596924, -0.09399386495351791], [-1.1445220708847046, 1.0739396810531616], [0.417937695980072, -0.2067480832338333], [-0.12798413634300232, 0.3147103190422058], [0.8643283247947693, -0.6526965498924255], [1.0006314516067505, -0.8375464081764221], [-0.46354997158050537, 0.6948562860488892], [-0.5109750032424927, 0.721587061882019], [-0.24279382824897766, 0.3710503876209259], [-1.108523964881897, 1.024078369140625], [-0.6178541779518127, 0.7822052836418152], [-0.8861712217330933, 0.9078284502029419], [0.8750177621841431, -0.6422545313835144], [-0.19063670933246613, 0.31573280692100525], [-0.2939070761203766, 0.44669726490974426], [1.0688282251358032, -1.0207123756408691], [-1.0429519414901733, 1.0317015647888184], [-1.093885898590088, 1.1350702047348022], [-0.059358347207307816, 0.2624397277832031], [-0.15109579265117645, 0.37314409017562866], [-0.40008318424224854, 0.6142528057098389], [0.7083966732025146, -0.5809084177017212], [0.03784399852156639, 0.14612776041030884], [-0.870694637298584, 0.9789559245109558]], [[-1.0055078268051147, 1.0500723123550415], [-1.082064151763916, 1.0668644905090332], [0.3540728688240051, -0.12450910359621048], [-0.291640043258667, 0.5022395849227905], [0.290570467710495, 0.019179897382855415], [-0.7222189903259277, 0.9314898252487183], [0.46327105164527893, -0.30555006861686707], [0.5282989740371704, -0.2331705242395401], [-1.0571826696395874, 1.09292733669281], [-1.085211992263794, 1.0916543006896973], [0.3991602659225464, -0.1786085069179535], [-1.1490917205810547, 1.1518583297729492], [0.5117121934890747, -0.34667617082595825], [-0.5709387063980103, 0.7907940149307251], [-0.3508795201778412, 0.571628749370575], [0.8910647630691528, -0.7415035963058472], [0.848726749420166, -0.7289050817489624], [-1.0226566791534424, 1.0831841230392456], [-1.0061349868774414, 1.091780662536621], [-0.34533166885375977, 0.5665662288665771], [-1.1209752559661865, 0.9608522653579712], [-1.120783805847168, 1.100189447402954], [-0.9560806751251221, 0.9652442336082458], [-0.5023013949394226, 0.6559897661209106], [0.1008802056312561, 0.12010423094034195], [-0.32804566621780396, 0.6081556081771851], [1.0818276405334473, -0.9732468724250793], [0.3551155924797058, -0.08726028352975845], [-0.8880037665367126, 1.0027927160263062], [0.8092604279518127, -0.7594105005264282], [0.4441280961036682, -0.2340494692325592], [-0.7652186155319214, 0.8889035582542419]], [[0.808664083480835, -0.7612979412078857], [-0.22318825125694275, 0.38659802079200745], [0.7946113348007202, -0.653544008731842], [0.3487706482410431, -0.045755013823509216], [-0.4751739203929901, 0.6770187020301819], [0.6126035451889038, -0.33657917380332947], [1.0048948526382446, -0.9666891694068909], [-1.1506236791610718, 1.0394670963287354], [0.592261791229248, -0.3963016867637634], [-0.47214803099632263, 0.5903919339179993], [0.5488196611404419, -0.29616159200668335], [-0.37971198558807373, 0.6144002079963684], [-0.614162027835846, 0.8231282234191895], [-1.0345531702041626, 1.1049906015396118], [-0.24476543068885803, 0.4229527711868286], [0.2691669166088104, -0.17758981883525848], [0.17502853274345398, -0.012336905114352703], [-0.12102100998163223, 0.3025466799736023], [-1.0571950674057007, 1.0740090608596802], [0.8305401802062988, -0.7584493160247803], [0.09989813715219498, 0.21604189276695251], [-0.5620102882385254, 0.7476114630699158], [-0.5575743317604065, 0.7341208457946777], [-1.0256990194320679, 1.0694222450256348], [0.11159572750329971, 0.24923963844776154], [-0.5931187272071838, 0.7856165766716003], [0.5355852246284485, -0.3381298780441284], [1.0557457208633423, -1.0481754541397095], [-1.0963795185089111, 1.0626258850097656], [0.5249406695365906, -0.2972162365913391], [1.0200504064559937, -0.98813396692276], [-0.7541207075119019, 0.8480228185653687]], [[0.9704735279083252, -0.8392990827560425], [0.853895366191864, -0.6473709344863892], [-0.33603042364120483, 0.5907936692237854], [0.9427430629730225, -0.8023548722267151], [0.793224573135376, -0.6501630544662476], [0.426288366317749, -0.2175930142402649], [-0.9354467988014221, 1.108563780784607], [-1.0080841779708862, 1.0934160947799683], [0.21769674122333527, 0.02359757013618946], [-0.5066088438034058, 0.7340171337127686], [1.0615876913070679, -0.94614577293396], [-1.102624773979187, 1.0780797004699707], [-0.31530675292015076, 0.5602892637252808], [0.26311272382736206, -0.024654446169734], [0.6963685154914856, -0.5575332045555115], [-1.0963846445083618, 1.1731599569320679], [-0.9803091287612915, 1.0286442041397095], [-1.0811063051223755, 1.053982138633728], [-0.7372087240219116, 0.8322957754135132], [-0.815200924873352, 0.8997095823287964], [0.6281946897506714, -0.621993899345398], [-0.3162378668785095, 0.5933661460876465], [-1.105621576309204, 1.008039951324463], [-0.4229198396205902, 0.4877530336380005], [-0.8587436676025391, 1.0064417123794556], [-0.9216487407684326, 1.0119503736495972], [0.752932608127594, -0.6565667390823364], [0.9800471067428589, -0.9162646532058716], [-1.0144288539886475, 1.059384822845459], [0.44894400238990784, -0.1923544555902481], [0.26656991243362427, -0.18166829645633698], [0.04795580729842186, 0.24930858612060547]], [[-1.0201574563980103, 1.0461103916168213], [0.5506101846694946, -0.18879233300685883], [0.15303345024585724, 0.07687253504991531], [0.48867344856262207, -0.27632978558540344], [-0.5119648575782776, 0.7278292179107666], [0.6421070098876953, -0.4430174231529236], [0.8754339218139648, -0.6297785043716431], [0.7651905417442322, -0.6494107246398926], [-1.038493037223816, 1.098926305770874], [-0.040684375911951065, 0.33367055654525757], [-0.2900724411010742, 0.5162544250488281], [0.969527006149292, -0.8592489957809448], [-0.8730253577232361, 0.968697190284729], [0.9060215353965759, -0.8364765644073486], [0.5386338233947754, -0.4464479982852936], [0.8063962459564209, -0.7600325345993042], [-0.17851650714874268, 0.44618648290634155], [0.7347944974899292, -0.5248762369155884], [0.4396246373653412, -0.12320563942193985], [0.41957518458366394, -0.25002893805503845], [-0.057554151862859726, 0.3319884240627289], [-0.7857469320297241, 0.9456993341445923], [-0.9579400420188904, 0.9795584678649902], [-0.804568886756897, 0.8402406573295593], [0.7400225400924683, -0.46727532148361206], [-0.39166751503944397, 0.679847776889801], [-0.4082721173763275, 0.657893180847168], [0.12310022860765457, 0.15713441371917725], [-0.3646589517593384, 0.5796865820884705], [0.40412086248397827, -0.16198274493217468], [0.488572895526886, -0.22976179420948029], [0.1467382162809372, 0.16596102714538574]], [[-0.6956382989883423, 0.9314993619918823], [-0.9083548784255981, 0.9379444122314453], [0.9117105007171631, -0.8626136183738708], [-1.1011189222335815, 1.0777859687805176], [0.4491004943847656, -0.25560665130615234], [0.967862069606781, -0.8186929225921631], [0.5804314017295837, -0.2800597548484802], [-0.699497640132904, 0.8757938146591187], [0.6436945796012878, -0.5642135143280029], [-0.11937128752470016, 0.3603837490081787], [-0.4045422673225403, 0.6457421183586121], [-1.045371174812317, 1.030147671699524], [-0.5144078135490417, 0.6215125918388367], [0.345707505941391, -0.03498181700706482], [-0.7828866243362427, 0.8889243006706238], [0.09423815459012985, 0.1681814193725586], [0.09144868701696396, 0.25869476795196533], [0.1346472203731537, 0.21707984805107117], [-0.9992926120758057, 0.9756050109863281], [0.10915850847959518, 0.14220458269119263], [-0.0850566178560257, 0.4415361285209656], [0.2193126082420349, -0.048101890832185745], [-0.9594156742095947, 0.9286000728607178], [-0.1442541629076004, 0.3779236674308777], [0.542420506477356, -0.2953183948993683], [0.19772925972938538, 0.0394982174038887], [-0.47302669286727905, 0.6870074272155762], [-0.34137821197509766, 0.6137716174125671], [0.5541415214538574, -0.43209517002105713], [0.7919983267784119, -0.6274111866950989], [-1.0486022233963013, 1.0811399221420288], [0.7723713517189026, -0.6414211988449097]], [[-0.8349790573120117, 0.8731217980384827], [-0.9032829999923706, 0.9716557264328003], [-0.698317289352417, 0.9001398086547852], [-0.473560631275177, 0.6985452175140381], [-0.6241433024406433, 0.8200637102127075], [-0.7997392416000366, 0.9390876889228821], [0.6362665891647339, -0.42757943272590637], [0.5398630499839783, -0.3909175992012024], [-0.43484339118003845, 0.6271897554397583], [0.7264531850814819, -0.5820985436439514], [0.41430896520614624, -0.2830144762992859], [0.6782314777374268, -0.3692438006401062], [-0.6232256293296814, 0.856325089931488], [-0.4509742259979248, 0.7273359894752502], [-0.4085666537284851, 0.5710976719856262], [-0.010739014483988285, 0.23979809880256653], [-0.27617719769477844, 0.4987223148345947], [-0.7677331566810608, 0.9637627005577087], [0.7501895427703857, -0.7389626502990723], [0.7770009636878967, -0.6354072093963623], [0.3513356149196625, -0.2104475498199463], [-0.919715404510498, 1.1048520803451538], [-1.0781489610671997, 1.0739473104476929], [0.0701916515827179, 0.24157801270484924], [-0.812698483467102, 1.011015772819519], [-0.8883564472198486, 1.0586459636688232], [0.588539719581604, -0.39164626598358154], [0.9093379974365234, -0.7553538084030151], [1.0237482786178589, -0.9541815519332886], [0.9209626913070679, -0.8264448046684265], [0.02287631295621395, 0.3166614770889282], [0.5482769012451172, -0.34852561354637146]], [[0.16989761590957642, 0.01235541794449091], [0.9645071029663086, -0.9407139420509338], [-0.5462589859962463, 0.7164605855941772], [-0.44566628336906433, 0.7100656032562256], [-0.6374756097793579, 0.8115853071212769], [0.41936182975769043, -0.10631494969129562], [-0.9464402198791504, 0.9899814128875732], [0.8689192533493042, -0.787778913974762], [-0.9223475456237793, 0.9818693995475769], [-0.7354787588119507, 0.9000001549720764], [1.0750843286514282, -0.9915350079536438], [0.9017771482467651, -0.8696010708808899], [0.7160512208938599, -0.5126820206642151], [0.5799629092216492, -0.3294062316417694], [0.17139890789985657, 0.21086910367012024], [-0.16083025932312012, 0.3935270607471466], [0.8817038536071777, -0.7104989290237427], [0.41860148310661316, -0.2734605669975281], [0.9107600450515747, -0.738515317440033], [0.4898771345615387, -0.23867592215538025], [0.036243874579668045, 0.15589503943920135], [-0.20147421956062317, 0.45862746238708496], [-0.534103274345398, 0.7038461565971375], [-0.9405240416526794, 1.0621355772018433], [-1.0569510459899902, 1.1303677558898926], [-0.6513923406600952, 0.8570278882980347], [-0.046519096940755844, 0.35375964641571045], [-0.8982764482498169, 1.0325449705123901], [-0.6645404100418091, 0.8189482688903809], [-0.910559892654419, 1.0652899742126465], [0.0016954968450590968, 0.2613477408885956], [-0.1958584189414978, 0.4136877954006195]], [[0.22644945979118347, 0.00012040251749567688], [-0.598337709903717, 0.7911836504936218], [0.4618131220340729, -0.3107627034187317], [-0.462088942527771, 0.5150189399719238], [-0.9522835612297058, 1.053411841392517], [-0.7344534993171692, 0.866732120513916], [-0.4123602509498596, 0.6598200798034668], [-1.109942078590393, 1.1296790838241577], [1.0181682109832764, -0.9505295753479004], [0.8454523086547852, -0.7046463489532471], [1.0470634698867798, -0.9020352363586426], [-0.04426508769392967, 0.3406733274459839], [-0.1478199064731598, 0.4159398078918457], [0.25422897934913635, 0.059433408081531525], [-0.89515620470047, 1.0503754615783691], [-0.9545423984527588, 1.10682213306427], [0.6996119618415833, -0.5290888547897339], [-1.105754017829895, 1.0922616720199585], [-0.040033742785453796, 0.384238064289093], [-0.19997157156467438, 0.4579956531524658], [-0.7767102718353271, 0.9489988088607788], [-1.058066725730896, 1.0524097681045532], [0.10908730328083038, 0.03390409052371979], [-0.8587422370910645, 0.9217880964279175], [0.009813366457819939, 0.26252204179763794], [-0.6385162472724915, 0.8729320168495178], [-0.1894327700138092, 0.40374162793159485], [-0.22689217329025269, 0.458856463432312], [-0.013330353423953056, 0.3269439935684204], [0.35232600569725037, -0.040944334119558334], [-1.0919896364212036, 1.0620046854019165], [-1.108962059020996, 1.0935673713684082]], [[-0.3654884696006775, 0.6705780029296875], [-1.0121866464614868, 1.0357370376586914], [0.22746634483337402, 0.06615453213453293], [-0.4855782687664032, 0.7477525472640991], [0.6565777063369751, -0.5437444448471069], [-1.0910626649856567, 1.14066743850708], [0.8624829053878784, -0.8607332110404968], [0.3068954348564148, 0.04749813675880432], [-0.3852117657661438, 0.4623844027519226], [-0.3929043114185333, 0.6232706904411316], [-0.11788569390773773, 0.3861581087112427], [0.5789756774902344, -0.3311457335948944], [0.7697175741195679, -0.5858537554740906], [1.0629924535751343, -0.9661266207695007], [-1.0948541164398193, 1.0929582118988037], [-0.7789482474327087, 0.8915362358093262], [-1.0834951400756836, 1.0638904571533203], [0.46010005474090576, -0.1911490112543106], [0.04253336787223816, 0.13289424777030945], [-0.0947490707039833, 0.20832699537277222], [0.7246554493904114, -0.7342156171798706], [-0.28351765871047974, 0.5769786238670349], [-0.9827404022216797, 0.9316193461418152], [-0.05933292955160141, 0.3907339572906494], [0.0014628245262429118, 0.22466729581356049], [0.6486334800720215, -0.35576310753822327], [0.0011565032182261348, 0.17477978765964508], [0.44793233275413513, -0.21071842312812805], [-0.4615650773048401, 0.7487572431564331], [-0.49817875027656555, 0.7227448225021362], [-0.213469997048378, 0.4416913390159607], [-0.12644672393798828, 0.3672071695327759]], [[0.8950381278991699, -0.7262372970581055], [-0.7133123278617859, 0.8428921103477478], [0.8766118884086609, -0.8489804267883301], [-0.4140186905860901, 0.629270076751709], [-0.9977173805236816, 1.0184059143066406], [-0.8457764387130737, 0.9612398743629456], [-0.3029627799987793, 0.4830107092857361], [-0.5317758321762085, 0.6785578727722168], [-0.4752611517906189, 0.7415734529495239], [0.47853514552116394, -0.31324321031570435], [-1.1494803428649902, 1.068448781967163], [-0.8940151333808899, 0.9772962331771851], [-0.7254737019538879, 0.809044599533081], [-1.0884907245635986, 1.082634449005127], [-0.5182403922080994, 0.6671077609062195], [0.5294312238693237, -0.3534613251686096], [-0.5154992938041687, 0.7507047653198242], [-0.6323957443237305, 0.8831675052642822], [0.23718059062957764, -0.057188987731933594], [-0.7342427968978882, 0.8994345664978027], [-0.6891912817955017, 0.8340103626251221], [-0.22974726557731628, 0.4647675156593323], [0.8997893929481506, -0.76368647813797], [-0.6766219735145569, 0.7299439907073975], [-0.9915172457695007, 0.9258812069892883], [0.8323463201522827, -0.6464487314224243], [-0.09700547903776169, 0.2358749955892563], [-0.8702912330627441, 0.9899991154670715], [0.8353479504585266, -0.8471555709838867], [-0.7950562238693237, 0.8668765425682068], [0.11502701044082642, 0.0030909006018191576], [-0.36753153800964355, 0.6126708984375]], [[0.18955548107624054, -0.09115331619977951], [0.9425270557403564, -0.7922720909118652], [0.6655449867248535, -0.6286932229995728], [-0.5425258874893188, 0.7542613744735718], [-0.4650610685348511, 0.7302433252334595], [0.5199671983718872, -0.4325634241104126], [-0.3354341685771942, 0.4843887686729431], [0.039056576788425446, 0.2330639511346817], [0.3975006341934204, -0.1880827248096466], [-0.5964705348014832, 0.7535853981971741], [0.03276538476347923, 0.14062660932540894], [-0.13326406478881836, 0.2921086251735687], [-0.5833109021186829, 0.6774609088897705], [-0.5544541478157043, 0.8493402600288391], [0.49124300479888916, -0.22350342571735382], [1.0857560634613037, -1.0383061170578003], [-0.5215473771095276, 0.7403315901756287], [-0.9566478133201599, 1.0113807916641235], [-1.0564411878585815, 1.0747793912887573], [-0.34633955359458923, 0.617348313331604], [-0.0368364192545414, 0.1353350430727005], [-1.020306944847107, 0.9687331914901733], [0.5764229893684387, -0.25466492772102356], [-0.6060224771499634, 0.6706523895263672], [0.7974973917007446, -0.5947109460830688], [0.24110525846481323, 0.04992179200053215], [0.979663610458374, -0.831505537033081], [-1.1176613569259644, 1.080256700515747], [0.46740177273750305, -0.2080252319574356], [0.6436212062835693, -0.49349719285964966], [-0.0006125086219981313, 0.22519232332706451], [-0.11897213757038116, 0.3357139825820923]], [[0.7446566224098206, -0.5314217209815979], [-0.8819001317024231, 1.0209180116653442], [-0.8856652975082397, 1.0059407949447632], [-0.011180213652551174, 0.10386261343955994], [-0.5718093514442444, 0.6192799210548401], [-0.7340036630630493, 0.9795709848403931], [-0.9091001152992249, 0.9399539232254028], [0.8623559474945068, -0.9184786081314087], [0.37901565432548523, -0.2179989516735077], [-0.848712146282196, 0.9305336475372314], [-0.9355373382568359, 1.0150355100631714], [-1.0276587009429932, 0.9943684339523315], [-1.013977289199829, 1.0599223375320435], [0.3580251932144165, -0.04022171348333359], [-0.4794834852218628, 0.6950231790542603], [-1.031196117401123, 0.9509549140930176]]]\n",
            "True_labels:  [[0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0], [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0], [1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0], [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0], [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1], [1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0], [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0], [0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1], [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0], [0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1], [1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1], [1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1], [0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0], [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0], [0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0], [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0], [1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1], [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0], [1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1], [0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1], [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0], [0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1], [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1], [1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1], [1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1], [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0], [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1], [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0], [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1], [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0], [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1], [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1], [0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1], [1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0], [1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0], [1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0], [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1], [0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1], [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]]\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HbgazjIlhGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbef6bed-cabd-4001-b2cc-e88d44b5cb78"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (labels_dev.sum(), len(labels_dev), (labels_dev.sum() / len(labels_dev) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 1071 of 2032 (52.71%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANhZEk7irYQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485e9ce0-21e5-4d14-f15a-5ceb33c87320"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "print(\"Len_true_labels: \", len(true_labels))\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  print(pred_labels_i)\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Len_true_labels:  64\n",
            "[1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0]\n",
            "[0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1]\n",
            "[1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "[0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0]\n",
            "[1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1]\n",
            "[1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0]\n",
            "[1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1]\n",
            "[1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1]\n",
            "[1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0]\n",
            "[0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1]\n",
            "[0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1]\n",
            "[1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0]\n",
            "[1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1]\n",
            "[0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0]\n",
            "[1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0]\n",
            "[0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
            "[1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0]\n",
            "[0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1]\n",
            "[1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1]\n",
            "[1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1]\n",
            "[0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1]\n",
            "[0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1]\n",
            "[1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1]\n",
            "[1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1]\n",
            "[1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0]\n",
            "[1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0]\n",
            "[1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1]\n",
            "[1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0]\n",
            "[0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0 0]\n",
            "[1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1]\n",
            "[1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 0 0 1]\n",
            "[1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1]\n",
            "[1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1]\n",
            "[0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1]\n",
            "[1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1]\n",
            "[0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1]\n",
            "[0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0]\n",
            "[1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0]\n",
            "[0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0]\n",
            "[1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1]\n",
            "[1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1]\n",
            "[0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1]\n",
            "[0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1]\n",
            "[1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1]\n",
            "[1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0]\n",
            "[1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0]\n",
            "[0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1]\n",
            "[1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1]\n",
            "[0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1]\n",
            "[0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1]\n",
            "[0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qTU9WjBt6fD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "e55b1a17-6003-427b-af27-6b6bbf86bdd2"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-a1af80ea924d>:2: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTX81rJ2t7M5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23106d8a-eab7-450b-db82-c562edaa6f4f"
      },
      "source": [
        "# Combine the results across all batches.\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR9UiX5furIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e26a2b0-952c-4a51-8b60-3213a83195b9"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/spiece.model',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4W9SsIpqIKE",
        "outputId": "d30cc4df-b75f-46f3-af92-468eb4eaaee0"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# output_dir = '/content/drive/My Drive/saved_model/KoBERT_model_1'\n",
        "output_dir = './model_save/'\n",
        "\n",
        "print(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "./model_save/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xfZW4WbqTIT",
        "outputId": "325b7108-2698-49e1-e5de-9e1ee303fa4e"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iMllmU9tcJw",
        "outputId": "6177a91f-ecd8-4f4e-b89b-4bd2886e49ff"
      },
      "source": [
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "print(\"sentences_test:\", sentences_test)\n",
        "# 모든 문장에 대하여\n",
        "for sent in sentences_test:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) 문장을 토크나이저 합니다. Tokenize the sentence.\n",
        "    #   (2) [CLS]를 모든 문장의 가장 앞에 삽입합니다.\n",
        "    #   (3) [SEP]을 모든 문장의 가장 뒤에 삽입합니다.\n",
        "    #       CLS, SEP는 토큰 임베딩 분야의 특수 토큰으로,\n",
        "    #       CLS는 special CLaSsification token, SEP은 sepcial SEParator token을 의미\n",
        "    #   (4) 토큰들을 그들의 단어 아이디와 매치시킵니다.\n",
        "    #   (5) 문장의 길이는 'max_length' 수치에 맞게 늘려주거나 줄여줍니다.\n",
        "    #       Pad: 특정 형상의 배열로 변형할 때 빈자리를 0으로 채워준다는 의미\n",
        "    #   (6) [PAD] 토큰을 위한 attention mask 생성\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                         # 인코딩할 문장 자리 / 문장을 인코딩\n",
        "                        add_special_tokens = True,    # 특수 토큰 [CLS]와 [SEP] 추가\n",
        "                        max_length = 64,              # max_length에 맞게 모든 문장 패딩 & 축소\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True, # Attention Mask 구축 / 자료 구조는 tensor 형태\n",
        "                                                      # Attention Mask는 단어 배치와 동일하게 \"1\" 생성\n",
        "                        return_tensors = 'pt',        # 인코딩된 문장을 pytorch 텐서 형태로 변경\n",
        "                                                      # tensorflow를 사용하고 있다면 return_tensors = 'tf'라고 씀\n",
        "                   )\n",
        "\n",
        "    # 인코딩된 문장들 List[input_ids_test]에 넣기 but input_ids_test은 이미\n",
        "    input_ids_test.append(encoded_dict['input_ids'])\n",
        "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "index_test = torch.tensor(index_test)\n",
        "\n",
        "print(\"Input_id_test: \", input_ids_test)\n",
        "print(\"Attention_mask_test: \", attention_masks_test)\n",
        "print(\"Index_test: \", index_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences_test: ['나는 철수에게 공을 던져다 주었다.' '먹은 것을 다 소화시켜야 한다.' '그가 노래를 부르고는 내가 피아노를 쳤다.' ...\n",
            " '그는 나를 바보 여긴다.' '수호는 모든 일에 전혀 무감각하다.' '나는 할아버지가 제일 무서우시다.']\n",
            "Input_id_test:  tensor([[   2, 1375, 4473,  ...,    1,    1,    1],\n",
            "        [   2, 2010, 7086,  ...,    1,    1,    1],\n",
            "        [   2, 1186, 1479,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2, 1191, 1370,  ...,    1,    1,    1],\n",
            "        [   2, 2872, 7926,  ...,    1,    1,    1],\n",
            "        [   2, 1375, 4977,  ...,    1,    1,    1]])\n",
            "Attention_mask_test:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "Index_test:  tensor([   1,    2,    3,  ..., 1058, 1059, 1060])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8YtZxpMsmrf"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_loaded = model_loaded.to(device)\n",
        "input_ids_test = input_ids_test.to(device)\n",
        "attention_masks_test = attention_masks_test.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBltg1k_tBfz",
        "outputId": "c428025a-0c80-4297-f186-37007dcd9510"
      },
      "source": [
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  outputs = model_loaded(input_ids_test, token_type_ids=None, attention_mask=attention_masks_test)\n",
        "test_logits = outputs[0]\n",
        "test_logits = test_logits.detach().cpu().numpy()\n",
        "test_logits = np.argmax(test_logits, axis=1).flatten()\n",
        "labels_test = []\n",
        "for i in range(len(test_logits)):\n",
        "    index = test_logits[i]\n",
        "    if index == 1:\n",
        "      labels_test.append(1)\n",
        "      # print(\"1(True)\")\n",
        "    else:\n",
        "      labels_test.append(0)\n",
        "      # print(\"0(False)\")\n",
        "result = labels_test\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSxBM4vKKJ7"
      },
      "source": [
        "import json\n",
        "\n",
        "dict_result = [{\"idx\" : idx, \"label\" : data} for idx, data in enumerate(result)]\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/COLA_Test_HJ.json\", \"w\") as json_file:\n",
        "    json_result = {\"cola\" : dict_result}\n",
        "    json.dump(json_result, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7TGEHLBMoNL",
        "outputId": "d75521c5-eca6-4a37-a11a-646488995a8b"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/COLA_Test_HJ.json') as json_file:\n",
        "    COLA = json.load(json_file)\n",
        "    print(COLA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cola': [{'idx': 0, 'label': 1}, {'idx': 1, 'label': 1}, {'idx': 2, 'label': 0}, {'idx': 3, 'label': 1}, {'idx': 4, 'label': 0}, {'idx': 5, 'label': 1}, {'idx': 6, 'label': 1}, {'idx': 7, 'label': 1}, {'idx': 8, 'label': 0}, {'idx': 9, 'label': 0}, {'idx': 10, 'label': 1}, {'idx': 11, 'label': 0}, {'idx': 12, 'label': 1}, {'idx': 13, 'label': 1}, {'idx': 14, 'label': 1}, {'idx': 15, 'label': 1}, {'idx': 16, 'label': 0}, {'idx': 17, 'label': 0}, {'idx': 18, 'label': 1}, {'idx': 19, 'label': 0}, {'idx': 20, 'label': 1}, {'idx': 21, 'label': 1}, {'idx': 22, 'label': 1}, {'idx': 23, 'label': 1}, {'idx': 24, 'label': 0}, {'idx': 25, 'label': 1}, {'idx': 26, 'label': 0}, {'idx': 27, 'label': 0}, {'idx': 28, 'label': 0}, {'idx': 29, 'label': 1}, {'idx': 30, 'label': 1}, {'idx': 31, 'label': 0}, {'idx': 32, 'label': 1}, {'idx': 33, 'label': 0}, {'idx': 34, 'label': 0}, {'idx': 35, 'label': 1}, {'idx': 36, 'label': 0}, {'idx': 37, 'label': 1}, {'idx': 38, 'label': 0}, {'idx': 39, 'label': 1}, {'idx': 40, 'label': 0}, {'idx': 41, 'label': 1}, {'idx': 42, 'label': 1}, {'idx': 43, 'label': 1}, {'idx': 44, 'label': 1}, {'idx': 45, 'label': 1}, {'idx': 46, 'label': 0}, {'idx': 47, 'label': 0}, {'idx': 48, 'label': 0}, {'idx': 49, 'label': 1}, {'idx': 50, 'label': 1}, {'idx': 51, 'label': 0}, {'idx': 52, 'label': 1}, {'idx': 53, 'label': 1}, {'idx': 54, 'label': 0}, {'idx': 55, 'label': 1}, {'idx': 56, 'label': 1}, {'idx': 57, 'label': 1}, {'idx': 58, 'label': 0}, {'idx': 59, 'label': 1}, {'idx': 60, 'label': 1}, {'idx': 61, 'label': 1}, {'idx': 62, 'label': 1}, {'idx': 63, 'label': 1}, {'idx': 64, 'label': 1}, {'idx': 65, 'label': 1}, {'idx': 66, 'label': 0}, {'idx': 67, 'label': 1}, {'idx': 68, 'label': 1}, {'idx': 69, 'label': 1}, {'idx': 70, 'label': 0}, {'idx': 71, 'label': 0}, {'idx': 72, 'label': 1}, {'idx': 73, 'label': 0}, {'idx': 74, 'label': 1}, {'idx': 75, 'label': 1}, {'idx': 76, 'label': 0}, {'idx': 77, 'label': 1}, {'idx': 78, 'label': 0}, {'idx': 79, 'label': 1}, {'idx': 80, 'label': 1}, {'idx': 81, 'label': 1}, {'idx': 82, 'label': 0}, {'idx': 83, 'label': 1}, {'idx': 84, 'label': 1}, {'idx': 85, 'label': 1}, {'idx': 86, 'label': 0}, {'idx': 87, 'label': 0}, {'idx': 88, 'label': 1}, {'idx': 89, 'label': 1}, {'idx': 90, 'label': 0}, {'idx': 91, 'label': 1}, {'idx': 92, 'label': 0}, {'idx': 93, 'label': 0}, {'idx': 94, 'label': 1}, {'idx': 95, 'label': 1}, {'idx': 96, 'label': 1}, {'idx': 97, 'label': 0}, {'idx': 98, 'label': 1}, {'idx': 99, 'label': 0}, {'idx': 100, 'label': 1}, {'idx': 101, 'label': 1}, {'idx': 102, 'label': 0}, {'idx': 103, 'label': 1}, {'idx': 104, 'label': 1}, {'idx': 105, 'label': 0}, {'idx': 106, 'label': 1}, {'idx': 107, 'label': 1}, {'idx': 108, 'label': 1}, {'idx': 109, 'label': 1}, {'idx': 110, 'label': 1}, {'idx': 111, 'label': 0}, {'idx': 112, 'label': 1}, {'idx': 113, 'label': 0}, {'idx': 114, 'label': 0}, {'idx': 115, 'label': 1}, {'idx': 116, 'label': 0}, {'idx': 117, 'label': 1}, {'idx': 118, 'label': 1}, {'idx': 119, 'label': 0}, {'idx': 120, 'label': 0}, {'idx': 121, 'label': 0}, {'idx': 122, 'label': 1}, {'idx': 123, 'label': 1}, {'idx': 124, 'label': 0}, {'idx': 125, 'label': 0}, {'idx': 126, 'label': 0}, {'idx': 127, 'label': 0}, {'idx': 128, 'label': 0}, {'idx': 129, 'label': 0}, {'idx': 130, 'label': 1}, {'idx': 131, 'label': 1}, {'idx': 132, 'label': 1}, {'idx': 133, 'label': 1}, {'idx': 134, 'label': 0}, {'idx': 135, 'label': 1}, {'idx': 136, 'label': 0}, {'idx': 137, 'label': 1}, {'idx': 138, 'label': 0}, {'idx': 139, 'label': 0}, {'idx': 140, 'label': 0}, {'idx': 141, 'label': 1}, {'idx': 142, 'label': 1}, {'idx': 143, 'label': 1}, {'idx': 144, 'label': 1}, {'idx': 145, 'label': 1}, {'idx': 146, 'label': 0}, {'idx': 147, 'label': 1}, {'idx': 148, 'label': 0}, {'idx': 149, 'label': 1}, {'idx': 150, 'label': 1}, {'idx': 151, 'label': 0}, {'idx': 152, 'label': 1}, {'idx': 153, 'label': 1}, {'idx': 154, 'label': 1}, {'idx': 155, 'label': 0}, {'idx': 156, 'label': 1}, {'idx': 157, 'label': 1}, {'idx': 158, 'label': 1}, {'idx': 159, 'label': 0}, {'idx': 160, 'label': 1}, {'idx': 161, 'label': 0}, {'idx': 162, 'label': 0}, {'idx': 163, 'label': 0}, {'idx': 164, 'label': 0}, {'idx': 165, 'label': 1}, {'idx': 166, 'label': 0}, {'idx': 167, 'label': 1}, {'idx': 168, 'label': 0}, {'idx': 169, 'label': 0}, {'idx': 170, 'label': 1}, {'idx': 171, 'label': 0}, {'idx': 172, 'label': 1}, {'idx': 173, 'label': 1}, {'idx': 174, 'label': 0}, {'idx': 175, 'label': 0}, {'idx': 176, 'label': 1}, {'idx': 177, 'label': 0}, {'idx': 178, 'label': 1}, {'idx': 179, 'label': 1}, {'idx': 180, 'label': 1}, {'idx': 181, 'label': 1}, {'idx': 182, 'label': 0}, {'idx': 183, 'label': 1}, {'idx': 184, 'label': 0}, {'idx': 185, 'label': 1}, {'idx': 186, 'label': 0}, {'idx': 187, 'label': 1}, {'idx': 188, 'label': 0}, {'idx': 189, 'label': 1}, {'idx': 190, 'label': 0}, {'idx': 191, 'label': 1}, {'idx': 192, 'label': 1}, {'idx': 193, 'label': 1}, {'idx': 194, 'label': 1}, {'idx': 195, 'label': 0}, {'idx': 196, 'label': 0}, {'idx': 197, 'label': 1}, {'idx': 198, 'label': 1}, {'idx': 199, 'label': 1}, {'idx': 200, 'label': 0}, {'idx': 201, 'label': 0}, {'idx': 202, 'label': 1}, {'idx': 203, 'label': 0}, {'idx': 204, 'label': 0}, {'idx': 205, 'label': 0}, {'idx': 206, 'label': 1}, {'idx': 207, 'label': 1}, {'idx': 208, 'label': 1}, {'idx': 209, 'label': 1}, {'idx': 210, 'label': 0}, {'idx': 211, 'label': 1}, {'idx': 212, 'label': 0}, {'idx': 213, 'label': 1}, {'idx': 214, 'label': 0}, {'idx': 215, 'label': 1}, {'idx': 216, 'label': 1}, {'idx': 217, 'label': 1}, {'idx': 218, 'label': 1}, {'idx': 219, 'label': 1}, {'idx': 220, 'label': 1}, {'idx': 221, 'label': 1}, {'idx': 222, 'label': 0}, {'idx': 223, 'label': 0}, {'idx': 224, 'label': 1}, {'idx': 225, 'label': 1}, {'idx': 226, 'label': 1}, {'idx': 227, 'label': 1}, {'idx': 228, 'label': 1}, {'idx': 229, 'label': 1}, {'idx': 230, 'label': 0}, {'idx': 231, 'label': 1}, {'idx': 232, 'label': 1}, {'idx': 233, 'label': 1}, {'idx': 234, 'label': 1}, {'idx': 235, 'label': 0}, {'idx': 236, 'label': 1}, {'idx': 237, 'label': 1}, {'idx': 238, 'label': 0}, {'idx': 239, 'label': 0}, {'idx': 240, 'label': 1}, {'idx': 241, 'label': 0}, {'idx': 242, 'label': 1}, {'idx': 243, 'label': 1}, {'idx': 244, 'label': 0}, {'idx': 245, 'label': 0}, {'idx': 246, 'label': 1}, {'idx': 247, 'label': 1}, {'idx': 248, 'label': 0}, {'idx': 249, 'label': 1}, {'idx': 250, 'label': 1}, {'idx': 251, 'label': 1}, {'idx': 252, 'label': 1}, {'idx': 253, 'label': 0}, {'idx': 254, 'label': 0}, {'idx': 255, 'label': 1}, {'idx': 256, 'label': 1}, {'idx': 257, 'label': 1}, {'idx': 258, 'label': 1}, {'idx': 259, 'label': 1}, {'idx': 260, 'label': 1}, {'idx': 261, 'label': 1}, {'idx': 262, 'label': 1}, {'idx': 263, 'label': 1}, {'idx': 264, 'label': 1}, {'idx': 265, 'label': 1}, {'idx': 266, 'label': 1}, {'idx': 267, 'label': 1}, {'idx': 268, 'label': 1}, {'idx': 269, 'label': 0}, {'idx': 270, 'label': 1}, {'idx': 271, 'label': 0}, {'idx': 272, 'label': 1}, {'idx': 273, 'label': 0}, {'idx': 274, 'label': 1}, {'idx': 275, 'label': 1}, {'idx': 276, 'label': 0}, {'idx': 277, 'label': 0}, {'idx': 278, 'label': 0}, {'idx': 279, 'label': 0}, {'idx': 280, 'label': 0}, {'idx': 281, 'label': 1}, {'idx': 282, 'label': 1}, {'idx': 283, 'label': 1}, {'idx': 284, 'label': 0}, {'idx': 285, 'label': 1}, {'idx': 286, 'label': 1}, {'idx': 287, 'label': 1}, {'idx': 288, 'label': 1}, {'idx': 289, 'label': 1}, {'idx': 290, 'label': 1}, {'idx': 291, 'label': 1}, {'idx': 292, 'label': 1}, {'idx': 293, 'label': 0}, {'idx': 294, 'label': 1}, {'idx': 295, 'label': 1}, {'idx': 296, 'label': 1}, {'idx': 297, 'label': 0}, {'idx': 298, 'label': 1}, {'idx': 299, 'label': 0}, {'idx': 300, 'label': 1}, {'idx': 301, 'label': 1}, {'idx': 302, 'label': 0}, {'idx': 303, 'label': 0}, {'idx': 304, 'label': 1}, {'idx': 305, 'label': 1}, {'idx': 306, 'label': 0}, {'idx': 307, 'label': 1}, {'idx': 308, 'label': 1}, {'idx': 309, 'label': 1}, {'idx': 310, 'label': 1}, {'idx': 311, 'label': 1}, {'idx': 312, 'label': 0}, {'idx': 313, 'label': 0}, {'idx': 314, 'label': 0}, {'idx': 315, 'label': 1}, {'idx': 316, 'label': 1}, {'idx': 317, 'label': 1}, {'idx': 318, 'label': 1}, {'idx': 319, 'label': 0}, {'idx': 320, 'label': 1}, {'idx': 321, 'label': 0}, {'idx': 322, 'label': 1}, {'idx': 323, 'label': 0}, {'idx': 324, 'label': 0}, {'idx': 325, 'label': 1}, {'idx': 326, 'label': 1}, {'idx': 327, 'label': 1}, {'idx': 328, 'label': 0}, {'idx': 329, 'label': 0}, {'idx': 330, 'label': 1}, {'idx': 331, 'label': 1}, {'idx': 332, 'label': 1}, {'idx': 333, 'label': 1}, {'idx': 334, 'label': 1}, {'idx': 335, 'label': 1}, {'idx': 336, 'label': 1}, {'idx': 337, 'label': 1}, {'idx': 338, 'label': 0}, {'idx': 339, 'label': 1}, {'idx': 340, 'label': 1}, {'idx': 341, 'label': 1}, {'idx': 342, 'label': 1}, {'idx': 343, 'label': 0}, {'idx': 344, 'label': 0}, {'idx': 345, 'label': 1}, {'idx': 346, 'label': 1}, {'idx': 347, 'label': 1}, {'idx': 348, 'label': 0}, {'idx': 349, 'label': 1}, {'idx': 350, 'label': 0}, {'idx': 351, 'label': 0}, {'idx': 352, 'label': 1}, {'idx': 353, 'label': 0}, {'idx': 354, 'label': 0}, {'idx': 355, 'label': 1}, {'idx': 356, 'label': 1}, {'idx': 357, 'label': 0}, {'idx': 358, 'label': 1}, {'idx': 359, 'label': 0}, {'idx': 360, 'label': 1}, {'idx': 361, 'label': 1}, {'idx': 362, 'label': 1}, {'idx': 363, 'label': 1}, {'idx': 364, 'label': 1}, {'idx': 365, 'label': 0}, {'idx': 366, 'label': 1}, {'idx': 367, 'label': 1}, {'idx': 368, 'label': 1}, {'idx': 369, 'label': 1}, {'idx': 370, 'label': 1}, {'idx': 371, 'label': 1}, {'idx': 372, 'label': 0}, {'idx': 373, 'label': 1}, {'idx': 374, 'label': 1}, {'idx': 375, 'label': 1}, {'idx': 376, 'label': 1}, {'idx': 377, 'label': 1}, {'idx': 378, 'label': 1}, {'idx': 379, 'label': 1}, {'idx': 380, 'label': 0}, {'idx': 381, 'label': 1}, {'idx': 382, 'label': 0}, {'idx': 383, 'label': 0}, {'idx': 384, 'label': 0}, {'idx': 385, 'label': 1}, {'idx': 386, 'label': 0}, {'idx': 387, 'label': 1}, {'idx': 388, 'label': 1}, {'idx': 389, 'label': 0}, {'idx': 390, 'label': 1}, {'idx': 391, 'label': 1}, {'idx': 392, 'label': 0}, {'idx': 393, 'label': 1}, {'idx': 394, 'label': 1}, {'idx': 395, 'label': 1}, {'idx': 396, 'label': 1}, {'idx': 397, 'label': 0}, {'idx': 398, 'label': 0}, {'idx': 399, 'label': 1}, {'idx': 400, 'label': 0}, {'idx': 401, 'label': 1}, {'idx': 402, 'label': 0}, {'idx': 403, 'label': 0}, {'idx': 404, 'label': 1}, {'idx': 405, 'label': 0}, {'idx': 406, 'label': 1}, {'idx': 407, 'label': 1}, {'idx': 408, 'label': 1}, {'idx': 409, 'label': 1}, {'idx': 410, 'label': 1}, {'idx': 411, 'label': 1}, {'idx': 412, 'label': 0}, {'idx': 413, 'label': 0}, {'idx': 414, 'label': 1}, {'idx': 415, 'label': 1}, {'idx': 416, 'label': 1}, {'idx': 417, 'label': 1}, {'idx': 418, 'label': 0}, {'idx': 419, 'label': 0}, {'idx': 420, 'label': 1}, {'idx': 421, 'label': 1}, {'idx': 422, 'label': 0}, {'idx': 423, 'label': 0}, {'idx': 424, 'label': 1}, {'idx': 425, 'label': 1}, {'idx': 426, 'label': 1}, {'idx': 427, 'label': 1}, {'idx': 428, 'label': 0}, {'idx': 429, 'label': 1}, {'idx': 430, 'label': 1}, {'idx': 431, 'label': 1}, {'idx': 432, 'label': 0}, {'idx': 433, 'label': 1}, {'idx': 434, 'label': 1}, {'idx': 435, 'label': 1}, {'idx': 436, 'label': 1}, {'idx': 437, 'label': 0}, {'idx': 438, 'label': 0}, {'idx': 439, 'label': 1}, {'idx': 440, 'label': 1}, {'idx': 441, 'label': 1}, {'idx': 442, 'label': 1}, {'idx': 443, 'label': 0}, {'idx': 444, 'label': 1}, {'idx': 445, 'label': 0}, {'idx': 446, 'label': 1}, {'idx': 447, 'label': 1}, {'idx': 448, 'label': 1}, {'idx': 449, 'label': 1}, {'idx': 450, 'label': 1}, {'idx': 451, 'label': 1}, {'idx': 452, 'label': 1}, {'idx': 453, 'label': 0}, {'idx': 454, 'label': 1}, {'idx': 455, 'label': 1}, {'idx': 456, 'label': 1}, {'idx': 457, 'label': 1}, {'idx': 458, 'label': 1}, {'idx': 459, 'label': 1}, {'idx': 460, 'label': 1}, {'idx': 461, 'label': 0}, {'idx': 462, 'label': 1}, {'idx': 463, 'label': 1}, {'idx': 464, 'label': 1}, {'idx': 465, 'label': 1}, {'idx': 466, 'label': 1}, {'idx': 467, 'label': 0}, {'idx': 468, 'label': 1}, {'idx': 469, 'label': 1}, {'idx': 470, 'label': 1}, {'idx': 471, 'label': 1}, {'idx': 472, 'label': 0}, {'idx': 473, 'label': 1}, {'idx': 474, 'label': 0}, {'idx': 475, 'label': 1}, {'idx': 476, 'label': 1}, {'idx': 477, 'label': 0}, {'idx': 478, 'label': 1}, {'idx': 479, 'label': 0}, {'idx': 480, 'label': 1}, {'idx': 481, 'label': 0}, {'idx': 482, 'label': 1}, {'idx': 483, 'label': 1}, {'idx': 484, 'label': 0}, {'idx': 485, 'label': 1}, {'idx': 486, 'label': 0}, {'idx': 487, 'label': 0}, {'idx': 488, 'label': 1}, {'idx': 489, 'label': 1}, {'idx': 490, 'label': 0}, {'idx': 491, 'label': 1}, {'idx': 492, 'label': 1}, {'idx': 493, 'label': 0}, {'idx': 494, 'label': 0}, {'idx': 495, 'label': 1}, {'idx': 496, 'label': 1}, {'idx': 497, 'label': 0}, {'idx': 498, 'label': 1}, {'idx': 499, 'label': 1}, {'idx': 500, 'label': 1}, {'idx': 501, 'label': 0}, {'idx': 502, 'label': 1}, {'idx': 503, 'label': 0}, {'idx': 504, 'label': 0}, {'idx': 505, 'label': 0}, {'idx': 506, 'label': 1}, {'idx': 507, 'label': 1}, {'idx': 508, 'label': 0}, {'idx': 509, 'label': 1}, {'idx': 510, 'label': 1}, {'idx': 511, 'label': 0}, {'idx': 512, 'label': 1}, {'idx': 513, 'label': 0}, {'idx': 514, 'label': 1}, {'idx': 515, 'label': 1}, {'idx': 516, 'label': 1}, {'idx': 517, 'label': 1}, {'idx': 518, 'label': 1}, {'idx': 519, 'label': 1}, {'idx': 520, 'label': 1}, {'idx': 521, 'label': 1}, {'idx': 522, 'label': 1}, {'idx': 523, 'label': 1}, {'idx': 524, 'label': 1}, {'idx': 525, 'label': 1}, {'idx': 526, 'label': 0}, {'idx': 527, 'label': 0}, {'idx': 528, 'label': 0}, {'idx': 529, 'label': 1}, {'idx': 530, 'label': 0}, {'idx': 531, 'label': 1}, {'idx': 532, 'label': 1}, {'idx': 533, 'label': 1}, {'idx': 534, 'label': 0}, {'idx': 535, 'label': 1}, {'idx': 536, 'label': 1}, {'idx': 537, 'label': 1}, {'idx': 538, 'label': 0}, {'idx': 539, 'label': 1}, {'idx': 540, 'label': 1}, {'idx': 541, 'label': 1}, {'idx': 542, 'label': 0}, {'idx': 543, 'label': 0}, {'idx': 544, 'label': 1}, {'idx': 545, 'label': 1}, {'idx': 546, 'label': 0}, {'idx': 547, 'label': 1}, {'idx': 548, 'label': 0}, {'idx': 549, 'label': 0}, {'idx': 550, 'label': 0}, {'idx': 551, 'label': 0}, {'idx': 552, 'label': 0}, {'idx': 553, 'label': 1}, {'idx': 554, 'label': 1}, {'idx': 555, 'label': 1}, {'idx': 556, 'label': 0}, {'idx': 557, 'label': 1}, {'idx': 558, 'label': 1}, {'idx': 559, 'label': 1}, {'idx': 560, 'label': 0}, {'idx': 561, 'label': 0}, {'idx': 562, 'label': 1}, {'idx': 563, 'label': 1}, {'idx': 564, 'label': 0}, {'idx': 565, 'label': 0}, {'idx': 566, 'label': 1}, {'idx': 567, 'label': 1}, {'idx': 568, 'label': 1}, {'idx': 569, 'label': 1}, {'idx': 570, 'label': 1}, {'idx': 571, 'label': 1}, {'idx': 572, 'label': 1}, {'idx': 573, 'label': 1}, {'idx': 574, 'label': 0}, {'idx': 575, 'label': 0}, {'idx': 576, 'label': 0}, {'idx': 577, 'label': 0}, {'idx': 578, 'label': 1}, {'idx': 579, 'label': 1}, {'idx': 580, 'label': 0}, {'idx': 581, 'label': 1}, {'idx': 582, 'label': 0}, {'idx': 583, 'label': 1}, {'idx': 584, 'label': 1}, {'idx': 585, 'label': 0}, {'idx': 586, 'label': 0}, {'idx': 587, 'label': 1}, {'idx': 588, 'label': 0}, {'idx': 589, 'label': 0}, {'idx': 590, 'label': 1}, {'idx': 591, 'label': 0}, {'idx': 592, 'label': 0}, {'idx': 593, 'label': 0}, {'idx': 594, 'label': 1}, {'idx': 595, 'label': 0}, {'idx': 596, 'label': 1}, {'idx': 597, 'label': 0}, {'idx': 598, 'label': 1}, {'idx': 599, 'label': 0}, {'idx': 600, 'label': 0}, {'idx': 601, 'label': 0}, {'idx': 602, 'label': 0}, {'idx': 603, 'label': 0}, {'idx': 604, 'label': 1}, {'idx': 605, 'label': 1}, {'idx': 606, 'label': 0}, {'idx': 607, 'label': 1}, {'idx': 608, 'label': 0}, {'idx': 609, 'label': 0}, {'idx': 610, 'label': 1}, {'idx': 611, 'label': 0}, {'idx': 612, 'label': 1}, {'idx': 613, 'label': 0}, {'idx': 614, 'label': 0}, {'idx': 615, 'label': 1}, {'idx': 616, 'label': 1}, {'idx': 617, 'label': 0}, {'idx': 618, 'label': 0}, {'idx': 619, 'label': 1}, {'idx': 620, 'label': 0}, {'idx': 621, 'label': 0}, {'idx': 622, 'label': 1}, {'idx': 623, 'label': 1}, {'idx': 624, 'label': 0}, {'idx': 625, 'label': 0}, {'idx': 626, 'label': 0}, {'idx': 627, 'label': 0}, {'idx': 628, 'label': 0}, {'idx': 629, 'label': 1}, {'idx': 630, 'label': 1}, {'idx': 631, 'label': 0}, {'idx': 632, 'label': 1}, {'idx': 633, 'label': 0}, {'idx': 634, 'label': 0}, {'idx': 635, 'label': 1}, {'idx': 636, 'label': 0}, {'idx': 637, 'label': 1}, {'idx': 638, 'label': 1}, {'idx': 639, 'label': 1}, {'idx': 640, 'label': 0}, {'idx': 641, 'label': 0}, {'idx': 642, 'label': 1}, {'idx': 643, 'label': 0}, {'idx': 644, 'label': 1}, {'idx': 645, 'label': 0}, {'idx': 646, 'label': 1}, {'idx': 647, 'label': 1}, {'idx': 648, 'label': 1}, {'idx': 649, 'label': 1}, {'idx': 650, 'label': 1}, {'idx': 651, 'label': 1}, {'idx': 652, 'label': 0}, {'idx': 653, 'label': 1}, {'idx': 654, 'label': 1}, {'idx': 655, 'label': 1}, {'idx': 656, 'label': 1}, {'idx': 657, 'label': 0}, {'idx': 658, 'label': 0}, {'idx': 659, 'label': 0}, {'idx': 660, 'label': 1}, {'idx': 661, 'label': 1}, {'idx': 662, 'label': 0}, {'idx': 663, 'label': 1}, {'idx': 664, 'label': 0}, {'idx': 665, 'label': 0}, {'idx': 666, 'label': 0}, {'idx': 667, 'label': 1}, {'idx': 668, 'label': 1}, {'idx': 669, 'label': 1}, {'idx': 670, 'label': 1}, {'idx': 671, 'label': 1}, {'idx': 672, 'label': 0}, {'idx': 673, 'label': 0}, {'idx': 674, 'label': 0}, {'idx': 675, 'label': 1}, {'idx': 676, 'label': 0}, {'idx': 677, 'label': 0}, {'idx': 678, 'label': 1}, {'idx': 679, 'label': 0}, {'idx': 680, 'label': 0}, {'idx': 681, 'label': 0}, {'idx': 682, 'label': 1}, {'idx': 683, 'label': 1}, {'idx': 684, 'label': 1}, {'idx': 685, 'label': 1}, {'idx': 686, 'label': 1}, {'idx': 687, 'label': 0}, {'idx': 688, 'label': 1}, {'idx': 689, 'label': 0}, {'idx': 690, 'label': 1}, {'idx': 691, 'label': 1}, {'idx': 692, 'label': 1}, {'idx': 693, 'label': 1}, {'idx': 694, 'label': 1}, {'idx': 695, 'label': 1}, {'idx': 696, 'label': 0}, {'idx': 697, 'label': 0}, {'idx': 698, 'label': 0}, {'idx': 699, 'label': 0}, {'idx': 700, 'label': 0}, {'idx': 701, 'label': 1}, {'idx': 702, 'label': 1}, {'idx': 703, 'label': 1}, {'idx': 704, 'label': 1}, {'idx': 705, 'label': 0}, {'idx': 706, 'label': 1}, {'idx': 707, 'label': 0}, {'idx': 708, 'label': 0}, {'idx': 709, 'label': 0}, {'idx': 710, 'label': 0}, {'idx': 711, 'label': 1}, {'idx': 712, 'label': 0}, {'idx': 713, 'label': 0}, {'idx': 714, 'label': 0}, {'idx': 715, 'label': 1}, {'idx': 716, 'label': 1}, {'idx': 717, 'label': 0}, {'idx': 718, 'label': 1}, {'idx': 719, 'label': 1}, {'idx': 720, 'label': 1}, {'idx': 721, 'label': 1}, {'idx': 722, 'label': 1}, {'idx': 723, 'label': 1}, {'idx': 724, 'label': 0}, {'idx': 725, 'label': 0}, {'idx': 726, 'label': 1}, {'idx': 727, 'label': 1}, {'idx': 728, 'label': 1}, {'idx': 729, 'label': 1}, {'idx': 730, 'label': 0}, {'idx': 731, 'label': 0}, {'idx': 732, 'label': 0}, {'idx': 733, 'label': 1}, {'idx': 734, 'label': 0}, {'idx': 735, 'label': 0}, {'idx': 736, 'label': 1}, {'idx': 737, 'label': 0}, {'idx': 738, 'label': 1}, {'idx': 739, 'label': 1}, {'idx': 740, 'label': 1}, {'idx': 741, 'label': 0}, {'idx': 742, 'label': 0}, {'idx': 743, 'label': 1}, {'idx': 744, 'label': 0}, {'idx': 745, 'label': 0}, {'idx': 746, 'label': 1}, {'idx': 747, 'label': 1}, {'idx': 748, 'label': 0}, {'idx': 749, 'label': 1}, {'idx': 750, 'label': 1}, {'idx': 751, 'label': 0}, {'idx': 752, 'label': 1}, {'idx': 753, 'label': 1}, {'idx': 754, 'label': 1}, {'idx': 755, 'label': 0}, {'idx': 756, 'label': 1}, {'idx': 757, 'label': 0}, {'idx': 758, 'label': 1}, {'idx': 759, 'label': 1}, {'idx': 760, 'label': 1}, {'idx': 761, 'label': 1}, {'idx': 762, 'label': 1}, {'idx': 763, 'label': 1}, {'idx': 764, 'label': 1}, {'idx': 765, 'label': 1}, {'idx': 766, 'label': 1}, {'idx': 767, 'label': 0}, {'idx': 768, 'label': 0}, {'idx': 769, 'label': 0}, {'idx': 770, 'label': 1}, {'idx': 771, 'label': 1}, {'idx': 772, 'label': 1}, {'idx': 773, 'label': 0}, {'idx': 774, 'label': 0}, {'idx': 775, 'label': 1}, {'idx': 776, 'label': 1}, {'idx': 777, 'label': 1}, {'idx': 778, 'label': 1}, {'idx': 779, 'label': 0}, {'idx': 780, 'label': 0}, {'idx': 781, 'label': 1}, {'idx': 782, 'label': 0}, {'idx': 783, 'label': 1}, {'idx': 784, 'label': 1}, {'idx': 785, 'label': 1}, {'idx': 786, 'label': 1}, {'idx': 787, 'label': 1}, {'idx': 788, 'label': 0}, {'idx': 789, 'label': 1}, {'idx': 790, 'label': 0}, {'idx': 791, 'label': 0}, {'idx': 792, 'label': 1}, {'idx': 793, 'label': 0}, {'idx': 794, 'label': 1}, {'idx': 795, 'label': 0}, {'idx': 796, 'label': 1}, {'idx': 797, 'label': 1}, {'idx': 798, 'label': 0}, {'idx': 799, 'label': 0}, {'idx': 800, 'label': 0}, {'idx': 801, 'label': 1}, {'idx': 802, 'label': 1}, {'idx': 803, 'label': 0}, {'idx': 804, 'label': 1}, {'idx': 805, 'label': 1}, {'idx': 806, 'label': 0}, {'idx': 807, 'label': 1}, {'idx': 808, 'label': 1}, {'idx': 809, 'label': 1}, {'idx': 810, 'label': 1}, {'idx': 811, 'label': 1}, {'idx': 812, 'label': 0}, {'idx': 813, 'label': 1}, {'idx': 814, 'label': 1}, {'idx': 815, 'label': 0}, {'idx': 816, 'label': 1}, {'idx': 817, 'label': 1}, {'idx': 818, 'label': 1}, {'idx': 819, 'label': 1}, {'idx': 820, 'label': 1}, {'idx': 821, 'label': 1}, {'idx': 822, 'label': 0}, {'idx': 823, 'label': 1}, {'idx': 824, 'label': 1}, {'idx': 825, 'label': 1}, {'idx': 826, 'label': 1}, {'idx': 827, 'label': 1}, {'idx': 828, 'label': 1}, {'idx': 829, 'label': 1}, {'idx': 830, 'label': 1}, {'idx': 831, 'label': 1}, {'idx': 832, 'label': 0}, {'idx': 833, 'label': 1}, {'idx': 834, 'label': 1}, {'idx': 835, 'label': 0}, {'idx': 836, 'label': 0}, {'idx': 837, 'label': 1}, {'idx': 838, 'label': 0}, {'idx': 839, 'label': 0}, {'idx': 840, 'label': 1}, {'idx': 841, 'label': 1}, {'idx': 842, 'label': 1}, {'idx': 843, 'label': 1}, {'idx': 844, 'label': 1}, {'idx': 845, 'label': 0}, {'idx': 846, 'label': 1}, {'idx': 847, 'label': 1}, {'idx': 848, 'label': 1}, {'idx': 849, 'label': 1}, {'idx': 850, 'label': 0}, {'idx': 851, 'label': 0}, {'idx': 852, 'label': 1}, {'idx': 853, 'label': 0}, {'idx': 854, 'label': 1}, {'idx': 855, 'label': 1}, {'idx': 856, 'label': 0}, {'idx': 857, 'label': 1}, {'idx': 858, 'label': 1}, {'idx': 859, 'label': 1}, {'idx': 860, 'label': 1}, {'idx': 861, 'label': 1}, {'idx': 862, 'label': 1}, {'idx': 863, 'label': 1}, {'idx': 864, 'label': 1}, {'idx': 865, 'label': 1}, {'idx': 866, 'label': 0}, {'idx': 867, 'label': 1}, {'idx': 868, 'label': 1}, {'idx': 869, 'label': 1}, {'idx': 870, 'label': 0}, {'idx': 871, 'label': 0}, {'idx': 872, 'label': 0}, {'idx': 873, 'label': 1}, {'idx': 874, 'label': 1}, {'idx': 875, 'label': 0}, {'idx': 876, 'label': 1}, {'idx': 877, 'label': 0}, {'idx': 878, 'label': 1}, {'idx': 879, 'label': 0}, {'idx': 880, 'label': 0}, {'idx': 881, 'label': 0}, {'idx': 882, 'label': 1}, {'idx': 883, 'label': 1}, {'idx': 884, 'label': 1}, {'idx': 885, 'label': 1}, {'idx': 886, 'label': 1}, {'idx': 887, 'label': 1}, {'idx': 888, 'label': 1}, {'idx': 889, 'label': 0}, {'idx': 890, 'label': 1}, {'idx': 891, 'label': 0}, {'idx': 892, 'label': 1}, {'idx': 893, 'label': 1}, {'idx': 894, 'label': 1}, {'idx': 895, 'label': 1}, {'idx': 896, 'label': 1}, {'idx': 897, 'label': 1}, {'idx': 898, 'label': 0}, {'idx': 899, 'label': 0}, {'idx': 900, 'label': 0}, {'idx': 901, 'label': 0}, {'idx': 902, 'label': 1}, {'idx': 903, 'label': 1}, {'idx': 904, 'label': 1}, {'idx': 905, 'label': 0}, {'idx': 906, 'label': 0}, {'idx': 907, 'label': 1}, {'idx': 908, 'label': 0}, {'idx': 909, 'label': 1}, {'idx': 910, 'label': 1}, {'idx': 911, 'label': 0}, {'idx': 912, 'label': 1}, {'idx': 913, 'label': 0}, {'idx': 914, 'label': 1}, {'idx': 915, 'label': 1}, {'idx': 916, 'label': 1}, {'idx': 917, 'label': 1}, {'idx': 918, 'label': 0}, {'idx': 919, 'label': 0}, {'idx': 920, 'label': 1}, {'idx': 921, 'label': 1}, {'idx': 922, 'label': 1}, {'idx': 923, 'label': 0}, {'idx': 924, 'label': 1}, {'idx': 925, 'label': 1}, {'idx': 926, 'label': 0}, {'idx': 927, 'label': 0}, {'idx': 928, 'label': 1}, {'idx': 929, 'label': 1}, {'idx': 930, 'label': 1}, {'idx': 931, 'label': 0}, {'idx': 932, 'label': 0}, {'idx': 933, 'label': 0}, {'idx': 934, 'label': 0}, {'idx': 935, 'label': 0}, {'idx': 936, 'label': 0}, {'idx': 937, 'label': 0}, {'idx': 938, 'label': 0}, {'idx': 939, 'label': 0}, {'idx': 940, 'label': 0}, {'idx': 941, 'label': 1}, {'idx': 942, 'label': 0}, {'idx': 943, 'label': 0}, {'idx': 944, 'label': 1}, {'idx': 945, 'label': 1}, {'idx': 946, 'label': 0}, {'idx': 947, 'label': 1}, {'idx': 948, 'label': 0}, {'idx': 949, 'label': 1}, {'idx': 950, 'label': 1}, {'idx': 951, 'label': 1}, {'idx': 952, 'label': 0}, {'idx': 953, 'label': 1}, {'idx': 954, 'label': 1}, {'idx': 955, 'label': 0}, {'idx': 956, 'label': 1}, {'idx': 957, 'label': 1}, {'idx': 958, 'label': 0}, {'idx': 959, 'label': 0}, {'idx': 960, 'label': 0}, {'idx': 961, 'label': 1}, {'idx': 962, 'label': 0}, {'idx': 963, 'label': 1}, {'idx': 964, 'label': 0}, {'idx': 965, 'label': 1}, {'idx': 966, 'label': 1}, {'idx': 967, 'label': 0}, {'idx': 968, 'label': 0}, {'idx': 969, 'label': 1}, {'idx': 970, 'label': 0}, {'idx': 971, 'label': 1}, {'idx': 972, 'label': 1}, {'idx': 973, 'label': 1}, {'idx': 974, 'label': 1}, {'idx': 975, 'label': 0}, {'idx': 976, 'label': 1}, {'idx': 977, 'label': 0}, {'idx': 978, 'label': 1}, {'idx': 979, 'label': 0}, {'idx': 980, 'label': 0}, {'idx': 981, 'label': 1}, {'idx': 982, 'label': 0}, {'idx': 983, 'label': 0}, {'idx': 984, 'label': 1}, {'idx': 985, 'label': 0}, {'idx': 986, 'label': 0}, {'idx': 987, 'label': 1}, {'idx': 988, 'label': 0}, {'idx': 989, 'label': 1}, {'idx': 990, 'label': 1}, {'idx': 991, 'label': 1}, {'idx': 992, 'label': 1}, {'idx': 993, 'label': 1}, {'idx': 994, 'label': 1}, {'idx': 995, 'label': 1}, {'idx': 996, 'label': 0}, {'idx': 997, 'label': 0}, {'idx': 998, 'label': 1}, {'idx': 999, 'label': 1}, {'idx': 1000, 'label': 1}, {'idx': 1001, 'label': 1}, {'idx': 1002, 'label': 1}, {'idx': 1003, 'label': 1}, {'idx': 1004, 'label': 0}, {'idx': 1005, 'label': 1}, {'idx': 1006, 'label': 1}, {'idx': 1007, 'label': 0}, {'idx': 1008, 'label': 1}, {'idx': 1009, 'label': 0}, {'idx': 1010, 'label': 1}, {'idx': 1011, 'label': 0}, {'idx': 1012, 'label': 1}, {'idx': 1013, 'label': 1}, {'idx': 1014, 'label': 1}, {'idx': 1015, 'label': 1}, {'idx': 1016, 'label': 1}, {'idx': 1017, 'label': 1}, {'idx': 1018, 'label': 0}, {'idx': 1019, 'label': 0}, {'idx': 1020, 'label': 1}, {'idx': 1021, 'label': 1}, {'idx': 1022, 'label': 1}, {'idx': 1023, 'label': 1}, {'idx': 1024, 'label': 1}, {'idx': 1025, 'label': 1}, {'idx': 1026, 'label': 1}, {'idx': 1027, 'label': 1}, {'idx': 1028, 'label': 1}, {'idx': 1029, 'label': 1}, {'idx': 1030, 'label': 1}, {'idx': 1031, 'label': 0}, {'idx': 1032, 'label': 1}, {'idx': 1033, 'label': 0}, {'idx': 1034, 'label': 0}, {'idx': 1035, 'label': 1}, {'idx': 1036, 'label': 0}, {'idx': 1037, 'label': 1}, {'idx': 1038, 'label': 1}, {'idx': 1039, 'label': 1}, {'idx': 1040, 'label': 0}, {'idx': 1041, 'label': 0}, {'idx': 1042, 'label': 0}, {'idx': 1043, 'label': 0}, {'idx': 1044, 'label': 0}, {'idx': 1045, 'label': 1}, {'idx': 1046, 'label': 1}, {'idx': 1047, 'label': 1}, {'idx': 1048, 'label': 1}, {'idx': 1049, 'label': 0}, {'idx': 1050, 'label': 0}, {'idx': 1051, 'label': 0}, {'idx': 1052, 'label': 1}, {'idx': 1053, 'label': 1}, {'idx': 1054, 'label': 1}, {'idx': 1055, 'label': 0}, {'idx': 1056, 'label': 0}, {'idx': 1057, 'label': 0}, {'idx': 1058, 'label': 0}, {'idx': 1059, 'label': 1}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8D2zJz6S-wn"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible. 하지만 42는 큰 의미 없는 수\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val) # 생성된 난수 중 씨드값 42의 수 출력(고정)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 학습값 손실, 검증값 손실, 검증데이터 정확성, 시간 등 여러 측정 상태 저장 및 출력\n",
        "training_stats = []\n",
        "\n",
        "# 전체 학습 시간 측정\n",
        "total_t0 = time.time()\n",
        "\n",
        "# 매 epoch에 대해서...\n",
        "for epoch_i in range(0, epochs): # ∵epochs = 4\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # 학습 데이터셋에 대한 1회차 실행\n",
        "\n",
        "    print('')\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # 전방 전달(forward pass) 수행 (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "\n",
        "        '''\n",
        "        전방 전달(forward pass)은 입력부터 출력까지 값을 계산한다.\n",
        "        그리고 나서 후방 전달(backward pass)은 역전파(back propagation)을 수행하는데,\n",
        "        이는 끝에서 시작해서 반복적으로 연쇄 법칙을 적용해 회로 입력에 대한 모든 길에서\n",
        "        그라디언트 값을 계산한다. 그라디언트 값은 회로를 통해 거꾸로 흐르는 것으로 볼 수 있다.\n",
        "\n",
        "        순전파(forwards propagation)은 뉴럴 네트워크의 그래프를 계산하기 위해서\n",
        "        중간 변수들을 순서대로 계산하고 저장한다. 즉, 입력층부터 시작해서 출력층까지 처리한다.\n",
        "        역전파(back propagation)은 중간 변수와 파라미터에 대한 그래디언트(gradient)를\n",
        "        반대 방향으로 계산하고 저장한다.\n",
        "        '''\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss = loss.float()\n",
        "        # print(\"loss:\", loss) # loss값 확인\n",
        "\n",
        "        # 모든 batch에 대한 학습 손실값을 축적\n",
        "        # 그래서 우리는 마지막에 평균 손실값을 구할 수 있다.\n",
        "        # 'loss'는 단일 값을 포함한 Tensor.\n",
        "        # '.item()'함수는 tensor로부터 Python 값을 리턴.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # gradients를 계산하기 위해 loss에 대해 후방 전달(backward pass) 수행\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Development\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Development...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "            logits = outputs[0]\n",
        "            logits = logits.float()\n",
        "\n",
        "        total_eval_loss += logits.item()\n",
        "\n",
        "        dev_logits = outputs[1]\n",
        "        dev_logits = dev_logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(dev_logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this development run.\n",
        "    avg_dev_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_dev_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_dev_loss = total_eval_loss / len(dev_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    development_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Development Loss: {0:.2f}\".format(avg_dev_loss))\n",
        "    print(\"  Development took: {:}\".format(development_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Dev. Loss': avg_dev_loss,\n",
        "            'Dev. Accur.': avg_dev_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Development Time': development_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}